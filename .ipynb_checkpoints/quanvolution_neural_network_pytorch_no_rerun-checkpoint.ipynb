{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rz3x2_QCv9w1",
    "outputId": "9d9a5b9a-4af3-4cb5-d239-5d27e54b5709"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AxGKV_rmaA1r"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOn2BmCeaA1s"
   },
   "source": [
    "# Setting of the main hyper-parameters of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QM9Kthb_aA1s"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f32ef4af7f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_epochs = 30   # Number of optimization epochs\n",
    "n_layers = 5    # Number of random layers\n",
    "n_train = 50    # Size of the train dataset\n",
    "n_test = 50     # Size of the test dataset\n",
    "\n",
    "SAVE_PATH = \"/content/\"  # Data saving folder\n",
    "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "torch.manual_seed(0)       # Seed for TensorFlow random number generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYzVqB7MaA1s"
   },
   "source": [
    "# Loading of the MNIST dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "DV2aff2CaA1s"
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "def transform(x):\n",
    "    x = np.array(x)\n",
    "    x = x/255.0\n",
    "    \n",
    "    return torch.from_numpy(x).float()\n",
    "train_set = torchvision.datasets.MNIST(root='./mnist', train=True, download=True, transform=transform)\n",
    "test_set = torchvision.datasets.MNIST(root='./mnist', train=False, download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=4)\n",
    "# print(len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JN6m4GKRaA1s"
   },
   "source": [
    "# Quantum circuit as a convolution kernel\n",
    "\n",
    "We follow the scheme described in the introduction and represented in\n",
    "the figure at the top of this demo.\n",
    "\n",
    "We initialize a PennyLane `default.qubit` device, simulating a system of\n",
    "$4$ qubits. The associated `qnode` represents the quantum circuit\n",
    "consisting of:\n",
    "\n",
    "1.  an embedding layer of local $R_y$ rotations (with angles scaled by a\n",
    "    factor of $\\pi$);\n",
    "2.  a random circuit of `n_layers`;\n",
    "3.  a final measurement in the computational basis, estimating $4$\n",
    "    expectation values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "clOjblH7aA1s",
    "outputId": "2edd97c9-b482-4e7f-e343-06d59b986322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.30467815 5.3906313  5.32343968 3.91796626]\n",
      " [2.4151415  1.86946507 0.35633815 1.71315002]\n",
      " [3.00125845 5.10300662 3.01578552 2.46793966]\n",
      " [5.2532378  2.1199226  4.07258398 2.31372983]\n",
      " [6.01398323 0.88184996 5.46691948 2.97576711]]\n",
      "tensor([1, 2, 3, 4], device='cuda:0')\n",
      "(<Figure size 1600x500 with 1 Axes>, <Axes: >)\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [1, 2, 3, 4],\n",
      "        [1, 2, 3, 4]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([0.4626, 0.4626, 0.4626]),\n",
       " tensor([0.4033, 0.4033, 0.4033]),\n",
       " tensor([-0.1318, -0.1318, -0.1318]),\n",
       " tensor([-0.5300, -0.5300, -0.5300])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dev1 = qml.device(\"lightning.qubit\", wires = 4)\n",
    "dev2 = qml.device(\"default.qubit\", wires = 4)\n",
    "# Random circuit parameters\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "print(rand_params)\n",
    "@qml.qnode(dev1, interface='torch', diff_method='adjoint')\n",
    "def circuit1(inputs, rand_params):\n",
    "    # Encoding of 4 classical input values\n",
    "    print(inputs)\n",
    "    qml.AngleEmbedding(inputs, wires=list(range(4)), rotation=\"Y\")\n",
    "\n",
    "    # Random quantum circuit\n",
    "    RandomLayers(rand_params, wires=list(range(4)), seed = None)\n",
    "\n",
    "\n",
    "    # Measurement producing 4 classical output values\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n",
    "\n",
    "\n",
    "print(qml.draw_mpl(circuit1, level=None, style = 'pennylane_sketch')(torch.tensor([1,2,3,4]).cuda(), rand_params))\n",
    "\n",
    "\n",
    "test_layer = qml.qnn.TorchLayer(circuit1, weight_shapes={'rand_params': (n_layers,8)})\n",
    "circuit1(torch.tensor([[1,2,3,4],[1,2,3,4],[1,2,3,4]]).cuda(),rand_params=rand_params)\n",
    "# # test_layer.rand_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracker': <pennylane.tracker.Tracker at 0x7f321eeccc10>,\n",
       " '_shots': Shots(total_shots=None, shot_vector=()),\n",
       " '_wires': Wires([0, 1, 2, 3]),\n",
       " '_c_dtype': numpy.complex128,\n",
       " '_batch_obs': False,\n",
       " '_wire_map': None,\n",
       " 'LightningStateVector': pennylane_lightning.lightning_qubit._state_vector.LightningStateVector,\n",
       " 'LightningMeasurements': pennylane_lightning.lightning_qubit._measurements.LightningMeasurements,\n",
       " 'LightningAdjointJacobian': pennylane_lightning.lightning_qubit._adjoint_jacobian.LightningAdjointJacobian,\n",
       " '_rng': Generator(PCG64) at 0x7F321EEB7680,\n",
       " '_mcmc': False,\n",
       " '_kernel_name': None,\n",
       " '_num_burnin': 0,\n",
       " '_statevector': <pennylane_lightning.lightning_qubit._state_vector.LightningStateVector at 0x7f3226e08650>}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev1.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn \n",
    "class QuanvolutionLayerTest(nn.Module):\n",
    "    def __init__(self, kernel_size=(2, 2), stride=1, n_filters=1, filter_layers = 1, padding = False):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_filters = n_filters\n",
    "        self.num_wires = kernel_size[0] * kernel_size[1]\n",
    "        self.filter_layer_size = np.random.randint(4, 2*self.num_wires*torch.floor(torch.log2(torch.tensor(self.num_wires))))\n",
    "        print(self.filter_layer_size)\n",
    "        \n",
    "        self.total_wires = self.n_filters * self.num_wires\n",
    "        self.filter_seeds = torch.randint(0, int(1e8), (1,)).item()\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.n_rotations_gate = filter_layers*self.filter_layer_size\n",
    "        self.kernel_h, self.kernel_w = self.kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        dev = qml.device(\"lightning.qubit\", wires=self.total_wires)\n",
    "        # @qml.transforms.broadcast_expand\n",
    "        @qml.qnode(dev,interface='torch', diff_method='adjoint')\n",
    "        def circuit(inputs, weights):\n",
    "            # Encoding classical inputs\n",
    "            qml.AngleEmbedding(inputs, wires=list(range(0, self.total_wires)), rotation=\"Y\")\n",
    "        \n",
    "            # Add random quantum layers\n",
    "            for i in range(self.n_filters):\n",
    "                # print(\"WIRE RANGE: \", i*self.num_wires, i*self.num_wires + self.num_wires, weights[i*self.num_wires: i*self.num_wires + self.num_wires])\n",
    "                RandomLayers(weights[:,i*self.n_rotations_gate: i*self.n_rotations_gate + self.n_rotations_gate], \n",
    "                            wires=list(range(i*self.num_wires, i*self.num_wires + self.num_wires)),\n",
    "                            # rotations=[qml.PauliX,qml.PauliY,qml.PauliZ],\n",
    "                            seed = self.filter_seeds+i)\n",
    "                         \n",
    "        \n",
    "            # Measurement producing classical outputs\n",
    "            measurement = [qml.expval(qml.PauliZ(j)) for j in range(self.total_wires)]\n",
    "            # measurement = [sum(measurement[i*self.num_wires: i*self.num_wires + self.num_wires]) for i in range(self.n_filters)]\n",
    "            return measurement\n",
    "        \n",
    "        weight_shapes = {\"weights\": (1,n_filters*filter_layers*self.filter_layer_size)}\n",
    "        # self.q_params = nn.Parameter(torch.randn((1,n_filters*filter_layers*self.filter_layer_size)))\n",
    "\n",
    "        self.kernel_circuits = qml.qnn.TorchLayer(circuit, weight_shapes = weight_shapes)\n",
    "        # self.kernel_circuits = circuit\n",
    "        # print(qml.draw(self.kernel_circuits, level = None, decimals = 3)(torch.zeros(self.total_wires)))\n",
    "       \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, n_filters, new_height, new_width)\n",
    "        \"\"\"\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        # print(x.shape)\n",
    "        new_height = (height - self.kernel_h) // self.stride + 1\n",
    "        new_width = (width - self.kernel_w) // self.stride + 1\n",
    "        epsilon = 1e-8\n",
    "        # print(new_height, new_width)\n",
    "        # # Prepare output tensor\n",
    "        # output = torch.zeros((batch_size, self.n_filters, new_height, new_width), dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # for b in range(batch_size):\n",
    "        #     print(\"CUR BATCH: \" + str(b))\n",
    "        #     for i in range(0, height - self.kernel_h + 1, self.stride):  # Step by stride\n",
    "        #         for j in range(0, width - self.kernel_w + 1, self.stride):  # Step by stride\n",
    "        #             print(b, i, j)\n",
    "        #             if i + self.kernel_h <= height and j + self.kernel_w <= width:\n",
    "        #                 q_out = torch.zeros(self.n_filters, dtype=torch.float32).to(self.device)\n",
    "        #                 for c in range(channels):\n",
    "        #                     kernel = x[b, c, i:i + self.kernel_h, j:j + self.kernel_w].flatten()\n",
    "        #                     # print(\"kernel: \",kernel.size())\n",
    "        #                     kernel = kernel[:self.num_wires]  # Adjust to fit the number of qubits\n",
    "        #                     kernel = kernel / torch.max(torch.abs(kernel) + epsilon)  # Normalize\n",
    "        #                     kernel = kernel.repeat(self.n_filters)\n",
    "        #                     # quantum_output = torch.hstack(\n",
    "                                \n",
    "        #                     # )\n",
    "        #                     quantum_output = torch.hstack([torch.sum(self.kernel_circuits(kernel)[i*self.num_wires: i*self.num_wires + self.num_wires]) for i in range(self.n_filters)])\n",
    "        #                     q_out += quantum_output.cuda()\n",
    "        #                     # print(quantum_output, q_out)\n",
    "        #                     # print(qml.draw(self.kernel_circuits, level = None)(kernel))\n",
    "        #                 # break\n",
    "        #                 output[b, :, i // self.stride, j // self.stride] = q_out  # Update with stride indexing\n",
    "        #                 # print(output)\n",
    "\n",
    "        # return output\n",
    "        # Prepare output tensor\n",
    "        # output = torch.zeros((batch_size, self.n_filters, new_height, new_width), dtype=torch.float32, device=self.device)\n",
    "\n",
    "        # Pre-extract patch for efficient computation\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        new_height = (height - self.kernel_h) // self.stride + 1\n",
    "        new_width = (width - self.kernel_w) // self.stride + 1\n",
    "\n",
    "        # Extract patches\n",
    "        patches = x.unfold(2, self.kernel_h, self.stride).unfold(3, self.kernel_w, self.stride)\n",
    "        patches = patches.contiguous().view(batch_size, channels, -1, self.kernel_h * self.kernel_w)\n",
    "        patches = patches.permute(0, 2, 1, 3)  # Shape: (batch_size, n_patches, channels, kernel_size)\n",
    "        # print(patches.size())\n",
    "        # Normalize patches and prepare for quantum input\n",
    "        # for i, patch in enumerate(patches):\n",
    "        #     patch = patch.flatten(2)  # Flatten channels and kernel dimensions\n",
    "        #     patch = patch / (torch.max(torch.abs(patch), dim=-1, keepdim=True).values + 1e-8)\n",
    "        #     print(patch.size())\n",
    "\n",
    "        #     # Repeat patches for each quantum filter\n",
    "        #     patch = patch.repeat(1, 1, self.n_filters).view(-1, self.n_filters * self.num_wires)\n",
    "        #     print(patch.size())\n",
    "\n",
    "        #     # Process with quantum circuit\n",
    "        #     quantum_output = torch.tensor(self.kernel_circuits(patch))\n",
    "        #     quantum_output = quantum_output.view(quantum_output.shape[0], self.n_filters, self.num_wires).sum(dim=-1)\n",
    "        #     print(quantum_output, quantum_output.size())\n",
    "        #     reconstructed = torch.stack([quantum_output[:,i].view(new_height,new_width) for i in range(self.n_filters)])\n",
    "        #     print(reconstructed, reconstructed.size())\n",
    "        #     output[i,:,:,:] = reconstructed\n",
    "        # quantum_output = quantum_output.permute(0, 3, 1, 2)  # Final output shape\n",
    "        \n",
    "        patches = patches.flatten(2)  # Flatten channels and kernel dimensions\n",
    "        patches = patches / (torch.max(torch.abs(patches), dim=-1, keepdim=True).values + epsilon)\n",
    "        # print(patches.size())\n",
    "\n",
    "        # Repeat patches for each quantum filter\n",
    "        patches = patches.repeat(1, 1, self.n_filters).view(-1, self.n_filters * self.num_wires)\n",
    "        # print(patches.size())\n",
    "\n",
    "        # Process with quantum circuit\n",
    "        # quantum_output = self.kernel_circuits(patches).detach()\n",
    "        quantum_outputs = torch.zeros(patches.size(0), self.n_filters*self.num_wires, device=torch.device('cuda'))\n",
    "\n",
    "        # Loop through each batch (individual images in the batch)\n",
    "        print(patches.size(), quantum_outputs.size())\n",
    "        # for b in range(patches.size(0)):\n",
    "        #     # Loop through each patch for the current batch\n",
    "        #     print('cur_batch: ', b)\n",
    "        #     patch = patches[b]  # Extract the patch from the batch\n",
    "        #     # Flatten and normalize the patch as needed (depending on how your kernel works)\n",
    "        #     patch = patch.flatten(0)  # Flatten the patch into a 1D tensor (size [channels * kernel_h * kernel_w])\n",
    "            \n",
    "            # Process the patch through the quantum circuit\n",
    "        quantum_output = self.kernel_circuits(patches.to(torch.device('cuda')))  # Add batch dimension temporarily\n",
    "        # print(quantum_output.size())\n",
    "            # # Store the result in the output tensor (assuming sum over expvals for this example)\n",
    "            # quantum_outputs[b,:] = quantum_output.detach()\n",
    "            # print(quantum_outputs)\n",
    "\n",
    "        # print(quantum_output.view(patches.size(0), self.n_filters, self.num_wires).size())\n",
    "        quantum_output = quantum_output.view(patches.size(0), self.n_filters, self.num_wires).sum(dim=-1)\n",
    "        print(quantum_output.size())\n",
    "        # print(quantum_output)\n",
    "        print('Finished 1 quanv layer')\n",
    "        quantum_output = quantum_output.view(batch_size, channels, new_height, new_width, self.n_filters).sum(dim=1) \n",
    "        print(quantum_output.size())\n",
    "        output = quantum_output.permute(0,3,1,2) # torch.stack([quantum_output.view(batch_size,-1,self.n_filters)[:,:,i].view(self.n_filters,new_height,new_width) for i in range(self.n_filters)],dim=1)\n",
    "        # print(reconstructed, reconstructed.size()) \n",
    "        # output[i,:,:,:] = reconstructed\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "torch.Size([784, 8]) torch.Size([784, 8])\n",
      "torch.Size([784, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 14, 14, 2])\n",
      "Model output: torch.Size([4, 2, 14, 14])\n",
      "Parameter containing:\n",
      "tensor([[3.2615, 3.8695, 5.0906, 6.1581, 0.7206, 1.9903, 4.3763, 5.7446, 5.8754,\n",
      "         5.9136, 3.7668, 0.4097, 3.4306, 1.1762]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "imag, cls = next(iter(train_loader))   \n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "        QuanvolutionLayerTest(kernel_size=(2, 2), n_filters=2, stride = 2),\n",
    "        # torch.nn.Flatten(),\n",
    "        # torch.nn.Linear(in_features=588, out_features=10)\n",
    "    ).cuda()\n",
    "outputs = model(imag.unsqueeze(1).cuda())\n",
    "print(\"Model output:\",  outputs.size())\n",
    "print(model._modules['0'].kernel_circuits.weights)\n",
    "\n",
    "# qml.draw_mpl(model._modules['0'].kernel_circuits)(imag.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAAPbCAYAAABBl+ibAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAr8JJREFUeJzs3X1cVHX6//E3gzJ4E3gPaiTajZiaGAZheVdseJ/t1zIzJUrdbmhT8ptaKqkldrNkvxajNW+yzUQt3TZd1GXlazdsbt60mlqamuYG3gUoGhhzfn/0cLYJVObImRnG1/PxOI91PvO5zrnOca52Ls+ZcwIMwzAEAAAAAABqnM3bCQAAAAAA4K9ougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVouiUtWrRIAQEB+vzzz72dimmRkZEaOHCgt9OoMZGRkXrggQe8nQb8GHXve6h7AADgjzzedJ/7ovvLpUWLFurTp4/+9re/mV7vrFmztGrVqppL1A3ff/+9Jk2apD59+uiKK65QQECA8vLyamTdhYWFmjBhgqKiolS/fn01aNBAMTExeu6551RUVFQj26jNsrOzdf/99+vaa69VQECAevfu7e2UUAXq3j3U/fkdP35cL730knr27KnmzZurUaNGuvnmm5Wdne3t1AAAAKpUx1sbnjFjhtq2bSvDMFRYWKhFixapf//++utf/2rqzM2sWbM0dOhQDRkypOaTvYivvvpKL7zwgq699lp17txZ+fn5NbLef/3rX+rfv79OnTql+++/XzExMZKkzz//XLNnz9bGjRu1bt26GtlWbfX6669r8+bNuummm3T8+HFvp4OLoO4vjrq/sPz8fD3zzDPq37+/pkyZojp16ui9997Tvffeq507d2r69OneThEAAMCF15rufv36qVu3bs7XDz30kMLCwvTuu+/WusslY2JidPz4cTVp0kQrVqzQ3XfffcnrLCoq0l133aXAwEBt3bpVUVFRLu8///zzmjdv3iVvp7Z7++231bp1a9lsNnXq1Mnb6eAiqPsLo+4vrmPHjtqzZ4/atGnjHHv00UeVkJCgF154QU899ZQaNGjgxQwBAABc+cxvuhs1aqR69eqpTh3Xfwd4+eWX1b17dzVt2lT16tVTTEyMVqxY4TInICBApaWleuutt5yXrv7yd4GHDx/WQw89pFatWslut6tt27Z65JFHVF5e7rKesrIypaamqnnz5mrQoIHuuusuHT169KK5X3HFFWrSpIn5na/CG2+8ocOHDysjI6PSF29JCgsL05QpUyqNf/zxx4qNjVVwcLDatWunxYsXu7x/4sQJTZgwQZ07d1bDhg0VEhKifv366YsvvnCZl5eXp4CAAC1btkzPP/+8rrzySgUHB+v222/X3r17Xeb27t1bnTp10s6dO9WnTx/Vr19frVu31osvvlgpv7KyMqWlpemaa66R3W5XRESEnnrqKZWVlZk5TIqIiJDN5jMfY7iJundF3V9c27ZtXRpu6efPwpAhQ1RWVqZ9+/a5vU4AAAAree1Md3FxsY4dOybDMHTkyBG99tprzsspf+nVV1/V4MGDNWLECJWXl2vp0qW6++679eGHH2rAgAGSfj7bOXr0aMXGxmrs2LGSpKuvvlqS9J///EexsbEqKirS2LFjFRUVpcOHD2vFihU6ffq0goKCnNt6/PHH1bhxY6WlpenAgQOaM2eOUlJSvPJbwQ8++ED16tXT0KFDqx2zd+9eDR06VA899JCSkpK0YMECPfDAA4qJiVHHjh0lSfv27dOqVat09913q23btiosLNQbb7yhXr16aefOnWrVqpXLOmfPni2bzaYJEyaouLhYL774okaMGKHPPvvMZd4PP/ygvn376re//a3uuecerVixQhMnTlTnzp3Vr18/SZLD4dDgwYP18ccfa+zYserQoYO2b9+uV155RV9//bXXfpsLz6HuL4y6N6+goECS1KxZsxpZHwAAQI0xPGzhwoWGpEqL3W43Fi1aVGn+6dOnXV6Xl5cbnTp1Mm677TaX8QYNGhhJSUmV4keNGmXYbDbjX//6V6X3HA6HS04JCQnOMcMwjPHjxxuBgYFGUVFRtfdv+fLlhiRjw4YN1Y6pSuPGjY0uXbpUe36bNm0MScbGjRudY0eOHDHsdrvx5JNPOsd+/PFHo6KiwiV2//79ht1uN2bMmOEc27BhgyHJ6NChg1FWVuYcf/XVVw1Jxvbt251jvXr1MiQZixcvdo6VlZUZ4eHhxv/8z/84x95++23DZrMZH330kcv2s7KyDEnGJ5984rI/Vf19XkjHjh2NXr16uRUDz6Duq4e6d7/uDcMwjh8/brRo0cLo0aOH27EAAABW89p1uZmZmVq/fr3Wr1+vP//5z+rTp49Gjx6t999/32VevXr1nH/+4YcfVFxcrB49emjLli0X3YbD4dCqVas0aNAgl9+RnhMQEODyeuzYsS5jPXr0UEVFhb799lt3d++SlZSU6IorrnAr5vrrr1ePHj2cr5s3b6727du7XG5pt9udl2NXVFTo+PHjatiwodq3b1/lMU1OTnY5K3hu/b++hLNhw4YuZyuDgoIUGxvrMm/58uXq0KGDoqKidOzYMedy2223SZI2bNjg1v6i9qHuL4y6d5/D4dCIESNUVFSk11577ZLWBQAAYAWvXV4eGxvr8oV4+PDh6tq1q1JSUjRw4EDnF74PP/xQzz33nLZt2+by+79ff3GuytGjR1VSUlLtG2xdddVVLq8bN24s6ecv/Z4WEhKikydPuhXz6/yln/fhl/k7HA69+uqrmjt3rvbv36+Kigrne02bNr3oOs93TK688spKfyeNGzfWv//9b+frPXv2aNeuXWrevHmV+R85cuR8uwY/Qd1fGHXvvscff1w5OTlavHixunTpcknrAgAAsILXmu5fs9ls6tOnj1599VXt2bNHHTt21EcffaTBgwerZ8+emjt3rlq2bKm6detq4cKFWrJkSY3nEBgYWOW4YRg1vq2LiYqK0rZt21ReXu5yxulCqpP/rFmzNHXqVD344IOaOXOmmjRpIpvNpnHjxsnhcJhaZ3XnORwOde7cWRkZGVXOjYiIqHIc/ou6d0Xdu2f69OmaO3euZs+erZEjR5peDwAAgJV8pumWpJ9++kmSdOrUKUnSe++9p+DgYK1du1Z2u905b+HChZViqzoD1rx5c4WEhGjHjh0WZWydQYMGKT8/X++9956GDx9eY+tdsWKF+vTpo/nz57uMFxUVWX4DoquvvlpffPGFbr/99mqdscTlgbr/L+q++jIzM/Xss89q3LhxmjhxYo2tFwAAoKb5zLOWzp49q3Xr1ikoKEgdOnSQ9PNZlICAAJdLIQ8cOFDl3W4bNGigoqIilzGbzaYhQ4bor3/9qz7//PNKMd44k1VdDz/8sFq2bKknn3xSX3/9daX3jxw5oueee87t9QYGBlba7+XLl+vw4cOmc62ue+65R4cPH67yOcNnzpxRaWmp5TnAt1D3rqj76snOztbvf/97jRgx4rxn0AEAAHyF1850/+1vf9Pu3bsl/fxFcsmSJdqzZ48mTZqkkJAQSdKAAQOUkZGhvn376r777tORI0eUmZmpa665xuU3g5IUExOjv//978rIyFCrVq3Utm1bxcXFadasWVq3bp169erlfFzN999/r+XLl+vjjz9Wo0aNamR/zn0R/vLLLyX9/Dijjz/+WJJcnqv77LPPavr06dqwYYN69+593vU1btxYK1euVP/+/RUdHa37779fMTExkqQtW7bo3XffVXx8vNt5Dhw4UDNmzFBycrK6d++u7du365133lG7du3cXpe7Ro4cqWXLlunhhx/Whg0bdMstt6iiokK7d+/WsmXLtHbt2ipvfHUhGzdu1MaNGyX9/Fve0tJS599Fz5491bNnzxrfD5hH3VP3l1r3mzZt0qhRo9S0aVPdfvvteuedd1ze7969u0f2CwAAoNo8fbv0qh4dFBwcbERHRxuvv/66y6N7DMMw5s+fb1x77bWG3W43oqKijIULFxppaWnGr1PfvXu30bNnT6NevXqGJJfHznz77bfGqFGjjObNmxt2u91o166d8dhjjzkfiXMup18/Xujc43Oq8xigX+/TL5dfevLJJ42AgABj165d1Tpe//nPf4zx48cb1113nREcHGzUr1/fiImJMZ5//nmjuLjYOa9NmzbGgAEDKsX36tXL5TFaP/74o/Hkk08aLVu2NOrVq2fccsstRn5+fqV55/Z9+fLlLuvbv3+/IclYuHChyzY6duxYadtJSUlGmzZtXMbKy8uNF154wejYsaNht9uNxo0bGzExMcb06dMr7U91Hh107rNQ1ZKWlnbReHgGdU/d11Tdn+/xc+eWX+YIAADgCwIMw4evtfRDsbGxatOmjZYvX+7tVAB4CHUPAABw+fKZ33RfDkpKSvTFF19oxowZ3k4FgIdQ9zBr48aNGjRokFq1aqWAgIAq72vwa3l5ebrxxhtlt9t1zTXXaNGiRZbnCaDmUPeAf6Lp9qCQkBCVlZU5bxgFwP9R9zCrtLRUXbp0UWZmZrXm79+/XwMGDFCfPn20bds2jRs3TqNHj9batWstzhRATaHuAf/E5eUAAPi4gIAArVy5UkOGDDnvnIkTJ2r16tUuj8u79957VVRUpJycHA9kCaAmUfeA//Cp53QDAABz8vPzlZCQ4DKWmJiocePGnTemrKxMZWVlztcOh0MnTpxQ06ZNa/S56kBtYBiGTp48qVatWslmqx0Xg5qpe4naB37JE7VP0w0AgB8oKChQWFiYy1hYWJhKSkp05swZ1atXr1JMenq6pk+f7qkUgVrh0KFDuvLKK72dRrWYqXuJ2geqYmXt03QDAHCZmjx5slJTU52vi4uLddVVV+nQoUMKCQnxYmaA55WUlCgiIkJXXHGFt1OxHLUP/Jcnap+mGwAAPxAeHq7CwkKXscLCQoWEhJz3bJfdbpfdbq80HhISwhdvXLZq0+XVZupeovaBqlhZ+9Vuuvt2nmJZEkBtkLP9OW+n4HFt/vSSt1MAvOrbsf/r7RSqLT4+XmvWrHEZW79+veLj472UEQCrUfdA7VA77hIBAMBl5tSpU9q2bZu2bdsm6edHA23btk0HDx6U9PPloaNGjXLOf/jhh7Vv3z499dRT2r17t+bOnatly5Zp/Pjx3kgfgAnUPeCfaLoBAPBBn3/+ubp27aquXbtKklJTU9W1a1dNmzZNkvT99987v4hLUtu2bbV69WqtX79eXbp00R/+8Ae9+eabSkxM9Er+ANxH3QP+id90AwDgg3r37i3DMM77/qJFi6qM2bp1q4VZAbASdQ/4J850AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWKSOtxO4HB25uYnbMQumvmJqW1t+vMpUXN2AClNx07cMNBX3crflbsdkDRlkaluAN3w96HW3Y3r++x5T22pa77SpuKLXzP33YvTzK03FvbR4qNsxp6/6ydS2AAAAvIUz3QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAPBhmZmZioyMVHBwsOLi4rRp06YLzp8zZ47at2+vevXqKSIiQuPHj9ePP/7ooWwB1ATqHvAvNN0AAPio7OxspaamKi0tTVu2bFGXLl2UmJioI0eOVDl/yZIlmjRpktLS0rRr1y7Nnz9f2dnZevrppz2cOQCzqHvA/9B0AwDgozIyMjRmzBglJyfr+uuvV1ZWlurXr68FCxZUOf/TTz/VLbfcovvuu0+RkZG64447NHz48IueJQPgO6h7wP/QdAMA4IPKy8u1efNmJSQkOMdsNpsSEhKUn59fZUz37t21efNm55ftffv2ac2aNerfv3+V88vKylRSUuKyAPAeT9S9RO0DnlbH2wkAAIDKjh07poqKCoWFhbmMh4WFaffu3VXG3HfffTp27JhuvfVWGYahn376SQ8//PB5LzNNT0/X9OnTazx3AOZ4ou4lah/wNM50AwDgJ/Ly8jRr1izNnTtXW7Zs0fvvv6/Vq1dr5syZVc6fPHmyiouLncuhQ4c8nDGAS+Vu3UvUPuBpnOkGAMAHNWvWTIGBgSosLHQZLywsVHh4eJUxU6dO1ciRIzV69GhJUufOnVVaWqqxY8fqmWeekc3m+m/tdrtddrvdmh0A4DZP1L1E7QOe5ldN9w83NDYVN376u6biOgd9byqugc3hdkzrwPqmttWxboGpuKh3HjMVF/RDgKm4p794wO2Yq3Tc1LbgX/YP/pOpuJu23GMq7vg3TUzFxT7/uNsxjfadNbWtUsPcfwsbnjhtKm55YpypuEjbYbdjdk4Mu/gkPxEUFKSYmBjl5uZqyJAhkiSHw6Hc3FylpKRUGXP69OlKX7ADAwMlSYZhWJovgEtH3QP+ya+abgAA/ElqaqqSkpLUrVs3xcbGas6cOSotLVVycrIkadSoUWrdurXS09MlSYMGDVJGRoa6du2quLg47d27V1OnTtWgQYOcX8IB+DbqHvA/NN0AAPioYcOG6ejRo5o2bZoKCgoUHR2tnJwc502WDh486HKGa8qUKQoICNCUKVN0+PBhNW/eXIMGDdLzzz/vrV0A4CbqHvA/NN0AAPiwlJSU815WmpeX5/K6Tp06SktLU1pamgcyA2AV6h7wL9y9HAAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgkTreTqAmhbz7T1NxM68cYSru1PVlpuK2/eaPbsfcPOUxU9v6sVmAqbhr1xw3FQd4WrsVvzMV1+QLc//maI8wV1MtNxx1P+j7I6a2dWJAB1NxB+4y+++w9UzGAQAA+D/OdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWqePtBGpSYMf2puJavfSpqbizCTGm4ur+JtDtmHGTlpna1ju/TTAVB9QWRpBhKu5EF4epuOWDXjMVN2XFKLdjyrpdY2pbhT3M7RsAAABqHme6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAPiwzMxMRUZGKjg4WHFxcdq0adMF5xcVFemxxx5Ty5YtZbfbdd1112nNmjUeyhZATaDuAf/iVzdSAwDAn2RnZys1NVVZWVmKi4vTnDlzlJiYqK+++kotWrSoNL+8vFy/+c1v1KJFC61YsUKtW7fWt99+q0aNGnk+eQCmUPeA/6HpBgDAR2VkZGjMmDFKTk6WJGVlZWn16tVasGCBJk2aVGn+ggULdOLECX366aeqW7euJCkyMtKTKQO4RNQ94H+4vBwAAB9UXl6uzZs3KyHhv49+tNlsSkhIUH5+fpUxH3zwgeLj4/XYY48pLCxMnTp10qxZs1RRUVHl/LKyMpWUlLgsALzHE3UvUfuAp9F0AwDgg44dO6aKigqFhYW5jIeFhamgoKDKmH379mnFihWqqKjQmjVrNHXqVP3hD3/Qc889V+X89PR0hYaGOpeIiIga3w8A1eeJupeofcDTaLoBAPATDodDLVq00J/+9CfFxMRo2LBheuaZZ5SVlVXl/MmTJ6u4uNi5HDp0yMMZA7hU7ta9RO0DnsZvugEA8EHNmjVTYGCgCgsLXcYLCwsVHh5eZUzLli1Vt25dBQYGOsc6dOiggoIClZeXKygoyGW+3W6X3W6v+eQBmOKJupeofcDTONMNAIAPCgoKUkxMjHJzc51jDodDubm5io+PrzLmlltu0d69e+VwOJxjX3/9tVq2bFnlF28AvoW6B/wTTTcAAD4qNTVV8+bN01tvvaVdu3bpkUceUWlpqfOuxqNGjdLkyZOd8x955BGdOHFCTzzxhL7++mutXr1as2bN0mOPPeatXQDgJuoe8D9cXg4AgI8aNmyYjh49qmnTpqmgoEDR0dHKyclx3mTp4MGDstn+++/nERERWrt2rcaPH68bbrhBrVu31hNPPKGJEyd6axcAuIm6B/xPgGEYRnUm9u08xepcap2KL78yFVfwRHe3Y157Yq6pbR0629RU3Du/Tbj4pMtMzvbz3wXUX7X500veTsHnBJQHmAsMPet2yBVbg01tqumOMlNx+4cGXnzSZebbsf/r7RQ8qqSkRKGhoSouLlZISIi30wE86nL+/F/O+w544vPP5eUAAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALFLH2wnUZoEd25uKC3/1U7djHgt61NS2to+fayou8P11puIW//YOU3FAbWEEGabiAorruh/jMLUplYea+0/71UvPmor75l7+rwQAAOB8ONMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWKSOtxO4HAV2bO92TKuXPjW1re4HHzYV91HGXFNxFe//3VTcO79NMBUH1BZGkOF2TMk1Faa2lZj8mam4f06NNRXXdoW5PPcPDTQVBwAAUJtwphsAAAAAAIvQdAMAAAAAYBGabgAAfFhmZqYiIyMVHBysuLg4bdq0qVpxS5cuVUBAgIYMGWJtggBqHHUP+BeabgAAfFR2drZSU1OVlpamLVu2qEuXLkpMTNSRI0cuGHfgwAFNmDBBPXr08FCmAGoKdQ/4H5puAAB8VEZGhsaMGaPk5GRdf/31ysrKUv369bVgwYLzxlRUVGjEiBGaPn262rVr58FsAdQE6h7wPzTdAAD4oPLycm3evFkJCf99uoPNZlNCQoLy8/PPGzdjxgy1aNFCDz300EW3UVZWppKSEpcFgPd4ou4lah/wNJpuAAB80LFjx1RRUaGwsDCX8bCwMBUUFFQZ8/HHH2v+/PmaN29etbaRnp6u0NBQ5xIREXHJeQMwzxN1L1H7gKfRdAMA4AdOnjypkSNHat68eWrWrFm1YiZPnqzi4mLncujQIYuzBFCTzNS9RO0DnlbH2wkAAIDKmjVrpsDAQBUWFrqMFxYWKjw8vNL8b775RgcOHNCgQYOcYw6HQ5JUp04dffXVV7r66qtdYux2u+x2uwXZAzDDE3UvUfuAp3GmGwAAHxQUFKSYmBjl5uY6xxwOh3JzcxUfH19pflRUlLZv365t27Y5l8GDB6tPnz7atm0bl48CtQB1D/gnznQDAOCjUlNTlZSUpG7duik2NlZz5sxRaWmpkpOTJUmjRo1S69atlZ6eruDgYHXq1MklvlGjRpJUaRyA76LuAf9D0w0AgI8aNmyYjh49qmnTpqmgoEDR0dHKyclx3mTp4MGDstm4aA3wJ9Q94H9ougEA8GEpKSlKSUmp8r28vLwLxi5atKjmEwJgOeoe8C803V7wn9uauh3zwLIiU9sadsXLpuKOVJgK00uZw0zFtdJxcxsEaoltA191O+a2rUmmtpWbWfl3f9UR9uV/TMUZgWbPuDQ3GQcAAFB7cG0KAAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYJE63k7AFxwc2NRUXM+hW0zFLWv5ltsxZw2HqW3dkvWUqbigk6bC1Cr3uLlAwMM+6p9hKi714J2m4vqPH+d2TNjWI6a2ZRTuMBcX1sxU3K4JzU3FAQAAXA440w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYpI63Ezif7/o2dTvm3qRcU9t6rMk2U3H1A4JMxV3319+7HRP6pbm/qsh/HDcVB3jDZwNecTvmgb13m9rWsCefNBUXfPwnU3EN//GZ+0HXXW1qW7tf6mAqDr4pMzNTL730kgoKCtSlSxe99tprio2NrXLuvHnztHjxYu3YsUOSFBMTo1mzZp13PgDfRN0D/oUz3QAA+Kjs7GylpqYqLS1NW7ZsUZcuXZSYmKgjR45UOT8vL0/Dhw/Xhg0blJ+fr4iICN1xxx06fPiwhzMHYBZ1D/gfmm4AAHxURkaGxowZo+TkZF1//fXKyspS/fr1tWDBgirnv/POO3r00UcVHR2tqKgovfnmm3I4HMrNNXclGADPo+4B/0PTDQCADyovL9fmzZuVkJDgHLPZbEpISFB+fn611nH69GmdPXtWTZo0sSpNADWIugf8k8/+phsAgMvZsWPHVFFRobCwMJfxsLAw7d69u1rrmDhxolq1auXyBf6XysrKVFZW5nxdUlJiPmEAl8wTdS9R+4CncaYbAAA/NHv2bC1dulQrV65UcHBwlXPS09MVGhrqXCIiIjycJYCaVJ26l6h9wNNougEA8EHNmjVTYGCgCgsLXcYLCwsVHh5+wdiXX35Zs2fP1rp163TDDTecd97kyZNVXFzsXA4dOlQjuQMwxxN1L1H7gKfRdAMA4IOCgoIUExPjcjOkczdHio+PP2/ciy++qJkzZyonJ0fdunW74DbsdrtCQkJcFgDe44m6l6h9wNP4TTcAAD4qNTVVSUlJ6tatm2JjYzVnzhyVlpYqOTlZkjRq1Ci1bt1a6enpkqQXXnhB06ZN05IlSxQZGamCggJJUsOGDdWwYUOv7QeA6qPuAf9D0w0AgI8aNmyYjh49qmnTpqmgoEDR0dHKyclx3mTp4MGDstn+e9Ha66+/rvLycg0dOtRlPWlpaXr22Wc9mToAk6h7wP/QdAMA4MNSUlKUkpJS5Xt5eXkurw8cOGB9QgAsR90D/oXfdAMAAAAAYBGabgAAAAAALOKzl5dHvPed2zEfFPYxta336t9mKq7CHmAqrsM/jpuKA/zd0MfHux3TYP2XprbVqFmgqTjDHmQqbldWrKk4AAAA1G6c6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsUsfbCZyP0aCe2zFNtv5gQSYAPOVQXxNBfTvWeB4AAABATeFMNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAODDMjMzFRkZqeDgYMXFxWnTpk0XnL98+XJFRUUpODhYnTt31po1azyUKYCaQt0D/qVOdSfmbH/OyjwA+KBvx/6vt1MALmvZ2dlKTU1VVlaW4uLiNGfOHCUmJuqrr75SixYtKs3/9NNPNXz4cKWnp2vgwIFasmSJhgwZoi1btqhTp05e2AMA7qLuAf8TYBiG4e0kAABAZXFxcbrpppv0xz/+UZLkcDgUERGhxx9/XJMmTao0f9iwYSotLdWHH37oHLv55psVHR2trKysi26vpKREoaGhKi4uVkhISM3tCFAL+Mrn39N1L/nOvgPe4InPf7XPdAMAAM8pLy/X5s2bNXnyZOeYzWZTQkKC8vPzq4zJz89Xamqqy1hiYqJWrVpV5fyysjKVlZU5XxcXF0v6+QsIcLk597n35vkoT9S9RO0Dv+SJ2qfpBgDABx07dkwVFRUKCwtzGQ8LC9Pu3burjCkoKKhyfkFBQZXz09PTNX369ErjERERJrMGar/jx48rNDTUK9v2RN1L1D5QFStrn6YbAIDL1OTJk13OkBUVFalNmzY6ePCg15qOS1FSUqKIiAgdOnSoVl4iS/7eVVxcrKuuukpNmjTxdiqWo/Z9C/l7lydqn6YbAAAf1KxZMwUGBqqwsNBlvLCwUOHh4VXGhIeHuzXfbrfLbrdXGg8NDa2VX5zOCQkJIX8vqu3522zee7iPJ+peovZ9Ffl7l5W1zyPDAADwQUFBQYqJiVFubq5zzOFwKDc3V/Hx8VXGxMfHu8yXpPXr1593PgDfQt0D/okz3QAA+KjU1FQlJSWpW7duio2N1Zw5c1RaWqrk5GRJ0qhRo9S6dWulp6dLkp544gn16tVLf/jDHzRgwAAtXbpUn3/+uf70pz95czcAuIG6B/wPTTcAAD5q2LBhOnr0qKZNm6aCggJFR0crJyfHedOkgwcPulwO1717dy1ZskRTpkzR008/rWuvvVarVq2q9rN67Xa70tLSqrzstDYgf+8i/5rh6bqXfGffzSJ/7yL/i+M53QAAAAAAWITfdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAB+LDMzU5GRkQoODlZcXJw2bdp0wfnLly9XVFSUgoOD1blzZ61Zs8blfcMwNG3aNLVs2VL16tVTQkKC9uzZ4xP5z5s3Tz169FDjxo3VuHFjJSQkVJr/wAMPKCAgwGXp27evT+S/aNGiSrkFBwe7zPHl49+7d+9K+QcEBGjAgAHOOZ48/hs3btSgQYPUqlUrBQQEaNWqVReNycvL04033ii73a5rrrlGixYtqjTH3ZryBuqeuvdU/tR9NRkAAMAvLV261AgKCjIWLFhgfPnll8aYMWOMRo0aGYWFhVXO/+STT4zAwEDjxRdfNHbu3GlMmTLFqFu3rrF9+3bnnNmzZxuhoaHGqlWrjC+++MIYPHiw0bZtW+PMmTNez/++++4zMjMzja1btxq7du0yHnjgASM0NNT47rvvnHOSkpKMvn37Gt9//71zOXHiRI3nbib/hQsXGiEhIS65FRQUuMzx5eN//Phxl9x37NhhBAYGGgsXLnTO8eTxX7NmjfHMM88Y77//viHJWLly5QXn79u3z6hfv76Rmppq7Ny503jttdeMwMBAIycnxznH3WPiDdQ9de/J/Kn76qHpBgDAT8XGxhqPPfaY83VFRYXRqlUrIz09vcr599xzjzFgwACXsbi4OON3v/udYRiG4XA4jPDwcOOll15yvl9UVGTY7Xbj3Xff9Xr+v/bTTz8ZV1xxhfHWW285x5KSkow777yzplOtkrv5L1y40AgNDT3v+mrb8X/llVeMK664wjh16pRzzJPH/5eq8+X7qaeeMjp27OgyNmzYMCMxMdH5+lKPiSdQ99T9paDural7Li8HAMAPlZeXa/PmzUpISHCO2Ww2JSQkKD8/v8qY/Px8l/mSlJiY6Jy/f/9+FRQUuMwJDQ1VXFzcedfpyfx/7fTp0zp79qyaNGniMp6Xl6cWLVqoffv2euSRR3T8+PEazV0yn/+pU6fUpk0bRURE6M4779SXX37pfK+2Hf/58+fr3nvvVYMGDVzGPXH8zbjY578mjonVqHvq3hv5/xJ1XzWabgAA/NCxY8dUUVGhsLAwl/GwsDAVFBRUGVNQUHDB+ef+1511mmUm/1+bOHGiWrVq5fJlqW/fvlq8eLFyc3P1wgsv6P/+7//Ur18/VVRUeD3/9u3ba8GCBfrLX/6iP//5z3I4HOrevbu+++47SbXr+G/atEk7duzQ6NGjXcY9dfzNON/nv6SkRGfOnKmRz6TVqHvq3tP5/xJ1f351aiRbAAAAHzJ79mwtXbpUeXl5Ljcluvfee51/7ty5s2644QZdffXVysvL0+233+6NVJ3i4+MVHx/vfN29e3d16NBBb7zxhmbOnOnFzNw3f/58de7cWbGxsS7jvnz8UftR995F3Z8fZ7oBAPBDzZo1U2BgoAoLC13GCwsLFR4eXmVMeHj4Beef+1931mmWmfzPefnllzV79mytW7dON9xwwwXntmvXTs2aNdPevXsvOedfupT8z6lbt666du3qzK22HP/S0lItXbpUDz300EW3Y9XxN+N8n/+QkBDVq1evRv5OrUbdU/eXgrr/mRV1T9MNAIAfCgoKUkxMjHJzc51jDodDubm5LmdVfik+Pt5lviStX7/eOb9t27YKDw93mVNSUqLPPvvsvOv0ZP6S9OKLL2rmzJnKyclRt27dLrqd7777TsePH1fLli1rJO9zzOb/SxUVFdq+fbszt9pw/KWfHz9VVlam+++//6Lbser4m3Gxz39N/J1ajbqn7r2VP3V/EdW+5RoAAKhVli5datjtdmPRokXGzp07jbFjxxqNGjVyPo5m5MiRxqRJk5zzP/nkE6NOnTrGyy+/bOzatctIS0ur8tFBjRo1Mv7yl78Y//73v40777zT0kfXuJP/7NmzjaCgIGPFihUuj6Y5efKkYRiGcfLkSWPChAlGfn6+sX//fuPvf/+7ceONNxrXXnut8eOPP3o9/+nTpxtr1641vvnmG2Pz5s3GvffeawQHBxtffvmlyz766vE/59ZbbzWGDRtWadzTx//kyZPG1q1bja1btxqSjIyMDGPr1q3Gt99+axiGYUyaNMkYOXKkc/65Rwf97//+r7Fr1y4jMzOzykcHXeiY+ALqnrr3ZP7nUPcXRtMNAIAfe+2114yrrrrKCAoKMmJjY41//vOfzvd69eplJCUlucxftmyZcd111xlBQUFGx44djdWrV7u873A4jKlTpxphYWGG3W43br/9duOrr77yifzbtGljSKq0pKWlGYZhGKdPnzbuuOMOo3nz5kbdunWNNm3aGGPGjLG0YXIn/3HjxjnnhoWFGf379ze2bNnisj5fPv6GYRi7d+82JBnr1q2rtC5PH/8NGzZU+Xk4l3NSUpLRq1evSjHR0dFGUFCQ0a5dO5dnDZ9zoWPiK6h76t5T+RsGdV8dAYZhGG6dgwcAAAAAANXCb7oBAAAAALAITTcAAAAAABah6QYAAAAAwCI03ZIWLVqkgIAAff75595OxbTIyEgNHDjQ22nUmMjISD3wwAPeTgN+jLr3PdQ9AADwRx5vus990f3l0qJFC/Xp00d/+9vfTK931qxZWrVqVc0l6obc3Fw9+OCDuu6661S/fn21a9dOo0eP1vfff3/J6y4sLNSECRMUFRWl+vXrq0GDBoqJidFzzz2noqKiS0++lsvOztb999+va6+9VgEBAerdu7e3U0IVqHv3UPfnd/z4cb300kvq2bOnmjdvrkaNGunmm29Wdna2t1MDAACoUh1vbXjGjBlq27atDMNQYWGhFi1apP79++uvf/2rqTM3s2bN0tChQzVkyJCaT/YiJk6cqBMnTujuu+/Wtddeq3379umPf/yjPvzwQ23btk3h4eGm1vuvf/1L/fv316lTp3T//fcrJiZGkvT5559r9uzZ2rhxo9atW1eTu1LrvP7669q8ebNuuukmHT9+3Nvp4CKo+4uj7i8sPz9fzzzzjPr3768pU6aoTp06eu+993Tvvfdq586dmj59urdTBAAAcOG1prtfv37q1q2b8/VDDz2ksLAwvfvuu7XucsmMjAzdeuutstn+e+FA37591atXL/3xj3/Uc8895/Y6i4qKdNdddykwMFBbt25VVFSUy/vPP/+85s2bd8m513Zvv/22WrduLZvNpk6dOnk7HVwEdX9h1P3FdezYUXv27FGbNm2cY48++qgSEhL0wgsv6KmnnlKDBg28mCEAAIArn/lNd6NGjVSvXj3VqeP67wAvv/yyunfvrqZNm6pevXqKiYnRihUrXOYEBASotLRUb731lvPS1V/+LvDw4cN66KGH1KpVK9ntdrVt21aPPPKIysvLXdZTVlam1NRUNW/eXA0aNNBdd92lo0ePXjT3nj17unzxPjfWpEkT7dq1y80j8bM33nhDhw8fVkZGRqUv3pIUFhamKVOmVBr/+OOPFRsbq+DgYLVr106LFy92ef/EiROaMGGCOnfurIYNGyokJET9+vXTF1984TIvLy9PAQEBWrZsmZ5//nldeeWVCg4O1u233669e/e6zO3du7c6deqknTt3qk+fPqpfv75at26tF198sVJ+ZWVlSktL0zXXXCO73a6IiAg99dRTKisrM3OYFBERUenYo/ag7l1R9xfXtm1bl4Zb+vmzMGTIEJWVlWnfvn1urxMAAMBKXjvTXVxcrGPHjskwDB05ckSvvfaa83LKX3r11Vc1ePBgjRgxQuXl5Vq6dKnuvvtuffjhhxowYICkn892jh49WrGxsRo7dqwk6eqrr5Yk/ec//1FsbKyKioo0duxYRUVF6fDhw1qxYoVOnz6toKAg57Yef/xxNW7cWGlpaTpw4IDmzJmjlJQUU78VPHXqlE6dOqVmzZqZOj4ffPCB6tWrp6FDh1Y7Zu/evRo6dKgeeughJSUlacGCBXrggQcUExOjjh07SpL27dunVatW6e6771bbtm1VWFioN954Q7169dLOnTvVqlUrl3XOnj1bNptNEyZMUHFxsV588UWNGDFCn332mcu8H374QX379tVvf/tb3XPPPVqxYoUmTpyozp07q1+/fpIkh8OhwYMH6+OPP9bYsWPVoUMHbd++Xa+88oq+/vprr/02F55D3V8YdW9eQUGBJJk+9gAAAJYxPGzhwoWGpEqL3W43Fi1aVGn+6dOnXV6Xl5cbnTp1Mm677TaX8QYNGhhJSUmV4keNGmXYbDbjX//6V6X3HA6HS04JCQnOMcMwjPHjxxuBgYFGUVGR2/s5c+ZMQ5KRm5vrdqxhGEbjxo2NLl26VHt+mzZtDEnGxo0bnWNHjhwx7Ha78eSTTzrHfvzxR6OiosIldv/+/YbdbjdmzJjhHNuwYYMhyejQoYNRVlbmHH/11VcNScb27dudY7169TIkGYsXL3aOlZWVGeHh4cb//M//OMfefvttw2azGR999JHL9rOysgxJxieffOKyP1X9fV5Ix44djV69erkVA8+g7quHune/7g3DMI4fP260aNHC6NGjh9uxAAAAVvPadbmZmZlav3691q9frz//+c/q06ePRo8erffff99lXr169Zx//uGHH1RcXKwePXpoy5YtF92Gw+HQqlWrNGjQIJffkZ4TEBDg8nrs2LEuYz169FBFRYW+/fZbt/Zt48aNmj59uu655x7ddtttbsWeU1JSoiuuuMKtmOuvv149evRwvm7evLnat2/vcrml3W53XhJbUVGh48ePq2HDhmrfvn2VxzQ5OdnlrOC59f/6Es6GDRu6nK0MCgpSbGysy7zly5erQ4cOioqK0rFjx5zLuWO0YcMGt/YXtQ91f2HUvfscDodGjBihoqIivfbaa5e0LgAAACt47fLy2NhYly/Ew4cPV9euXZWSkqKBAwc6v/B9+OGHeu6557Rt2zaX3//9+otzVY4ePaqSkpJq32DrqquucnnduHFjST9/6a+u3bt366677lKnTp305ptvVjvu10JCQnTy5Em3Yn6dv/TzPvwyf4fDoVdffVVz587V/v37VVFR4XyvadOmF13n+Y7JlVdeWenvpHHjxvr3v//tfL1nzx7t2rVLzZs3rzL/I0eOnG/X4Ceo+wuj7t33+OOPKycnR4sXL1aXLl0uaV0AAABW8FrT/Ws2m019+vTRq6++qj179qhjx4766KOPNHjwYPXs2VNz585Vy5YtVbduXS1cuFBLliyp8RwCAwOrHDcMo1rxhw4d0h133KHQ0FCtWbPG7TNWvxQVFaVt27apvLzc5YzThVQn/1mzZmnq1Kl68MEHNXPmTDVp0kQ2m03jxo2Tw+Ewtc7qznM4HOrcubMyMjKqnBsREVHlOPwXde+KunfP9OnTNXfuXM2ePVsjR440vR4AAAAr+UzTLUk//fSTpJ9vRiRJ7733noKDg7V27VrZ7XbnvIULF1aKreoMWPPmzRUSEqIdO3ZYlPF/HT9+XHfccYfKysqUm5urli1bXtL6Bg0apPz8fL333nsaPnx4DWUprVixQn369NH8+fNdxouKiiy/AdHVV1+tL774Qrfffnu1zlji8kDd/xd1X32ZmZl69tlnNW7cOE2cOLHG1gsAAFDTfOZZS2fPntW6desUFBSkDh06SPr5LEpAQIDLpZAHDhyo8m63DRo0UFFRkcuYzWbTkCFD9Ne//lWff/55pZjqnsm6mNLSUvXv31+HDx/WmjVrdO21117yOh9++GG1bNlSTz75pL7++utK7x85csTUc4ADAwMr7ffy5ct1+PBh07lW1z333KPDhw9X+ZzhM2fOqLS01PIc4Fuoe1fUffVkZ2fr97//vUaMGHHeM+gAAAC+wmtnuv/2t79p9+7dkn7+IrlkyRLt2bNHkyZNUkhIiCRpwIABysjIUN++fXXffffpyJEjyszM1DXXXOPym0FJiomJ0d///ndlZGSoVatWatu2reLi4jRr1iytW7dOvXr1cj6u5vvvv9fy5cv18ccfq1GjRpe8LyNGjNCmTZv04IMPateuXS7P6G3YsKGGDBnifP3ss89q+vTp2rBhg3r37n3edTZu3FgrV65U//79FR0drfvvv18xMTGSpC1btujdd99VfHy827kOHDhQM2bMUHJysrp3767t27frnXfeUbt27dxel7tGjhypZcuW6eGHH9aGDRt0yy23qKKiQrt379ayZcu0du3aKm98dSEbN27Uxo0bJf38W97S0lJnU9KzZ0/17NmzxvcD5lH31P2l1v2mTZs0atQoNW3aVLfffrveeecdl/e7d+/ukf0CAACoLq813dOmTXP+OTg4WFFRUXr99df1u9/9zjl+2223af78+Zo9e7bGjRuntm3b6oUXXtCBAwcqffnOyMjQ2LFjNWXKFJ05c0ZJSUmKi4tT69at9dlnn2nq1Kl65513VFJSotatW6tfv36qX79+jezLtm3bJEkLFizQggULXN5r06aNy5fvU6dOKSAgQOHh4Rddb1xcnHbs2KGXXnpJq1ev1ttvvy2bzaYOHTpo0qRJSklJcTvXp59+WqWlpVqyZImys7N14403avXq1Zo0aZLb63KXzWbTqlWr9Morr2jx4sVauXKl6tevr3bt2umJJ57Qdddd5/Y6//GPf2j69OkuY1OnTpUkpaWl0XT7GOqeur/Uut+5c6fKy8t19OhRPfjgg5XeX7hwIU03AADwKQFGTV1riWqJjY1VmzZttHz5cm+nAsBDqHsAAIDLl8/8pvtyUFJSoi+++EIzZszwdioAPIS6h1kbN27UoEGD1KpVKwUEBFR5X4Nfy8vL04033ii73a5rrrlGixYtsjxPADWHugf8E023B4WEhKisrMx5wygA/o+6h1mlpaXq0qWLMjMzqzV///79GjBggPr06aNt27Zp3LhxGj16tNauXWtxpgBqCnUP+CcuLwcAwMcFBARo5cqVLvcK+LWJEydq9erVLo/Lu/fee1VUVKScnBwPZAmgJlH3gP/wqed0AwAAc/Lz85WQkOAylpiYqHHjxp03pqysTGVlZc7XDodDJ06cUNOmTWv0uepAbWAYhk6ePKlWrVrJZqsdF4OaqXuJ2gd+yRO1T9MNAIAfKCgoUFhYmMtYWFiYSkpKdObMGdWrV69STHp6eqUnQACXu0OHDunKK6/0dhrVYqbuJWofqIqVtU/TDQDAZWry5MlKTU11vi4uLtZVV12lQ4cOKSQkxIuZAZ5XUlKiiIgIXXHFFd5OxXLUPvBfnqh9mm4AAPxAeHi4CgsLXcYKCwsVEhJy3rNddrtddru90nhISAhfvHHZqk2XV5upe4naB6piZe1Xu+nu2/Fpy5IAaoOcL2d5OwWPu3b5TG+nAHjVnrunejuFaouPj9eaNWtcxtavX6/4+HgvZQTAatQ9UDvUjrtEAABwmTl16pS2bdumbdu2Sfr50UDbtm3TwYMHJf18eeioUaOc8x9++GHt27dPTz31lHbv3q25c+dq2bJlGj9+vDfSB2ACdQ/4J5puAAB80Oeff66uXbuqa9eukqTU1FR17dpV06ZNkyR9//33zi/iktS2bVutXr1a69evV5cuXfSHP/xBb775phITE72SPwD3UfeAf+I33QAA+KDevXvLMIzzvr9o0aIqY7Zu3WphVgCsRN0D/okz3QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABap4+0EUD1Hbm1mKm75lJdMxdUNMBWmsYnJ5gIBVLLz1kWm4josfqxmE7mIgHalHt0eAABAbcKZbgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAPiwzMxMRUZGKjg4WHFxcdq0adMF58+ZM0ft27dXvXr1FBERofHjx+vHH3/0ULYAagJ1D/gXmm4AAHxUdna2UlNTlZaWpi1btqhLly5KTEzUkSNHqpy/ZMkSTZo0SWlpadq1a5fmz5+v7OxsPf300x7OHIBZ1D3gf2i6AQDwURkZGRozZoySk5N1/fXXKysrS/Xr19eCBQuqnP/pp5/qlltu0X333afIyEjdcccdGj58+EXPkgHwHdQ94H9ougEA8EHl5eXavHmzEhISnGM2m00JCQnKz8+vMqZ79+7avHmz88v2vn37tGbNGvXv37/K+WVlZSopKXFZAHiPJ+peovYBT6vj7QQAAEBlx44dU0VFhcLCwlzGw8LCtHv37ipj7rvvPh07dky33nqrDMPQTz/9pIcffvi8l5mmp6dr+vTpNZ47AHM8UfcStQ94Gme6AQDwE3l5eZo1a5bmzp2rLVu26P3339fq1as1c+bMKudPnjxZxcXFzuXQoUMezhjApXK37iVqH/A0znQDAOCDmjVrpsDAQBUWFrqMFxYWKjw8vMqYqVOnauTIkRo9erQkqXPnziotLdXYsWP1zDPPyGZz/bd2u90uu91uzQ4AcJsn6l6i9gFPo+m+BEVdmpqKO9PM/QsMPpqUYWpbZv+KuywfZyru//11kam4zEGDTMUBnrbj1oWm4hxyuB3T9Q9PmNpWi4MVpuL+M/AnU3H1tjU0FfdT9ClTcZeLoKAgxcTEKDc3V0OGDJEkORwO5ebmKiUlpcqY06dPV/qCHRgYKEkyDMPSfAFcOuoe8E803QAA+KjU1FQlJSWpW7duio2N1Zw5c1RaWqrk5GRJ0qhRo9S6dWulp6dLkgYNGqSMjAx17dpVcXFx2rt3r6ZOnapBgwY5v4QD8G3UPeB/aLoBAPBRw4YN09GjRzVt2jQVFBQoOjpaOTk5zpssHTx40OUM15QpUxQQEKApU6bo8OHDat68uQYNGqTnn3/eW7sAwE3UPeB/aLoBAPBhKSkp572sNC8vz+V1nTp1lJaWprS0NA9kBsAq1D3gX7h7OQAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAInW8nUBtVt4gwFTc1qfnuh0z8Ou7TG3rvWs/MBXX9oNyU3G33v2DqbhMU1GA5znkMBV38/NPuB3T7OsyU9s61TrIVFzAD3VNxTXfdtZU3PfRpsIAAABqFc50AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABap4+0EfEFhz2am4v5v6ium4iYW3ux2zNne35va1s0pT5iKa1lw1FRcqK2eqbgH/rLO7ZhFd95haluAJO24daGpuPhnf28qrsX2U27H7Blprp5a/cNhKq5OqzOm4orbNjQV13KR+zHfP1BmalsAAADewpluAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAD4sMzNTkZGRCg4OVlxcnDZt2nTB+UVFRXrsscfUsmVL2e12XXfddVqzZo2HsgVQE6h7wL9wIzUAAHxUdna2UlNTlZWVpbi4OM2ZM0eJiYn66quv1KJFi0rzy8vL9Zvf/EYtWrTQihUr1Lp1a3377bdq1KiR55MHYAp1D/gfmm4AAHxURkaGxowZo+TkZElSVlaWVq9erQULFmjSpEmV5i9YsEAnTpzQp59+qrp160qSIiMjPZkygEtE3QP+h8vLAQDwQeXl5dq8ebMSEhKcYzabTQkJCcrPz68y5oMPPlB8fLwee+wxhYWFqVOnTpo1a5YqKio8lTaAS0DdA/6JM90AAPigY8eOqaKiQmFhYS7jYWFh2r17d5Ux+/bt0z/+8Q+NGDFCa9as0d69e/Xoo4/q7NmzSktLqzS/rKxMZWX/ffZ5SUlJze4EALd4ou4lah/wNM50AwDgJxwOh1q0aKE//elPiomJ0bBhw/TMM88oKyuryvnp6ekKDQ11LhERER7OGMClcrfuJWof8DSabgAAfFCzZs0UGBiowsJCl/HCwkKFh4dXGdOyZUtdd911CgwMdI516NBBBQUFKi8vrzR/8uTJKi4udi6HDh2q2Z0A4BZP1L1E7QOeRtMNAIAPCgoKUkxMjHJzc51jDodDubm5io+PrzLmlltu0d69e+VwOJxjX3/9tVq2bKmgoKBK8+12u0JCQlwWAN7jibqXqH3A02i6AQDwUampqZo3b57eeust7dq1S4888ohKS0uddzUeNWqUJk+e7Jz/yCOP6MSJE3riiSf09ddfa/Xq1Zo1a5Yee+wxb+0CADdR94D/4UZqAAD4qGHDhuno0aOaNm2aCgoKFB0drZycHOdNlg4ePCib7b//fh4REaG1a9dq/PjxuuGGG9S6dWs98cQTmjhxord2AYCbqHvA/wQYhmFUZ2Lfjk9bncslK+rS1FTcey++bCru9j89ZSquzQcn3I4JOFs7HvuwJne5qbhjFaVux4y64wFT2zIr58tZHt2eL7h2+Uxvp3BRX/VYbCquw58eNRXXYvNPpuJONwu8+KRfKenrfl14Q4O8Bqbimr9e9eNvLuRA9g2mtmXWnrunenR73lZSUqLQ0FAVFxdzuSkuO5fz5/9y3nfAE59/Li8HAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYJE63k6gJp1pZu7fECpMbi/yvaMmI/3XWcPc0Rx3aEANZ4LLxZGKUlNxkStOmIrbNzXIVBwqC7ymrbdTAAAAsBxnugEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL1PF2AjWpIshc3EmH//7bQ1GXpqbijtxkbnsLSyJMxX255Hq3Y1rqqKltwb9knog1FWd8tc/kFqNMxnnOjlsXmorbWu4wFffss/eZijvZuYWJqDOmtgUAAOAt/tttAgAAAADgZTTdAAAAAABYhKYbAAAflpmZqcjISAUHBysuLk6bNm2qVtzSpUsVEBCgIUOGWJsggBpH3QP+haYbAAAflZ2drdTUVKWlpWnLli3q0qWLEhMTdeTIkQvGHThwQBMmTFCPHj08lCmAmkLdA/6HphsAAB+VkZGhMWPGKDk5Wddff72ysrJUv359LViw4LwxFRUVGjFihKZPn6527dp5MFsANYG6B/wPTTcAAD6ovLxcmzdvVkJCgnPMZrMpISFB+fn5542bMWOGWrRooYceeuii2ygrK1NJSYnLAsB7PFH3ErUPeBpNNwAAPujYsWOqqKhQWFiYy3hYWJgKCgqqjPn44481f/58zZs3r1rbSE9PV2hoqHOJiDD32EcANcMTdS9R+4Cn0XQDAOAHTp48qZEjR2revHlq1qxZtWImT56s4uJi53Lo0CGLswRQk8zUvUTtA55Wx9sJAACAypo1a6bAwEAVFha6jBcWFio8PLzS/G+++UYHDhzQoEGDnGMOh0OSVKdOHX311Ve6+uqrXWLsdrvsdrsF2QMwwxN1L1H7gKdxphsAAB8UFBSkmJgY5ebmOsccDodyc3MVHx9faX5UVJS2b9+ubdu2OZfBgwerT58+2rZtG5ePArUAdQ/4J850AwDgo1JTU5WUlKRu3bopNjZWc+bMUWlpqZKTkyVJo0aNUuvWrZWenq7g4GB16tTJJb5Ro0aSVGkcgO+i7gH/Q9MNAICPGjZsmI4ePapp06apoKBA0dHRysnJcd5k6eDBg7LZuGgN8CfUPeB/aLoBAPBhKSkpSklJqfK9vLy8C8YuWrSo5hMCYDnqHvAv/tV0B5gLO+EIrtk8LFDUpampuN9PzzYVN3NHf1Nxq357i6m4ljpqKg4wy9amtbdTuKgdty40FXf7jqGm4hqmBpmK++ZZszfjOWMyDgAAoPbg2hQAAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAInW8nUCNMsyF3RJs7t8eZv/tbVNxgSYSvcJWYWpbvfN+byoudFOwqTjpqMk4wLO+G9zSVFxAwElTcT/9FOh2TM8Jj5naVqNdJabiTl53hak46YzJOAAAAP/HmW4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAInW8nUBNapnxqam4qJtHmorbfevbpuLafjjG7ZhG/65raltRuUdNxUknTcYBnrV4y82m4gLaOEzFNdrQ0FRcs22n3Y45E26Y2ta+yWb/037GZByslJmZqZdeekkFBQXq0qWLXnvtNcXGxlY5d968eVq8eLF27NghSYqJidGsWbPOOx+Ab6LuAf/CmW4AAHxUdna2UlNTlZaWpi1btqhLly5KTEzUkSNHqpyfl5en4cOHa8OGDcrPz1dERITuuOMOHT582MOZAzCLugf8D003AAA+KiMjQ2PGjFFycrKuv/56ZWVlqX79+lqwYEGV89955x09+uijio6OVlRUlN588005HA7l5uZ6OHMAZlH3gP+h6QYAwAeVl5dr8+bNSkhIcI7ZbDYlJCQoPz+/Wus4ffq0zp49qyZNmliVJoAaRN0D/smvftMNAIC/OHbsmCoqKhQWFuYyHhYWpt27d1drHRMnTlSrVq1cvsD/UllZmcrKypyvS0pKzCcM4JJ5ou4lah/wNM50AwDgh2bPnq2lS5dq5cqVCg4OrnJOenq6QkNDnUtERISHswRQk6pT9xK1D3gaTTcAAD6oWbNmCgwMVGFhoct4YWGhwsPDLxj78ssva/bs2Vq3bp1uuOGG886bPHmyiouLncuhQ4dqJHcA5nii7iVqH/A0mm4AAHxQUFCQYmJiXG6GdO7mSPHx8eeNe/HFFzVz5kzl5OSoW7duF9yG3W5XSEiIywLAezxR9xK1D3gav+kGAMBHpaamKikpSd26dVNsbKzmzJmj0tJSJScnS5JGjRql1q1bKz09XZL0wgsvaNq0aVqyZIkiIyNVUFAgSWrYsKEaNjT3jHkAnkXdA/6HphsAAB81bNgwHT16VNOmTVNBQYGio6OVk5PjvMnSwYMHZbP996K1119/XeXl5Ro6dKjLetLS0vTss896MnUAJlH3gP+h6QYAwIelpKQoJSWlyvfy8vJcXh84cMD6hABYjroH/Au/6QYAAAAAwCI03QAAAAAAWMSvLi8P7HCtqbh2aT+aiuuvu03FdVCRqTgAlQXVP2su0GRc6YWf2HL+uN5mos6Y2xgAAAB8Bme6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAMCHZWZmKjIyUsHBwYqLi9OmTZsuOH/58uWKiopScHCwOnfurDVr1ngoUwA1hboH/Eud6k7M+XKWlXkA8EF77p7q7RSAy1p2drZSU1OVlZWluLg4zZkzR4mJifrqq6/UokWLSvM//fRTDR8+XOnp6Ro4cKCWLFmiIUOGaMuWLerUqZMX9gCAu6h7wP8EGIZheDsJAABQWVxcnG666Sb98Y9/lCQ5HA5FRETo8ccf16RJkyrNHzZsmEpLS/Xhhx86x26++WZFR0crKyvrotsrKSlRaGioiouLFRISUnM7AtQCvvL593TdS76z74A3eOLzX+0z3QAAwHPKy8u1efNmTZ482Tlms9mUkJCg/Pz8KmPy8/OVmprqMpaYmKhVq1ZVOb+srExlZWXO18XFxZJ+/gICXG7Ofe69eT7KE3UvUfvAL3mi9mm6AQDwQceOHVNFRYXCwsJcxsPCwrR79+4qYwoKCqqcX1BQUOX89PR0TZ8+vdJ4RESEyayB2u/48eMKDQ31yrY9UfcStQ9Uxcrap+kGAOAyNXnyZJczZEVFRWrTpo0OHjzotabjUpSUlCgiIkKHDh2qlZfIkr93FRcX66qrrlKTJk28nYrlqH3fQv7e5Ynap+kGAMAHNWvWTIGBgSosLHQZLywsVHh4eJUx4eHhbs232+2y2+2VxkNDQ2vlF6dzQkJCyN+Lanv+Npv3Hu7jibqXqH1fRf7eZWXt88gwAAB8UFBQkGJiYpSbm+scczgcys3NVXx8fJUx8fHxLvMlaf369eedD8C3UPeAf+JMNwAAPio1NVVJSUnq1q2bYmNjNWfOHJWWlio5OVmSNGrUKLVu3Vrp6emSpCeeeEK9evXSH/7wBw0YMEBLly7V559/rj/96U/e3A0AbqDuAf9D0w0AgI8aNmyYjh49qmnTpqmgoEDR0dHKyclx3jTp4MGDLpfDde/eXUuWLNGUKVP09NNP69prr9WqVauq/axeu92utLS0Ki87rQ3I37vIv2Z4uu4l39l3s8jfu8j/4nhONwAAAAAAFuE33QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAIAfy8zMVGRkpIKDgxUXF6dNmzZdcP7y5csVFRWl4OBgde7cWWvWrHF53zAMTZs2TS1btlS9evWUkJCgPXv2+ET+8+bNU48ePdS4cWM1btxYCQkJleY/8MADCggIcFn69u3rE/kvWrSoUm7BwcEuc3z5+Pfu3btS/gEBARowYIBzjieP/8aNGzVo0CC1atVKAQEBWrVq1UVj8vLydOONN8put+uaa67RokWLKs1xt6a8gbqn7j2VP3VfTQYAAPBLS5cuNYKCgowFCxYYX375pTFmzBijUaNGRmFhYZXzP/nkEyMwMNB48cUXjZ07dxpTpkwx6tata2zfvt05Z/bs2UZoaKixatUq44svvjAGDx5stG3b1jhz5ozX87/vvvuMzMxMY+vWrcauXbuMBx54wAgNDTW+++4755ykpCSjb9++xvfff+9cTpw4UeO5m8l/4cKFRkhIiEtuBQUFLnN8+fgfP37cJfcdO3YYgYGBxsKFC51zPHn816xZYzzzzDPG+++/b0gyVq5cecH5+/btM+rXr2+kpqYaO3fuNF577TUjMDDQyMnJcc5x95h4A3VP3Xsyf+q+emi6AQDwU7GxscZjjz3mfF1RUWG0atXKSE9Pr3L+PffcYwwYMMBlLC4uzvjd735nGIZhOBwOIzw83HjppZec7xcVFRl2u9149913vZ7/r/3000/GFVdcYbz11lvOsaSkJOPOO++s6VSr5G7+CxcuNEJDQ8+7vtp2/F955RXjiiuuME6dOuUc8+Tx/6XqfPl+6qmnjI4dO7qMDRs2zEhMTHS+vtRj4gnUPXV/Kah7a+qey8sBAPBD5eXl2rx5sxISEpxjNptNCQkJys/PrzImPz/fZb4kJSYmOufv379fBQUFLnNCQ0MVFxd33nV6Mv9fO336tM6ePasmTZq4jOfl5alFixZq3769HnnkER0/frxGc5fM53/q1Cm1adNGERERuvPOO/Xll18636ttx3/+/Pm699571aBBA5dxTxx/My72+a+JY2I16p6690b+v0TdV42mGwAAP3Ts2DFVVFQoLCzMZTwsLEwFBQVVxhQUFFxw/rn/dWedZpnJ/9cmTpyoVq1auXxZ6tu3rxYvXqzc3Fy98MIL+r//+z/169dPFRUVXs+/ffv2WrBggf7yl7/oz3/+sxwOh7p3767vvvtOUu06/ps2bdKOHTs0evRol3FPHX8zzvf5Lykp0ZkzZ2rkM2k16p6693T+v0Tdn1+dGskWAADAh8yePVtLly5VXl6ey02J7r33XuefO3furBtuuEFXX3218vLydPvtt3sjVaf4+HjFx8c7X3fv3l0dOnTQG2+8oZkzZ3oxM/fNnz9fnTt3VmxsrMu4Lx9/1H7UvXdR9+fHmW4AAPxQs2bNFBgYqMLCQpfxwsJChYeHVxkTHh5+wfnn/teddZplJv9zXn75Zc2ePVvr1q3TDTfccMG57dq1U7NmzbR3795LzvmXLiX/c+rWrauuXbs6c6stx7+0tFRLly7VQw89dNHtWHX8zTjf5z8kJET16tWrkb9Tq1H31P2loO5/ZkXd03QDAOCHgoKCFBMTo9zcXOeYw+FQbm6uy1mVX4qPj3eZL0nr1693zm/btq3Cw8Nd5pSUlOizzz477zo9mb8kvfjii5o5c6ZycnLUrVu3i27nu+++0/Hjx9WyZcsayfscs/n/UkVFhbZv3+7MrTYcf+nnx0+VlZXp/vvvv+h2rDr+Zlzs818Tf6dWo+6pe2/lT91fRLVvuQYAAGqVpUuXGna73Vi0aJGxc+dOY+zYsUajRo2cj6MZOXKkMWnSJOf8Tz75xKhTp47x8ssvG7t27TLS0tKqfHRQo0aNjL/85S/Gv//9b+POO++09NE17uQ/e/ZsIygoyFixYoXLo2lOnjxpGIZhnDx50pgwYYKRn59v7N+/3/j73/9u3Hjjjca1115r/Pjjj17Pf/r06cbatWuNb775xti8ebNx7733GsHBwcaXX37pso++evzPufXWW41hw4ZVGvf08T958qSxdetWY+vWrYYkIyMjw9i6davx7bffGoZhGJMmTTJGjhzpnH/u0UH/+7//a+zatcvIzMys8tFBFzomvoC6p+49mf851P2F0XQDAODHXnvtNeOqq64ygoKCjNjYWOOf//yn871evXoZSUlJLvOXLVtmXHfddUZQUJDRsWNHY/Xq1S7vOxwOY+rUqUZYWJhht9uN22+/3fjqq698Iv82bdoYkiotaWlphmEYxunTp4077rjDaN68uVG3bl2jTZs2xpgxYyxtmNzJf9y4cc65YWFhRv/+/Y0tW7a4rM+Xj79hGMbu3bsNSca6desqrcvTx3/Dhg1Vfh7O5ZyUlGT06tWrUkx0dLQRFBRktGvXzuVZw+dc6Jj4CuqeuvdU/oZB3VdHgGEYhlvn4AEAAAAAQLXwm24AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNt6RFixYpICBAn3/+ubdTMS0yMlIDBw70dho1JjIyUg888IC304Afo+59D3UPAAD8kceb7nNfdH+5tGjRQn369NHf/vY30+udNWuWVq1aVXOJumHjxo0aPHiwIiIiFBwcrPDwcPXt21effPLJJa+7sLBQEyZMUFRUlOrXr68GDRooJiZGzz33nIqKii49+VouOztb999/v6699loFBASod+/e3k4JVaDu3UPdn9/x48f10ksvqWfPnmrevLkaNWqkm2++WdnZ2d5ODQAAoEp1vLXhGTNmqG3btjIMQ4WFhVq0aJH69++vv/71r6bO3MyaNUtDhw7VkCFDaj7Zi/j6669ls9n08MMPKzw8XD/88IP+/Oc/q2fPnlq9erX69u1rar3/+te/1L9/f506dUr333+/YmJiJEmff/65Zs+erY0bN2rdunU1uSu1zuuvv67Nmzfrpptu0vHjx72dDi6Cur846v7C8vPz9cwzz6h///6aMmWK6tSpo/fee0/33nuvdu7cqenTp3s7RQAAABdea7r79eunbt26OV8/9NBDCgsL07vvvlvrLpccPXq0Ro8e7TL26KOPql27dpozZ46pL99FRUW66667FBgYqK1btyoqKsrl/eeff17z5s27pLz9wdtvv63WrVvLZrOpU6dO3k4HF0HdXxh1f3EdO3bUnj171KZNG+fYo48+qoSEBL3wwgt66qmn1KBBAy9mCAAA4MpnftPdqFEj1atXT3XquP47wMsvv6zu3buradOmqlevnmJiYrRixQqXOQEBASotLdVbb73lvHT1l78LPHz4sB566CG1atVKdrtdbdu21SOPPKLy8nKX9ZSVlSk1NVXNmzdXgwYNdNddd+no0aOm9qd+/fpq3ry56UtB33jjDR0+fFgZGRmVvnhLUlhYmKZMmVJp/OOPP1ZsbKyCg4PVrl07LV682OX9EydOaMKECercubMaNmyokJAQ9evXT1988YXLvLy8PAUEBGjZsmV6/vnndeWVVyo4OFi333679u7d6zK3d+/e6tSpk3bu3Kk+ffqofv36at26tV588cVK+ZWVlSktLU3XXHON7Ha7IiIi9NRTT6msrMzMYVJERIRsNp/5GMNN1L0r6v7i2rZt69JwSz9/FoYMGaKysjLt27fP7XUCAABYyWtnuouLi3Xs2DEZhqEjR47otddec15O+UuvvvqqBg8erBEjRqi8vFxLly7V3XffrQ8//FADBgyQ9PPZztGjRys2NlZjx46VJF199dWSpP/85z+KjY1VUVGRxo4dq6ioKB0+fFgrVqzQ6dOnFRQU5NzW448/rsaNGystLU0HDhzQnDlzlJKSUu3fCpaUlKi8vFzHjh3T4sWLtWPHDj399NOmjs8HH3ygevXqaejQodWO2bt3r4YOHaqHHnpISUlJWrBggR544AHFxMSoY8eOkqR9+/Zp1apVuvvuu9W2bVsVFhbqjTfeUK9evbRz5061atXKZZ2zZ8+WzWbThAkTVFxcrBdffFEjRozQZ5995jLvhx9+UN++ffXb3/5W99xzj1asWKGJEyeqc+fO6tevnyTJ4XBo8ODB+vjjjzV27Fh16NBB27dv1yuvvKKvv/7aa7/NhedQ9xdG3ZtXUFAgSWrWrFmNrA8AAKDGGB62cOFCQ1KlxW63G4sWLao0//Tp0y6vy8vLjU6dOhm33Xaby3iDBg2MpKSkSvGjRo0ybDab8a9//avSew6HwyWnhIQE55hhGMb48eONwMBAo6ioqFr7lpiY6NyfoKAg43e/+51x5syZasX+WuPGjY0uXbpUe36bNm0MScbGjRudY0eOHDHsdrvx5JNPOsd+/PFHo6KiwiV2//79ht1uN2bMmOEc27BhgyHJ6NChg1FWVuYcf/XVVw1Jxvbt251jvXr1MiQZixcvdo6VlZUZ4eHhxv/8z/84x95++23DZrMZH330kcv2s7KyDEnGJ5984rI/Vf19XkjHjh2NXr16uRUDz6Duq4e6d7/uDcMwjh8/brRo0cLo0aOH27EAAABW89p1uZmZmVq/fr3Wr1+vP//5z+rTp49Gjx6t999/32VevXr1nH/+4YcfVFxcrB49emjLli0X3YbD4dCqVas0aNAgl9+RnhMQEODyeuzYsS5jPXr0UEVFhb799ttq7dPs2bO1bt06zZ8/XzfffLPKy8v1008/VSv210pKSnTFFVe4FXP99derR48eztfNmzdX+/btXS63tNvtzsuxKyoqdPz4cTVs2FDt27ev8pgmJye7nBU8t/5fX8LZsGFDl7OVQUFBio2NdZm3fPlydejQQVFRUTp27Jhzue222yRJGzZscGt/UftQ9xdG3bvP4XBoxIgRKioq0muvvXZJ6wIAALCC1y4vj42NdflCPHz4cHXt2lUpKSkaOHCg8wvfhx9+qOeee07btm1z+f3fr784V+Xo0aMqKSmp9g22rrrqKpfXjRs3lvTzl/7qiI6Odv75/vvv14033qgHHnig0m9RqyMkJEQnT550K+bX+Us/78Mv83c4HHr11Vc1d+5c7d+/XxUVFc73mjZtetF1nu+YXHnllZX+Tho3bqx///vfztd79uzRrl271Lx58yrzP3LkyPl2DX6Cur8w6t59jz/+uHJycrR48WJ16dLlktYFAABgBa813b9ms9nUp08fvfrqq9qzZ486duyojz76SIMHD1bPnj01d+5ctWzZUnXr1tXChQu1ZMmSGs8hMDCwynHDMNxeV1BQkAYPHqzZs2frzJkzLmfuqiMqKkrbtm1TeXm5yxmnC6lO/rNmzdLUqVP14IMPaubMmWrSpIlsNpvGjRsnh8Nhap3VnedwONS5c2dlZGRUOTciIqLKcfgv6t4Vde+e6dOna+7cuZo9e7ZGjhxpej0AAABW8pmmW5LzksxTp05Jkt577z0FBwdr7dq1stvtznkLFy6sFFvVGbDmzZsrJCREO3bssCjjCztz5owMw9DJkyfd/vI9aNAg5efn67333tPw4cNrLKcVK1aoT58+mj9/vst4UVGR5Tcguvrqq/XFF1/o9ttvr9YZS1weqPv/ou6rLzMzU88++6zGjRuniRMn1th6AQAAaprPPGvp7NmzWrdunYKCgtShQwdJP59FCQgIcLkU8sCBA1Xe7bZBgwaVHtNjs9k0ZMgQ/fWvf9Xnn39eKcbMmayqVHV5ZFFRkd577z1FRESoRYsWbq/z4YcfVsuWLfXkk0/q66+/rnKbzz33nNvrDQwMrLTfy5cv1+HDh91el7vuueceHT58uMrnDJ85c0alpaWW5wDfQt27ou6rJzs7W7///e81YsSI855BBwAA8BVeO9P9t7/9Tbt375b08xfJJUuWaM+ePZo0aZJCQkIkSQMGDFBGRob69u2r++67T0eOHFFmZqauueYal98MSlJMTIz+/ve/KyMjQ61atVLbtm0VFxenWbNmad26derVq5fzcTXff/+9li9fro8//liNGjW65H3p16+frrzySsXFxalFixY6ePCgFi5cqP/85z+VHjv07LPPavr06dqwYYN69+593nU2btxYK1euVP/+/RUdHa37779fMTExkqQtW7bo3XffVXx8vNu5Dhw4UDNmzFBycrK6d++u7du365133lG7du3cXpe7Ro4cqWXLlunhhx/Whg0bdMstt6iiokK7d+/WsmXLtHbt2ipvfHUhGzdu1MaNGyX9/Fve0tJSZ1PSs2dP9ezZs8b3A+ZR99T9pdb9pk2bNGrUKDVt2lS333673nnnHZf3u3fv7pH9AgAAqC6vNd3Tpk1z/jk4OFhRUVF6/fXX9bvf/c45ftttt2n+/PmaPXu2xo0bp7Zt2+qFF17QgQMHKn35zsjI0NixYzVlyhSdOXNGSUlJiouLU+vWrfXZZ59p6tSpeuedd1RSUqLWrVurX79+ql+/fo3sy4MPPqilS5fqlVdeUVFRkRo3bqybb75ZS5YscbmrsPTzJbQBAQEKDw+/6Hrj4uK0Y8cOvfTSS1q9erXefvtt2Ww2dejQQZMmTVJKSorbuT799NMqLS3VkiVLlJ2drRtvvFGrV6/WpEmT3F6Xu2w2m1atWqVXXnlFixcv1sqVK1W/fn21a9dOTzzxhK677jq31/mPf/xD06dPdxmbOnWqJCktLY2m28dQ99T9pdb9zp07VV5erqNHj+rBBx+s9P7ChQtpugEAgE8JMGrqWktUS2xsrNq0aaPly5d7OxUAHkLdAwAAXL585jfdl4OSkhJ98cUXmjFjhrdTAeAh1D3M2rhxowYNGqRWrVopICCgyvsa/FpeXp5uvPFG2e12XXPNNVq0aJHleQKoOdQ94J9ouj0oJCREZWVlzhtGAfB/1D3MKi0tVZcuXZSZmVmt+fv379eAAQPUp08fbdu2TePGjdPo0aO1du1aizMFUFOoe8A/cXk5AAA+LiAgQCtXrtSQIUPOO2fixIlavXq1y+Py7r33XhUVFSknJ8cDWQKoSdQ94D986jndAADAnPz8fCUkJLiMJSYmaty4ceeNKSsrU1lZmfO1w+HQiRMn1LRp0xp9rjpQGxiGoZMnT6pVq1ay2WrHxaBm6l6i9oFf8kTt03QDAOAHCgoKFBYW5jIWFhamkpISnTlzRvXq1asUk56eXukJEMDl7tChQ7ryyiu9nUa1mKl7idoHqmJl7dN0AwBwmZo8ebJSU1Odr4uLi3XVVVfp0KFDCgkJ8WJmgOeVlJQoIiJCV1xxhbdTsRy1D/yXJ2qfphsAAD8QHh6uwsJCl7HCwkKFhISc92yX3W6X3W6vNB4SEsIXb1y2atPl1WbqXqL2gapYWfvVbrr7dp5iWRJAbZCz/Tlvp+BxVy993tspAF71zb3PeDuFaouPj9eaNWtcxtavX6/4+HgvZQTAatQ9UDvUjrtEAABwmTl16pS2bdumbdu2Sfr50UDbtm3TwYMHJf18eeioUaOc8x9++GHt27dPTz31lHbv3q25c+dq2bJlGj9+vDfSB2ACdQ/4J5puAAB80Oeff66uXbuqa9eukqTU1FR17dpV06ZNkyR9//33zi/iktS2bVutXr1a69evV5cuXfSHP/xBb775phITE72SPwD3UfeAf+I33QAA+KDevXvLMIzzvr9o0aIqY7Zu3WphVgCsRN0D/okz3QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABap4+0E4F8O/6apqbjJj7zrdszi395halsAataGW/9oKm7IzP91O6a4zxlT2wIAAPAWznQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgDAh2VmZioyMlLBwcGKi4vTpk2bLjh/zpw5at++verVq6eIiAiNHz9eP/74o4eyBVATqHvAv9B0AwDgo7Kzs5Wamqq0tDRt2bJFXbp0UWJioo4cOVLl/CVLlmjSpElKS0vTrl27NH/+fGVnZ+vpp5/2cOYAzKLuAf9D0w0AgI/KyMjQmDFjlJycrOuvv15ZWVmqX7++FixYUOX8Tz/9VLfccovuu+8+RUZG6o477tDw4cMvepYMgO+g7gH/Q9MNAIAPKi8v1+bNm5WQkOAcs9lsSkhIUH5+fpUx3bt31+bNm51ftvft26c1a9aof//+Vc4vKytTSUmJywLAezxR9xK1D3haHW8nAAAAKjt27JgqKioUFhbmMh4WFqbdu3dXGXPffffp2LFjuvXWW2UYhn766Sc9/PDD573MND09XdOnT6/x3AGY44m6l6h9wNM40w0AgJ/Iy8vTrFmzNHfuXG3ZskXvv/++Vq9erZkzZ1Y5f/LkySouLnYuhw4d8nDGAC6Vu3UvUfuAp3GmGwAAH9SsWTMFBgaqsLDQZbywsFDh4eFVxkydOlUjR47U6NGjJUmdO3dWaWmpxo4dq2eeeUY2m+u/tdvtdtntdmt2AIDbPFH3ErUPeJrPNt3Br59wO+bHR5pYkMnl6YcujU3FtRhk7l9KE+p/53bMYlNbgi9r2bTY7Zjvj4dakMnlaWvPLFNxN378qKm4tvOq/n3ihRT3iTa1rdooKChIMTExys3N1ZAhQyRJDodDubm5SklJqTLm9OnTlb5gBwYGSpIMw7A0XwCXjroH/JPPNt0AAFzuUlNTlZSUpG7duik2NlZz5sxRaWmpkpOTJUmjRo1S69atlZ6eLkkaNGiQMjIy1LVrV8XFxWnv3r2aOnWqBg0a5PwSDsC3UfeA/6HpBgDARw0bNkxHjx7VtGnTVFBQoOjoaOXk5DhvsnTw4EGXM1xTpkxRQECApkyZosOHD6t58+YaNGiQnn/+eW/tAgA3UfeA/6HpBgDAh6WkpJz3stK8vDyX13Xq1FFaWprS0tI8kBkAq1D3gH/h7uUAAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvU8XYC5/PndqvdjhmqkRZkAncsuy7bVNyIvg/WcCaolV5v7n7MPeU1n8dlyh5Q11Rcu5cqTMV9syTaVBwAAEBtwpluAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCJ1rN7ADzc0NhV3VhU1nAncYng7AdRme3ovMhXXZ/GYmk0EbjnlKDMVF7Brv8ktXmcyDgAAoPbgTDcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAH5aZmanIyEgFBwcrLi5OmzZtuuD8oqIiPfbYY2rZsqXsdruuu+46rVmzxkPZAqgJ1D3gXyy/kRoAADAnOztbqampysrKUlxcnObMmaPExER99dVXatGiRaX55eXl+s1vfqMWLVpoxYoVat26tb799ls1atTI88kDMIW6B/wPTTcAAD4qIyNDY8aMUXJysiQpKytLq1ev1oIFCzRp0qRK8xcsWKATJ07o008/Vd26dSVJkZGRnkwZwCWi7gH/w+XlAAD4oPLycm3evFkJCQnOMZvNpoSEBOXn51cZ88EHHyg+Pl6PPfaYwsLC1KlTJ82aNUsVFTyGE6gNqHvAP3GmGwAAH3Ts2DFVVFQoLCzMZTwsLEy7d++uMmbfvn36xz/+oREjRmjNmjXau3evHn30UZ09e1ZpaWmV5peVlams7L/PZy8pKanZnQDgFk/UvUTtA57GmW4AAPyEw+FQixYt9Kc//UkxMTEaNmyYnnnmGWVlZVU5Pz09XaGhoc4lIiLCwxkDuFTu1r1E7QOeRtMNAIAPatasmQIDA1VYWOgyXlhYqPDw8CpjWrZsqeuuu06BgYHOsQ4dOqigoEDl5eWV5k+ePFnFxcXO5dChQzW7EwDc4om6l6h9wNNougEA8EFBQUGKiYlRbm6uc8zhcCg3N1fx8fFVxtxyyy3au3evHA6Hc+zrr79Wy5YtFRQUVGm+3W5XSEiIywLAezxR9xK1D3gaTTcAAD4qNTVV8+bN01tvvaVdu3bpkUceUWlpqfOuxqNGjdLkyZOd8x955BGdOHFCTzzxhL7++mutXr1as2bN0mOPPeatXQDgJuoe8D/cSA0AAB81bNgwHT16VNOmTVNBQYGio6OVk5PjvMnSwYMHZbP999/PIyIitHbtWo0fP1433HCDWrdurSeeeEITJ0701i4AcBN1D/gfy5vuOmWGqbizhuPiky4jP3RpbCruWHSAqbhV92SYiotZOd5UXJSKTMXBN33/0ylTcfW/MPObsqp/4+YPtvY8/01wLmRHeV1TcXF/ftJUXMTNVf9m8OJ4nE11pKSkKCUlpcr38vLyKo3Fx8frn//8p8VZAbASdQ/4Fy4vBwAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGCROlZvIPBHh6m4ZoEN3I75w+qFprb1csEdpuImhK8zFRcYYLgd0/f/Hje1rdB/BpuKq1CAqbiQvYGm4uBfTjjMfQ6+H9LW7ZhrW35rals3NTEXt3L/DabiKjY1djtm4Nvm6t7Ef2IkScHXm6v7s1eYrfsKk3EAAAC1B2e6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvUsXoD9b8tMRXXr/99bsec6BxqaltmjWjQ2VRc+Ecn3I6JUqmpbRV1CjIV1yqwwlxc7nFTcfAvQz59xFRc4zPux5ydFmZqW5/KXFzj0Lqm4v5z32m3Yw53MrUp7e61wFTcgDtHmYr7JtXy/ysBAACotTjTDQAAAACARWi6AQAAAACwCE03AAA+LDMzU5GRkQoODlZcXJw2bdpUrbilS5cqICBAQ4YMsTZBADWOugf8C003AAA+Kjs7W6mpqUpLS9OWLVvUpUsXJSYm6siRIxeMO3DggCZMmKAePXp4KFMANYW6B/wPTTcAAD4qIyNDY8aMUXJysq6//nplZWWpfv36WrDg/DfLq6io0IgRIzR9+nS1a9fOg9kCqAnUPeB/aLoBAPBB5eXl2rx5sxISEpxjNptNCQkJys/PP2/cjBkz1KJFCz300EMX3UZZWZlKSkpcFgDe44m6l6h9wNNougEA8EHHjh1TRUWFwsJcH28XFhamgoKCKmM+/vhjzZ8/X/PmzavWNtLT0xUaGupcIiIiLjlvAOZ5ou4lah/wNJpuAAD8wMmTJzVy5EjNmzdPzZo1q1bM5MmTVVxc7FwOHTpkcZYAapKZupeofcDT6ng7AQAAUFmzZs0UGBiowsJCl/HCwkKFh4dXmv/NN9/owIEDGjRokHPM4XBIkurUqaOvvvpKV199tUuM3W6X3W63IHsAZnii7iVqH/A0znQDAOCDgoKCFBMTo9zcXOeYw+FQbm6u4uPjK82PiorS9u3btW3bNucyePBg9enTR9u2bePyUaAWoO4B/8SZbgAAfFRqaqqSkpLUrVs3xcbGas6cOSotLVVycrIkadSoUWrdurXS09MVHBysTp06ucQ3atRIkiqNA/Bd1D3gf2i6AQDwUcOGDdPRo0c1bdo0FRQUKDo6Wjk5Oc6bLB08eFA2GxetAf6Eugf8D003AAA+LCUlRSkpKVW+l5eXd8HYRYsW1XxCACxH3QP+xWeb7oCzFW7HNN1ywoJMarfAs4a5OAXUcCbAxf1wxxn3YyzI48LKPb5Fdx2pOG0qznboiMkttjIZBwAA4P+4NgUAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwSB1vJwAA8BGNQrydAQAAgN/hTDcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuVKlugM3UAqD2Km8VYmqBtTIzMxUZGang4GDFxcVp06ZN5507b9489ejRQ40bN1bjxo2VkJBwwfkAfBN1D/gXuiQAAHxUdna2UlNTlZaWpi1btqhLly5KTEzUkSNHqpyfl5en4cOHa8OGDcrPz1dERITuuOMOHT582MOZAzCLugf8D003AAA+KiMjQ2PGjFFycrKuv/56ZWVlqX79+lqwYEGV89955x09+uijio6OVlRUlN588005HA7l5uZ6OHMAZlH3gP+h6QYAwAeVl5dr8+bNSkhIcI7ZbDYlJCQoPz+/Wus4ffq0zp49qyZNmliVJoAaRN0D/qmOtxMAAACVHTt2TBUVFQoLC3MZDwsL0+7du6u1jokTJ6pVq1YuX+B/qaysTGVlZc7XJSUl5hMGcMk8UfcStQ94Gme6AQDwQ7Nnz9bSpUu1cuVKBQcHVzknPT1doaGhziUiIsLDWQKoSdWpe4naBzyNphsAAB/UrFkzBQYGqrCw0GW8sLBQ4eHhF4x9+eWXNXv2bK1bt0433HDDeedNnjxZxcXFzuXQoUM1kjsAczxR9xK1D3gaTTcAAD4oKChIMTExLjdDOndzpPj4+PPGvfjii5o5c6ZycnLUrVu3C27DbrcrJCTEZQHgPZ6oe4naBzyN33QDAOCjUlNTlZSUpG7duik2NlZz5sxRaWmpkpOTJUmjRo1S69atlZ6eLkl64YUXNG3aNC1ZskSRkZEqKCiQJDVs2FANGzb02n4AqD7qHvA/NN0AAPioYcOG6ejRo5o2bZoKCgoUHR2tnJwc502WDh48KJvtvxetvf766yovL9fQoUNd1pOWlqZnn33Wk6kDMIm6B/wPTTcAAD4sJSVFKSkpVb6Xl5fn8vrAgQPWJwTActQ94F/4TTcAAAAAABah6QYAAAAAwCJcXu7n6r//mam4ni3Gm4oL1wlTcQBqzi15vzcVF9HA7P8llJuMAwAA8H+c6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsUsfbCcBagR3bm4oL/+hEDWcCwFMC6zhMxf3nvvIazgQAAACc6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAB8WGZmpiIjIxUcHKy4uDht2rTpgvOXL1+uqKgoBQcHq3PnzlqzZo2HMgVQU6h7wL/Uqe7EnO3PWZkHAB/0zb3PeDsF4LKWnZ2t1NRUZWVlKS4uTnPmzFFiYqK++uortWjRotL8Tz/9VMOHD1d6eroGDhyoJUuWaMiQIdqyZYs6derkhT0A4C7qHvA/AYZhGN5OAgAAVBYXF6ebbrpJf/zjHyVJDodDERERevzxxzVp0qRK84cNG6bS0lJ9+OGHzrGbb75Z0dHRysrKuuj2SkpKFBoaquLiYoWEhNTcjgC1gK98/j1d95Lv7Dvw/9u79+io6nP/458kkEmgJICBCaHhJnKRu+EkJ1iKaDQo13NaG9SSwE/AqlgwR7koklIqCRcRDo1SLSRSxVCoYBWMYDRaJS2Vi8hNQcAAhwSCJYGACSbf3x8upowZSDJkz0zC+7XWLJnvfJ+9n/1lnuU87D2zvcET7/8an+kGAACeU15erm3btmnGjBmOMX9/f8XFxSkvL89lTF5enpKTk53G4uPjtX79epfzy8rKVFZW5nheXFws6fsPIMD15tL73pvnozxR9xK1D1zOE7VP0w0AgA8qKipSRUWF7Ha707jdbtf+/ftdxhQUFLicX1BQ4HJ+amqqZs+eXWU8MjLSzayB+u/06dMKDQ31yr49UfcStQ+4YmXt03QDAHCdmjFjhtMZsjNnzqh9+/bKz8/3WtNxLUpKShQZGamjR4/Wy0tkyd+7iouL1a5dO7Vs2dLbqViO2vct5O9dnqh9mm4AAHxQWFiYAgICVFhY6DReWFio8PBwlzHh4eG1mm+z2WSz2aqMh4aG1ssPTpeEhISQvxfV9/z9/b13cx9P1L1E7fsq8vcuK2ufW4YBAOCDAgMDFRUVpZycHMdYZWWlcnJyFBsb6zImNjbWab4kbd68+YrzAfgW6h5omDjTDQCAj0pOTlZSUpL69++v6OhoLV68WKWlpRo3bpwkKTExUW3btlVqaqokafLkyRo0aJCee+45DR06VFlZWfr000/10ksvefMwANQCdQ80PDTdAAD4qISEBJ06dUqzZs1SQUGB+vbtq+zsbMePJuXn5ztdDjdgwACtWrVKM2fO1FNPPaWbbrpJ69evr/G9em02m1JSUlxedlofkL93kX/d8HTdS75z7O4if+8i/+pxn24AAAAAACzCd7oBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwCABiw9PV0dOnRQUFCQYmJitHXr1qvOX7Nmjbp166agoCD16tVLGzdudHrdGKNZs2apTZs2Cg4OVlxcnA4cOOAT+b/88ssaOHCgWrRooRYtWiguLq7K/LFjx8rPz8/pMWTIEJ/IPzMzs0puQUFBTnN8ef1vu+22Kvn7+flp6NChjjmeXP+PPvpIw4cPV0REhPz8/LR+/fpqY3Jzc3XLLbfIZrOpc+fOyszMrDKntjXlDdQ9de+p/Kn7GjIAAKBBysrKMoGBgWbFihVmz549ZsKECaZ58+amsLDQ5fxPPvnEBAQEmPnz55u9e/eamTNnmsaNG5vPP//cMSctLc2Ehoaa9evXm88++8yMGDHCdOzY0Vy4cMHr+d9///0mPT3d7Nixw+zbt8+MHTvWhIaGmmPHjjnmJCUlmSFDhpgTJ044Ht98802d5+5O/hkZGSYkJMQpt4KCAqc5vrz+p0+fdsp99+7dJiAgwGRkZDjmeHL9N27caJ5++mnzxhtvGElm3bp1V51/6NAh06RJE5OcnGz27t1rli5dagICAkx2drZjTm3XxBuoe+rek/lT9zVD0w0AQAMVHR1tHn30UcfziooKExERYVJTU13O/8UvfmGGDh3qNBYTE2MeeughY4wxlZWVJjw83CxYsMDx+pkzZ4zNZjOvv/661/P/oe+++840a9bMvPLKK46xpKQkM3LkyLpO1aXa5p+RkWFCQ0OvuL36tv7PP/+8adasmTl37pxjzJPrf7mafPieOnWq6dGjh9NYQkKCiY+Pdzy/1jXxBOqeur8W1L01dc/l5QAANEDl5eXatm2b4uLiHGP+/v6Ki4tTXl6ey5i8vDyn+ZIUHx/vmH/48GEVFBQ4zQkNDVVMTMwVt+nJ/H/o/Pnzunjxolq2bOk0npubq9atW6tr1656+OGHdfr06TrNXXI//3Pnzql9+/aKjIzUyJEjtWfPHsdr9W39ly9frtGjR6tp06ZO455Yf3dU9/6vizWxGnVP3Xsj/8tR967RdAMA0AAVFRWpoqJCdrvdadxut6ugoMBlTEFBwVXnX/pvbbbpLnfy/6Fp06YpIiLC6cPSkCFDtHLlSuXk5GjevHn68MMPdffdd6uiosLr+Xft2lUrVqzQm2++qVdffVWVlZUaMGCAjh07Jql+rf/WrVu1e/dujR8/3mncU+vvjiu9/0tKSnThwoU6eU9ajbqn7j2d/+Wo+ytrVCfZAgAA+JC0tDRlZWUpNzfX6UeJRo8e7fhzr1691Lt3b914443Kzc3VHXfc4Y1UHWJjYxUbG+t4PmDAAHXv3l1/+MMfNGfOHC9mVnvLly9Xr169FB0d7TTuy+uP+o+69y7q/so40w0AQAMUFhamgIAAFRYWOo0XFhYqPDzcZUx4ePhV51/6b2226S538r9k4cKFSktL06ZNm9S7d++rzu3UqZPCwsJ08ODBa875cteS/yWNGzdWv379HLnVl/UvLS1VVlaWHnzwwWr3Y9X6u+NK7/+QkBAFBwfXyd+p1ah76v5aUPffs6LuaboBAGiAAgMDFRUVpZycHMdYZWWlcnJynM6qXC42NtZpviRt3rzZMb9jx44KDw93mlNSUqJ//OMfV9ymJ/OXpPnz52vOnDnKzs5W//79q93PsWPHdPr0abVp06ZO8r7E3fwvV1FRoc8//9yRW31Yf+n720+VlZXpl7/8ZbX7sWr93VHd+78u/k6tRt1T997Kn7qvRo1/cg0AANQrWVlZxmazmczMTLN3714zceJE07x5c8ftaMaMGWOmT5/umP/JJ5+YRo0amYULF5p9+/aZlJQUl7cOat68uXnzzTfNrl27zMiRIy29dU1t8k9LSzOBgYFm7dq1TremOXv2rDHGmLNnz5onnnjC5OXlmcOHD5v33nvP3HLLLeamm24y3377rdfznz17tnn33XfNV199ZbZt22ZGjx5tgoKCzJ49e5yO0VfX/5Kf/OQnJiEhocq4p9f/7NmzZseOHWbHjh1Gklm0aJHZsWOH+frrr40xxkyfPt2MGTPGMf/SrYOefPJJs2/fPpOenu7y1kFXWxNfQN1T957M/xLq/upougEAaMCWLl1q2rVrZwIDA010dLT5+9//7nht0KBBJikpyWn+n//8Z9OlSxcTGBhoevToYTZs2OD0emVlpXnmmWeM3W43NpvN3HHHHeaLL77wifzbt29vJFV5pKSkGGOMOX/+vLnrrrtMq1atTOPGjU379u3NhAkTLG2YapP/lClTHHPtdru55557zPbt252258vrb4wx+/fvN5LMpk2bqmzL0+v/wQcfuHw/XMo5KSnJDBo0qEpM3759TWBgoOnUqZPTvYYvudqa+Arqnrr3VP7GUPc14WeMMbU6Bw8AAAAAAGqE73QDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVouiVlZmbKz89Pn376qbdTcZufn58mTZrk7TTqjJ+fn37zm994Ow00YNS976HuAQBAQ+TxpvvSB93LH61bt9bgwYP1zjvvuL3duXPnav369XWX6DWYMGGC/Pz8NGzYsGve1ldffaWHHnpInTp1UlBQkEJCQnTrrbdqyZIlunDhQh1kW7+9+OKLuvfee9WuXTv5+flp7Nix3k4JLlD3tUPdX9nRo0c1e/ZsRUdHq0WLFgoLC9Ntt92m9957z9upAQAAuNTIWzv+7W9/q44dO8oYo8LCQmVmZuqee+7RW2+95daH1rlz5+rnP/+5Ro0aVffJ1sKnn36qzMxMBQUFXfO2NmzYoHvvvVc2m02JiYnq2bOnysvL9fHHH+vJJ5/Unj179NJLL9VB1vXXvHnzdPbsWUVHR+vEiRPeTgfVoO6rR91f3Ztvvql58+Zp1KhRSkpK0nfffaeVK1fqzjvv1IoVKzRu3DhvpwgAAODEa0333Xffrf79+zueP/jgg7Lb7Xr99dfr5EyRNxhj9Otf/1qJiYnKycm5pm0dPnxYo0ePVvv27fX++++rTZs2jtceffRRHTx4UBs2bLjWlOu9Dz/80HGW+0c/+pG300E1qPuro+6rN3jwYOXn5yssLMwx9qtf/Up9+/bVrFmzaLoBAIDP8ZnvdDdv3lzBwcFq1Mj53wEWLlyoAQMG6IYbblBwcLCioqK0du1apzl+fn4qLS3VK6+84rh09fLLjI8fP64HH3xQERERstls6tixox5++GGVl5c7baesrEzJyclq1aqVmjZtqv/6r//SqVOnanwMf/rTn7R79249++yztV+AH5g/f77OnTun5cuXO33wvqRz586aPHlylfH169erZ8+estls6tGjh7Kzs51e//rrr/XII4+oa9euCg4O1g033KB7771XR44ccZp36XLgTz75pNo16dChg4YNG6aPP/5Y0dHRCgoKUqdOnbRy5coq+Z05c0ZTpkxRZGSkbDabOnfurHnz5qmystKNVZLat28vPz8/t2LhfdS9M+q+ej169HBquCXJZrPpnnvu0bFjx3T27NlabxMAAMBKXjvTXVxcrKKiIhljdPLkSS1dulTnzp3TL3/5S6d5S5Ys0YgRI/TAAw+ovLxcWVlZuvfee/X2229r6NChkr7/0Dt+/HhFR0dr4sSJkqQbb7xRkvR///d/io6O1pkzZzRx4kR169ZNx48f19q1a3X+/HkFBgY69vXYY4+pRYsWSklJ0ZEjR7R48WJNmjRJq1evrvZ4zp49q2nTpumpp55SeHj4Na/PW2+9pU6dOmnAgAE1jvn444/1xhtv6JFHHlGzZs30v//7v/rZz36m/Px83XDDDZKkf/7zn9qyZYtGjx6tH//4xzpy5IhefPFF3Xbbbdq7d6+aNGnitM2arsnBgwf185//XA8++KCSkpK0YsUKjR07VlFRUerRo4ck6fz58xo0aJCOHz+uhx56SO3atdOWLVs0Y8YMnThxQosXL762RYPPo+6vjrp3X0FBgZo0aVLlWAAAALzOeFhGRoaRVOVhs9lMZmZmlfnnz593el5eXm569uxpbr/9dqfxpk2bmqSkpCrxiYmJxt/f3/zzn/+s8lplZaVTTnFxcY4xY4x5/PHHTUBAgDlz5ky1x/XEE0+Yjh07mm+//dYYY0z79u3N0KFDq41zpbi42EgyI0eOrHGMJBMYGGgOHjzoGPvss8+MJLN06VLH2A/X0xhj8vLyjCSzcuVKx1ht1qR9+/ZGkvnoo48cYydPnjQ2m838z//8j2Nszpw5pmnTpubLL7902v/06dNNQECAyc/PdzqelJSUGh+/MVd+D8D7qPvqUffu1b0xxhw4cMAEBQWZMWPG1DoWAADAal67vDw9PV2bN2/W5s2b9eqrr2rw4MEaP3683njjDad5wcHBjj//61//UnFxsQYOHKjt27dXu4/KykqtX79ew4cPd/oe6SU/vCx54sSJTmMDBw5URUWFvv7666vu58svv9SSJUu0YMEC2Wy2avOqTklJiSSpWbNmtYqLi4tznOmTpN69eyskJESHDh1yjF2+nhcvXtTp06fVuXNnNW/e3OWa1nRNbr75Zg0cONDxvFWrVuratavTvtesWaOBAweqRYsWKioqcjzi4uJUUVGhjz76qFbHi/qHur8y6t4958+f17333qvg4GClpaVd07YAAACs4LXLy6Ojo50+EN93333q16+fJk2apGHDhjku/3z77bf1u9/9Tjt37lRZWZljfk2+x3vq1CmVlJSoZ8+eNcqpXbt2Ts9btGgh6fsP/VczefJkDRgwQD/72c9qtJ/qhISESFKtv5v4w/yl74/h8vwvXLig1NRUZWRk6Pjx4zLGOF4rLi6udptXWpOa7PvAgQPatWuXWrVq5TL/kydPuhxHw0HdXxl1X3sVFRUaPXq09u7dq3feeUcRERFubwsAAMAqXmu6f8jf31+DBw/WkiVLdODAAfXo0UN/+9vfNGLECP30pz/VCy+8oDZt2qhx48bKyMjQqlWr6jyHgIAAl+OXf0D9offff1/Z2dl64403nH6U6LvvvtOFCxd05MgRtWzZ0vGBuiZCQkIUERGh3bt31zhGqln+jz32mDIyMjRlyhTFxsYqNDRUfn5+Gj16tMsfNarpmtRkXmVlpe68805NnTrV5dwuXbq4HEfDRd3/G3VfexMmTNDbb7+t1157Tbfffrvb2wEAALCSzzTd0vcfWCXp3LlzkqS//OUvCgoK0rvvvut0+WZGRkaVWFdnwFq1aqWQkJBaf4itjfz8fEnSf//3f1d57fjx4+rYsaOef/55TZkypVbbHTZsmF566SXl5eUpNja2LlKVJK1du1ZJSUl67rnnHGPffvutzpw5U2f7uJIbb7xR586dU1xcnOX7Qv1B3f8bdV9zTz75pDIyMrR48WLdd999dbptAACAuuQztwy7ePGiNm3apMDAQHXv3l3S92dR/Pz8VFFR4Zh35MgRrV+/vkp806ZNq3yA9Pf316hRo/TWW2/p008/rRJztTNZNXX77bdr3bp1VR6tWrVS//79tW7dOg0fPrzW2506daqaNm2q8ePHq7CwsMrrX331lZYsWVLr7QYEBFQ57qVLlzqtsVV+8YtfKC8vT++++26V186cOeNovnD9oO6dUfc1s2DBAi1cuFBPPfWUy1uoAQAA+BKvnel+5513tH//fknff6dv1apVOnDggKZPn+64JHPo0KFatGiRhgwZovvvv18nT55Uenq6OnfurF27djltLyoqSu+9954WLVqkiIgIdezYUTExMZo7d642bdqkQYMGaeLEierevbtOnDihNWvW6OOPP1bz5s2v6TjatWvn8nuNU6ZMkd1u16hRo5zGx44dq1deeUWHDx9Whw4drrjdG2+8UatWrVJCQoK6d++uxMRE9ezZU+Xl5dqyZYvWrFnjdE/imho2bJj+9Kc/KTQ0VDfffLPy8vL03nvvOW4tZKUnn3xSf/3rXzVs2DDHbYVKS0v1+eefa+3atTpy5EiV++9W56233tJnn30m6fsGbteuXfrd734nSRoxYoR69+5d58cB91H31P211v26des0depU3XTTTerevbteffVVp9fvvPNO2e32uj4MAAAAt3mt6Z41a5bjz0FBQerWrZtefPFFPfTQQ47x22+/XcuXL1daWpqmTJmijh07at68eTpy5EiVD9+LFi3SxIkTNXPmTF24cEFJSUmKiYlR27Zt9Y9//EPPPPOMXnvtNZWUlKht27a6++67vXI/13Pnzik4OLhGH/pHjBihXbt2acGCBXrzzTf14osvymazqXfv3nruuec0YcKEWu9/yZIlCggI0GuvvaZvv/1Wt956q9577z3Fx8e7cTS106RJE3344YeaO3eu1qxZo5UrVyokJERdunTR7NmzFRoaWutt/uUvf9Err7zieL5jxw7t2LFDkvTjH/+YptvHUPfNq51L3V/dpX9kO3DggMaMGVPl9Q8++ICmGwAA+BQ/UxfXWqLG7Ha7EhMTtWDBAm+nAsBDqHsAAIDrl898p/t6sGfPHl24cEHTpk3zdioAPIS6h7s++ugjDR8+XBEREfLz83P5uwY/lJubq1tuuUU2m02dO3dWZmam5XkCqDvUPdAw0XR7UI8ePVRSUlLr7y0DqL+oe7irtLRUffr0UXp6eo3mHz58WEOHDtXgwYO1c+dOTZkyRePHj3f5I3YAfBN1DzRMXF4OAICP8/Pz07p166r8SN/lpk2bpg0bNjjdLm/06NE6c+aMsrOzPZAlgLpE3QMNh0/dpxsAALgnLy+vyv3Q4+Pjr3q/+LKyMpWVlTmeV1ZW6ptvvtENN9wgPz8/q1IFfJIxRmfPnlVERIT8/evHxaDu1L1E7QOX80Tt03QDANAAFBQUVPnldrvdrpKSEl24cEHBwcFVYlJTUzV79mxPpQjUC0ePHtWPf/xjb6dRI+7UvUTtA65YWfs03QAAXKdmzJih5ORkx/Pi4mK1a9dOR48eVUhIiBczAzyvpKREkZGRatasmbdTsRy1D/ybJ2qfphsAgAYgPDxchYWFTmOFhYUKCQm54tkum80mm81WZTwkJIQP3rhu1afLq92pe4naB1yxsvZr3HQP6fm0ZUkA9UH27me9nYLHdViZ5u0UAK86kjjd2ynUWGxsrDZu3Og0tnnzZsXGxnopIwBWo+6B+qF+/EoEAADXmXPnzmnnzp3auXOnpO9vDbRz507l5+dL+v7y0MTERMf8X/3qVzp06JCmTp2q/fv364UXXtCf//xnPf74495IH4AbqHugYaLpBgDAB3366afq16+f+vXrJ0lKTk5Wv379NGvWLEnSiRMnHB/EJaljx47asGGDNm/erD59+ui5557TH//4R8XHx3slfwC1R90DDRPf6QYAwAfddtttMsZc8fXMzEyXMTt27LAwKwBWou6Bhokz3QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABZp5O0E4Ju+HHeDW3FzR65yKy5zVLxbcQDqTuZPl7sVN3nRI27FFfcvcysOAACgPuFMNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAHxYenq6OnTooKCgIMXExGjr1q1Xnb948WJ17dpVwcHBioyM1OOPP65vv/3WQ9kCqAvUPdCw0HQDAOCjVq9ereTkZKWkpGj79u3q06eP4uPjdfLkSZfzV61apenTpyslJUX79u3T8uXLtXr1aj311FMezhyAu6h7oOGh6QYAwEctWrRIEyZM0Lhx43TzzTdr2bJlatKkiVasWOFy/pYtW3Trrbfq/vvvV4cOHXTXXXfpvvvuq/YsGQDfQd0DDQ9NNwAAPqi8vFzbtm1TXFycY8zf319xcXHKy8tzGTNgwABt27bN8WH70KFD2rhxo+655x6X88vKylRSUuL0AOA9nqh7idoHPK2RtxMAAABVFRUVqaKiQna73Wncbrdr//79LmPuv/9+FRUV6Sc/+YmMMfruu+/0q1/96oqXmaampmr27Nl1njsA93ii7iVqH/A0znQDANBA5Obmau7cuXrhhRe0fft2vfHGG9qwYYPmzJnjcv6MGTNUXFzseBw9etTDGQO4VrWte4naBzyNM90AAPigsLAwBQQEqLCw0Gm8sLBQ4eHhLmOeeeYZjRkzRuPHj5ck9erVS6WlpZo4caKefvpp+fs7/1u7zWaTzWaz5gAA1Jon6l6i9gFPo+lu4EpubuFW3Bf3p7u3v0r3bk+R6VYUAFf23bnMrbifTv+1W3Gt/7TFrbjizCi34q4XgYGBioqKUk5OjkaNGiVJqqysVE5OjiZNmuQy5vz581U+YAcEBEiSjDGW5gvg2lH3QMNE0w0AgI9KTk5WUlKS+vfvr+joaC1evFilpaUaN26cJCkxMVFt27ZVamqqJGn48OFatGiR+vXrp5iYGB08eFDPPPOMhg8f7vgQDsC3UfdAw0PTDQCAj0pISNCpU6c0a9YsFRQUqG/fvsrOznb8yFJ+fr7TGa6ZM2fKz89PM2fO1PHjx9WqVSsNHz5czz77rLcOAUAtUfdAw+NnanjdyZCeT1udCyzg7uXlHy550b39uXl5+QPxY92K86Ts3dff/7w6rEzzdgpwg6cvL2/+J9e3sanOgXpwefmRxOneTsGjSkpKFBoaquLiYoWEhHg7HcCjruf3//V87IAn3v/8ejkAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCKNvJ0AauZffVq6FXf/zHfcijtRcd6tuOHzp7oV10ZFbsUBDdmuuHS34vp8MsGtuI5rdrgVd3HwLW7FAQAAXA840w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYpJG3E4C1JjY/6FZcrz896VZc5/eL3IoDUFWwX6BbcWGrm7gVZ3p2divuUJKfW3EAAADXA850AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAPBh6enp6tChg4KCghQTE6OtW7dedf6ZM2f06KOPqk2bNrLZbOrSpYs2btzooWwB1AXqHmhY+CE1AAB81OrVq5WcnKxly5YpJiZGixcvVnx8vL744gu1bt26yvzy8nLdeeedat26tdauXau2bdvq66+/VvPmzT2fPAC3UPdAw0PTDQCAj1q0aJEmTJigcePGSZKWLVumDRs2aMWKFZo+fXqV+StWrNA333yjLVu2qHHjxpKkDh06eDJlANeIugcaHi4vBwDAB5WXl2vbtm2Ki4tzjPn7+ysuLk55eXkuY/76178qNjZWjz76qOx2u3r27Km5c+eqoqLCU2kDuAbUPdAwcaYbAAAfVFRUpIqKCtntdqdxu92u/fv3u4w5dOiQ3n//fT3wwAPauHGjDh48qEceeUQXL15USkpKlfllZWUqKytzPC8pKanbgwBQK56oe4naBzyNM90AADQQlZWVat26tV566SVFRUUpISFBTz/9tJYtW+ZyfmpqqkJDQx2PyMhID2cM4FrVtu4lah/wNJpuAAB8UFhYmAICAlRYWOg0XlhYqPDwcJcxbdq0UZcuXRQQEOAY6969uwoKClReXl5l/owZM1RcXOx4HD16tG4PAkCteKLuJWof8DSabgAAfFBgYKCioqKUk5PjGKusrFROTo5iY2Ndxtx66606ePCgKisrHWNffvml2rRpo8DAwCrzbTabQkJCnB4AvMcTdS9R+4Cn0XQDAOCjkpOT9fLLL+uVV17Rvn379PDDD6u0tNTxq8aJiYmaMWOGY/7DDz+sb775RpMnT9aXX36pDRs2aO7cuXr00Ue9dQgAaom6BxoefkgNAAAflZCQoFOnTmnWrFkqKChQ3759lZ2d7fiRpfz8fPn7//vfzyMjI/Xuu+/q8ccfV+/evdW2bVtNnjxZ06ZN89YhAKgl6h5oePyMMaYmE4f0fNrqXK4bZ3q3rHXMXxc859a+/t+hn7kV993DXGb0Q9m7n/V2Ch7XYWWat1NoMA7dtbzWMf3mPuLWvtq87voXbquz/7mObsU1ZEcSq94TtyErKSlRaGioiouLudwU153r+f1/PR874In3P5eXAwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALBII28nUJ/9q09Lt+L+mPp8rWMC5OfWvvLXdnIrLkJFbsUBDd2uuHS34jq+/VitY7r97V9u7etiz/ZuxQEAAKDucaYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsAhNNwAAAAAAFqHpBgAAAADAIjTdAAAAAABYhKYbAAAAAACL0HQDAAAAAGARmm4AAAAAACxC0w0AAAAAgEVougEAAAAAsEgjbydQn11s6udWXI/A4FrHDN4z0q19ReQUuRUHwLUKGbfi7B8G1DrG7//cq9+vHm/nVhwAAADqHme6AQAAAACwCE03AAAAAAAWoekGAMCHpaenq0OHDgoKClJMTIy2bt1ao7isrCz5+flp1KhR1iYIoM5R90DDQtMNAICPWr16tZKTk5WSkqLt27erT58+io+P18mTJ68ad+TIET3xxBMaOHCghzIFUFeoe6DhoekGAMBHLVq0SBMmTNC4ceN08803a9myZWrSpIlWrFhxxZiKigo98MADmj17tjp16uTBbAHUBeoeaHhougEA8EHl5eXatm2b4uLiHGP+/v6Ki4tTXl7eFeN++9vfqnXr1nrwwQer3UdZWZlKSkqcHgC8xxN1L1H7gKfRdAMA4IOKiopUUVEhu93uNG6321VQUOAy5uOPP9by5cv18ssv12gfqampCg0NdTwiIyOvOW8A7vNE3UvUPuBpNN0AADQAZ8+e1ZgxY/Tyyy8rLCysRjEzZsxQcXGx43H06FGLswRQl9ype4naBzytkbcTAAAAVYWFhSkgIECFhYVO44WFhQoPD68y/6uvvtKRI0c0fPhwx1hlZaUkqVGjRvriiy904403OsXYbDbZbDYLsgfgDk/UvUTtA57GmW4AAHxQYGCgoqKilJOT4xirrKxUTk6OYmNjq8zv1q2bPv/8c+3cudPxGDFihAYPHqydO3dy+ShQD1D3QMPEmW4AAHxUcnKykpKS1L9/f0VHR2vx4sUqLS3VuHHjJEmJiYlq27atUlNTFRQUpJ49ezrFN2/eXJKqjAPwXdQ90PDQdAMA4KMSEhJ06tQpzZo1SwUFBerbt6+ys7MdP7KUn58vf38uWgMaEuoeaHhougEA8GGTJk3SpEmTXL6Wm5t71djMzMy6TwiA5ah7oGGh6b4GebN/71bcie8u1DrmX39t69a+glXkVhwA1+6cmexWXMu122sdc/E/b3ZrXwAAAPAdXJsCAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWKSRtxPwBSdjb/Do/gb+7bFax3TJKbIgE+D6tSPu927F3Z39uFtx/h0iax3z5Tj+XRQAAKC+4xMdAAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYJFG3k7AFxgPr0KXZ0s9u0MAVWQUd3crrnFppVtx+2eEuhUHpKena8GCBSooKFCfPn20dOlSRUdHu5z78ssva+XKldq9e7ckKSoqSnPnzr3ifAC+iboHGhbOdAMA4KNWr16t5ORkpaSkaPv27erTp4/i4+N18uRJl/Nzc3N133336YMPPlBeXp4iIyN111136fjx4x7OHIC7qHug4aHpBgDARy1atEgTJkzQuHHjdPPNN2vZsmVq0qSJVqxY4XL+a6+9pkceeUR9+/ZVt27d9Mc//lGVlZXKycnxcOYA3EXdAw0PTTcAAD6ovLxc27ZtU1xcnGPM399fcXFxysvLq9E2zp8/r4sXL6ply5ZWpQmgDlH3QMPEd7oBAPBBRUVFqqiokN1udxq32+3av39/jbYxbdo0RUREOH2Av1xZWZnKysocz0tKStxPGMA180TdS9Q+4Gmc6QYAoAFKS0tTVlaW1q1bp6CgIJdzUlNTFRoa6nhERkZ6OEsAdakmdS9R+4Cn0XQDAOCDwsLCFBAQoMLCQqfxwsJChYeHXzV24cKFSktL06ZNm9S7d+8rzpsxY4aKi4sdj6NHj9ZJ7gDc44m6l6h9wNNougEA8EGBgYGKiopy+jGkSz+OFBsbe8W4+fPna86cOcrOzlb//v2vug+bzaaQkBCnBwDv8UTdS9Q+4Gl8pxsAAB+VnJyspKQk9e/fX9HR0Vq8eLFKS0s1btw4SVJiYqLatm2r1NRUSdK8efM0a9YsrVq1Sh06dFBBQYEk6Uc/+pF+9KMfee04ANQcdQ80PDTdAAD4qISEBJ06dUqzZs1SQUGB+vbtq+zsbMePLOXn58vf/98Xrb344osqLy/Xz3/+c6ftpKSk6De/+Y0nUwfgJuoeaHhougEA8GGTJk3SpEmTXL6Wm5vr9PzIkSPWJwTActQ90LDwnW4AAAAAACxC0w0AAAAAgEW4vFxS2B/y3Iq7tcz1ZT/V7k+n3YoDUHeWvjvErbibjp11c49Xvl8qAAAAGi7OdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWaeTtBHxBwM1d3IoL23q6jjMB4Cmm5UW34r6cHFTHmQAAAKAh40w3AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMAAAAAYBGabgAAAAAALELTDQAAAACARWi6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAAAAAAIvQdAMA4MPS09PVoUMHBQUFKSYmRlu3br3q/DVr1qhbt24KCgpSr169tHHjRg9lCqCuUPdAw9KophOzdz9rZR4AfNCRxOneTgG4rq1evVrJyclatmyZYmJitHjxYsXHx+uLL75Q69atq8zfsmWL7rvvPqWmpmrYsGFatWqVRo0ape3bt6tnz55eOAIAtUXdAw2PnzHGeDsJAABQVUxMjP7jP/5Dv//97yVJlZWVioyM1GOPPabp06v+o1hCQoJKS0v19ttvO8b+8z//U3379tWyZcuq3V9JSYlCQ0NVXFyskJCQujsQoB7wlfe/p+te8p1jB7zBE+//Gp/pBgAAnlNeXq5t27ZpxowZjjF/f3/FxcUpLy/PZUxeXp6Sk5OdxuLj47V+/XqX88vKylRWVuZ4XlxcLOn7DyDA9ebS+96b56M8UfcStQ9czhO1T9MNAIAPKioqUkVFhex2u9O43W7X/v37XcYUFBS4nF9QUOByfmpqqmbPnl1lPDIy0s2sgfrv9OnTCg0N9cq+PVH3ErUPuGJl7dN0AwBwnZoxY4bTGbIzZ86offv2ys/P91rTcS1KSkoUGRmpo0eP1stLZMnfu4qLi9WuXTu1bNnS26lYjtr3LeTvXZ6ofZpuAAB8UFhYmAICAlRYWOg0XlhYqPDwcJcx4eHhtZpvs9lks9mqjIeGhtbLD06XhISEkL8X1ff8/f29d3MfT9S9RO37KvL3Litrn1uGAQDggwIDAxUVFaWcnBzHWGVlpXJychQbG+syJjY21mm+JG3evPmK8wH4FuoeaJg40w0AgI9KTk5WUlKS+vfvr+joaC1evFilpaUaN26cJCkxMVFt27ZVamqqJGny5MkaNGiQnnvuOQ0dOlRZWVn69NNP9dJLL3nzMADUAnUPNDw03QAA+KiEhASdOnVKs2bNUkFBgfr27avs7GzHjybl5+c7XQ43YMAArVq1SjNnztRTTz2lm266SevXr6/xvXptNptSUlJcXnZaH5C/d5F/3fB03Uu+c+zuIn/vIv/qcZ9uAAAAAAAswne6AQAAAACwCE03AAAAAAAWoekGAAAAAMAiNN0AAAAAAFiEphsAgAYsPT1dHTp0UFBQkGJiYrR169arzl+zZo26deumoKAg9erVSxs3bnR63RijWbNmqU2bNgoODlZcXJwOHDjgE/m//PLLGjhwoFq0aKEWLVooLi6uyvyxY8fKz8/P6TFkyBCfyD8zM7NKbkFBQU5zfHn9b7vttir5+/n5aejQoY45nlz/jz76SMOHD1dERIT8/Py0fv36amNyc3N1yy23yGazqXPnzsrMzKwyp7Y15Q3UPXXvqfyp+xoyAACgQcrKyjKBgYFmxYoVZs+ePWbChAmmefPmprCw0OX8Tz75xAQEBJj58+ebvXv3mpkzZ5rGjRubzz//3DEnLS3NhIaGmvXr15vPPvvMjBgxwnTs2NFcuHDB6/nff//9Jj093ezYscPs27fPjB071oSGhppjx4455iQlJZkhQ4aYEydOOB7ffPNNnefuTv4ZGRkmJCTEKbeCggKnOb68/qdPn3bKfffu3SYgIMBkZGQ45nhy/Tdu3Giefvpp88YbbxhJZt26dVedf+jQIdOkSROTnJxs9u7da5YuXWoCAgJMdna2Y05t18QbqHvq3pP5U/c1Q9MNAEADFR0dbR599FHH84qKChMREWFSU1Ndzv/FL35hhg4d6jQWExNjHnroIWOMMZWVlSY8PNwsWLDA8fqZM2eMzWYzr7/+utfz/6HvvvvONGvWzLzyyiuOsaSkJDNy5Mi6TtWl2uafkZFhQkNDr7i9+rb+zz//vGnWrJk5d+6cY8yT63+5mnz4njp1qunRo4fTWEJCgomPj3c8v9Y18QTqnrq/FtS9NXXP5eUAADRA5eXl2rZtm+Li4hxj/v7+iouLU15ensuYvLw8p/mSFB8f75h/+PBhFRQUOM0JDQ1VTEzMFbfpyfx/6Pz587p48aJatmzpNJ6bm6vWrVura9euevjhh3X69Ok6zV1yP/9z586pffv2ioyM1MiRI7Vnzx7Ha/Vt/ZcvX67Ro0eradOmTuOeWH93VPf+r4s1sRp1T917I//LUfeu0XQDANAAFRUVqaKiQna73WncbreroKDAZUxBQcFV51/6b2226S538v+hadOmKSIiwunD0pAhQ7Ry5Url5ORo3rx5+vDDD3X33XeroqLC6/l37dpVK1as0JtvvqlXX31VlZWVGjBggI4dOyapfq3/1q1btXv3bo0fP95p3FPr744rvf9LSkp04cKFOnlPWo26p+49nf/lqPsra1Qn2QIAAPiQtLQ0ZWVlKTc31+lHiUaPHu34c69evdS7d2/deOONys3N1R133OGNVB1iY2MVGxvreD5gwAB1795df/jDHzRnzhwvZlZ7y5cvV69evRQdHe007svrj/qPuvcu6v7KONMNAEADFBYWpoCAABUWFjqNFxYWKjw83GVMeHj4Vedf+m9ttukud/K/ZOHChUpLS9OmTZvUu3fvq87t1KmTwsLCdPDgwWvO+XLXkv8ljRs3Vr9+/Ry51Zf1Ly0tVVZWlh588MFq92PV+rvjSu//kJAQBQcH18nfqdWoe+r+WlD337Oi7mm6AQBogAIDAxUVFaWcnBzHWGVlpXJycpzOqlwuNjbWab4kbd682TG/Y8eOCg8Pd5pTUlKif/zjH1fcpifzl6T58+drzpw5ys7OVv/+/avdz7Fjx3T69Gm1adOmTvK+xN38L1dRUaHPP//ckVt9WH/p+9tPlZWV6Ze//GW1+7Fq/d1R3fu/Lv5OrUbdU/feyp+6r0aNf3INAADUK1lZWcZms5nMzEyzd+9eM3HiRNO8eXPH7WjGjBljpk+f7pj/ySefmEaNGpmFCxeaffv2mZSUFJe3DmrevLl58803za5du8zIkSMtvXVNbfJPS0szgYGBZu3atU63pjl79qwxxpizZ8+aJ554wuTl5ZnDhw+b9957z9xyyy3mpptuMt9++63X8589e7Z59913zVdffWW2bdtmRo8ebYKCgsyePXucjtFX1/+Sn/zkJyYhIaHKuKfX/+zZs2bHjh1mx44dRpJZtGiR2bFjh/n666+NMcZMnz7djBkzxjH/0q2DnnzySbNv3z6Tnp7u8tZBV1sTX0DdU/eezP8S6v7qaLoBAGjAli5datq1a2cCAwNNdHS0+fvf/+54bdCgQSYpKclp/p///GfTpUsXExgYaHr06GE2bNjg9HplZaV55plnjN1uNzabzdxxxx3miy++8In827dvbyRVeaSkpBhjjDl//ry56667TKtWrUzjxo1N+/btzYQJEyxtmGqT/5QpUxxz7Xa7ueeee8z27dudtufL62+MMfv37zeSzKZNm6psy9Pr/8EHH7h8P1zKOSkpyQwaNKhKTN++fU1gYKDp1KmT072GL7namvgK6p6691T+xlD3NeFnjDG1OgcPAAAAAABqhO90AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALAITTcAAAAAABah6QYAAAAAwCI03QAAAAAAWISmGwAAAAAAi9B0AwAAAABgEZpuAAAAAAAsQtMNAAAAAIBFaLoBAAAAALDI/wcaMoBUzJSOJAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1000 with 16 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imag, cls\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate a random tensor to simulate the model output\n",
    "model_output = outputs  # Simulating a batch of 4 images with 3 channels and 27x27 size\n",
    "\n",
    "# Set up the figure\n",
    "fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "\n",
    "# Loop through the images in the batch and display them\n",
    "for batch_idx in range(4):\n",
    "    for channel_idx in range(2):\n",
    "        ax = axes[batch_idx, channel_idx]\n",
    "        ax.imshow(model_output[batch_idx,channel_idx].cpu().detach().numpy())\n",
    "        ax.axis('off')  # Turn off axis\n",
    "        ax.set_title(f\"Batch {batch_idx+1}, Channel {channel_idx+1}\")\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model._modules['0'].kernel_circuits.weights.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 553
    },
    "id": "Tr1vbdXw2-tS",
    "outputId": "3f3b2195-2fb8-4060-f020-d08ffbd04ddb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class QuanvolutionLayer(nn.Module):\n",
    "    def __init__(self, kernel_size=(2, 2), stride=1, n_filters=1, filter_layers = 1):\n",
    "        super().__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.n_filters = n_filters\n",
    "        self.num_wires = kernel_size[0] * kernel_size[1]\n",
    "        self.filter_layer_size = np.random.randint(4, 2*self.num_wires*torch.floor(torch.log2(torch.tensor(self.num_wires))))\n",
    "        print(self.filter_layer_size)\n",
    "        self.filter_seeds = [\n",
    "            torch.randint(0, int(1e8), (1,)).item() for _ in range(self.n_filters)\n",
    "        ]\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.q_params = nn.Parameter(torch.randn(n_filters , filter_layers*self.filter_layer_size))\n",
    "        self.n_rotations_gate = filter_layers*self.filter_layer_size\n",
    "        self.kernel_h, self.kernel_w = self.kernel_size\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x (torch.Tensor): Input tensor of shape (batch_size, channels, height, width)\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: Output tensor of shape (batch_size, n_filters, new_height, new_width)\n",
    "        \"\"\"\n",
    "        batch_size, channels, height, width = x.shape\n",
    "        new_height = (height - self.kernel_h) // self.stride + 1\n",
    "        new_width = (width - self.kernel_w) // self.stride + 1\n",
    "        epsilon = 1e-8\n",
    "        # print(new_height, new_width)\n",
    "        # Prepare output tensor\n",
    "        output = torch.zeros((batch_size, self.n_filters, new_height, new_width), dtype=torch.float32).to(self.device)\n",
    "        \n",
    "        dev = qml.device(\"lightning.gpu\", wires=self.num_wires)\n",
    "        @qml.qnode(dev,interface='torch', diff_method='best')\n",
    "        def circuit(inputs, weights, seed = None):\n",
    "            # Encoding classical inputs\n",
    "            for j in range(self.num_wires):\n",
    "                qml.RY(np.pi * inputs[j], wires=j)\n",
    "        \n",
    "            # Add random quantum layers\n",
    "            RandomLayers(weights, \n",
    "                         wires=list(range(self.num_wires)),\n",
    "                         # rotations=[qml.PauliX,qml.PauliY,qml.PauliZ],\n",
    "                         seed = seed)\n",
    "                         \n",
    "        \n",
    "            # Measurement producing classical outputs\n",
    "            return [qml.expval(qml.PauliZ(j)) for j in range(self.num_wires)]\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            print(\"CUR BATCH: \" + str(b))\n",
    "            for i in range(0, height - self.kernel_h + 1, self.stride):  # Step by stride\n",
    "                for j in range(0, width - self.kernel_w + 1, self.stride):  # Step by stride\n",
    "                    if i + self.kernel_h <= height and j + self.kernel_w <= width:\n",
    "                        q_out = torch.zeros(self.n_filters, dtype=torch.float32).to(self.device)\n",
    "                        for c in range(channels):\n",
    "                            kernel = x[b, c, i:i + self.kernel_h, j:j + self.kernel_w].flatten()\n",
    "                            # print(\"kernel: \",kernel.size())\n",
    "                            kernel = kernel[:self.num_wires]  # Adjust to fit the number of qubits\n",
    "                            kernel = kernel / torch.max(torch.abs(kernel) + epsilon)  # Normalize\n",
    "                            for f in range(self.n_filters):\n",
    "                                quantum_output = torch.sum(torch.hstack(\n",
    "                                    circuit(inputs = kernel, weights = self.q_params[f].unsqueeze(0), seed = self.filter_seeds[f]))\n",
    "                                ).float()\n",
    "\n",
    "                                q_out[f] += quantum_output\n",
    "                        output[b, :, i // self.stride, j // self.stride] = q_out  # Update with stride indexing\n",
    "                        # print(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class DynLinear(nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super().__init__()\n",
    "        self.out_features = out_features\n",
    "        self.linear = None  # Placeholder for the Linear layer\n",
    "\n",
    "    def initialize_linear(self, in_features):\n",
    "        \"\"\"Dynamically initialize the Linear layer with the given input size.\"\"\"\n",
    "        self.linear = nn.Linear(in_features, self.out_features)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        self.linear.to(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.linear is None:\n",
    "            # Initialize the Linear layer on the first forward pass\n",
    "            in_features = x.shape[-1]\n",
    "            self.initialize_linear(in_features)\n",
    "        return self.linear(x)\n",
    "\n",
    "# Example Neural Network with Quanvolutional Layer\n",
    "class QuanvolutionalCNN(nn.Module):\n",
    "    def __init__(self, model_type = \"quantum\"):\n",
    "        super().__init__()\n",
    "        \n",
    "        if model_type == \"classic\":\n",
    "            self.conv_block = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(32),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                torch.nn.Dropout(0.5),\n",
    "                nn.Conv2d(32, 32, 3),\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(32, 64, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(64),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "                torch.nn.Dropout(0.3)\n",
    "            )\n",
    "        elif model_type == 'quantum':\n",
    "            self.conv_block = nn.Sequential(\n",
    "                QuanvolutionLayerTest(kernel_size=(2,2), n_filters=2, stride=2),\n",
    "                nn.ReLU(),\n",
    "                # nn.MaxPool2d(2, 2),                \n",
    "                nn.Conv2d(2,128,2),\n",
    "                # QuanvolutionLayerTest(kernel_size=(2,2), n_filters=2,stride=2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2, 2),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model type. Choose either 'classic' or 'quantum'.\")\n",
    "        self.model_type = model_type\n",
    "        # self.quanv = QuanvolutionLayer(kernel_size=(2, 2), n_filters=3)\n",
    "        # self.conv  = nn.Conv2d(1, 32,(2,2))\n",
    "        self.fc = nn.Sequential(\n",
    "            DynLinear(1024),  # Adjust based on quanv output shape\n",
    "            nn.ReLU(),\n",
    "            DynLinear(10)   # 10 classes for classification\n",
    "        )\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    def forward(self, x):\n",
    "        # x = self.quanv(x)\n",
    "        # if self.model_type == 'quantum':\n",
    "        #     x = x.cpu() # Somewhat reduce overhead in gpu copy operations when circuit is too small\n",
    "        \n",
    "        x = self.conv_block(x)\n",
    "        \n",
    "        x = nn.Flatten()(x)  # Flatten\n",
    "        x = self.fc(x)\n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Example Usage\n",
    "# if __name__ == \"__main__\":\n",
    "# Example batch of grayscale images (batch_size=1, channels=1, height=4, width=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics import MulticlassAccuracy\n",
    "from torcheval.metrics.functional import multiclass_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tYPANui-4jFo",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tStep: 100 \tLoss: 2.111 \tMean Loss: 2.085 \tMean Acc: 0.295\n",
      "Epoch: 1 \tStep: 200 \tLoss: 2.169 \tMean Loss: 2.007 \tMean Acc: 0.393\n",
      "Epoch: 1 \tStep: 300 \tLoss: 1.768 \tMean Loss: 1.878 \tMean Acc: 0.468\n",
      "Epoch: 1 \tStep: 400 \tLoss: 1.757 \tMean Loss: 1.877 \tMean Acc: 0.507\n",
      "Epoch: 1 \tStep: 500 \tLoss: 1.97 \tMean Loss: 1.793 \tMean Acc: 0.545\n",
      "Epoch: 1 \tStep: 600 \tLoss: 1.663 \tMean Loss: 1.834 \tMean Acc: 0.565\n",
      "Epoch: 1 \tStep: 700 \tLoss: 1.751 \tMean Loss: 1.817 \tMean Acc: 0.581\n",
      "Epoch: 1 \tStep: 800 \tLoss: 1.617 \tMean Loss: 1.759 \tMean Acc: 0.598\n",
      "Epoch: 1 \tStep: 900 \tLoss: 1.58 \tMean Loss: 1.782 \tMean Acc: 0.613\n",
      "Epoch: 1 \tStep: 1000 \tLoss: 1.742 \tMean Loss: 1.694 \tMean Acc: 0.629\n",
      "Epoch: 1 \tStep: 1100 \tLoss: 1.694 \tMean Loss: 1.739 \tMean Acc: 0.64\n",
      "Epoch: 1 \tStep: 1200 \tLoss: 1.721 \tMean Loss: 1.748 \tMean Acc: 0.647\n",
      "Epoch: 1 \tStep: 1300 \tLoss: 1.481 \tMean Loss: 1.733 \tMean Acc: 0.656\n",
      "Epoch: 1 \tStep: 1400 \tLoss: 2.232 \tMean Loss: 1.692 \tMean Acc: 0.666\n",
      "Epoch: 1 \tStep: 1500 \tLoss: 1.493 \tMean Loss: 1.679 \tMean Acc: 0.673\n",
      "Epoch: 1 \tStep: 1600 \tLoss: 1.792 \tMean Loss: 1.681 \tMean Acc: 0.682\n",
      "Epoch: 1 \tStep: 1700 \tLoss: 1.903 \tMean Loss: 1.656 \tMean Acc: 0.69\n",
      "Epoch: 1 \tStep: 1800 \tLoss: 1.489 \tMean Loss: 1.714 \tMean Acc: 0.694\n",
      "Epoch: 1 \tStep: 1900 \tLoss: 1.57 \tMean Loss: 1.62 \tMean Acc: 0.7\n",
      "Epoch: 1 \tStep: 2000 \tLoss: 1.703 \tMean Loss: 1.656 \tMean Acc: 0.703\n",
      "Epoch: 1 \tStep: 2100 \tLoss: 1.485 \tMean Loss: 1.664 \tMean Acc: 0.709\n",
      "Epoch: 1 \tStep: 2200 \tLoss: 1.892 \tMean Loss: 1.756 \tMean Acc: 0.712\n",
      "Epoch: 1 \tStep: 2300 \tLoss: 1.675 \tMean Loss: 1.691 \tMean Acc: 0.716\n",
      "Epoch: 1 \tStep: 2400 \tLoss: 1.535 \tMean Loss: 1.645 \tMean Acc: 0.719\n",
      "Epoch: 1 \tStep: 2500 \tLoss: 1.519 \tMean Loss: 1.601 \tMean Acc: 0.725\n",
      "Epoch: 1 \tStep: 2600 \tLoss: 1.514 \tMean Loss: 1.622 \tMean Acc: 0.73\n",
      "Epoch: 1 \tStep: 2700 \tLoss: 1.489 \tMean Loss: 1.606 \tMean Acc: 0.736\n",
      "Epoch: 1 \tStep: 2800 \tLoss: 1.665 \tMean Loss: 1.594 \tMean Acc: 0.741\n",
      "Epoch: 1 \tStep: 2900 \tLoss: 1.747 \tMean Loss: 1.672 \tMean Acc: 0.744\n",
      "Epoch: 1 \tStep: 3000 \tLoss: 1.819 \tMean Loss: 1.618 \tMean Acc: 0.746\n",
      "Epoch: 1 \tStep: 3100 \tLoss: 1.893 \tMean Loss: 1.672 \tMean Acc: 0.748\n",
      "Epoch: 1 \tStep: 3200 \tLoss: 1.666 \tMean Loss: 1.654 \tMean Acc: 0.75\n",
      "Epoch: 1 \tStep: 3300 \tLoss: 1.569 \tMean Loss: 1.685 \tMean Acc: 0.752\n",
      "Epoch: 1 \tStep: 3400 \tLoss: 1.464 \tMean Loss: 1.579 \tMean Acc: 0.755\n",
      "Epoch: 1 \tStep: 3500 \tLoss: 1.955 \tMean Loss: 1.677 \tMean Acc: 0.756\n",
      "Epoch: 1 \tStep: 3600 \tLoss: 1.474 \tMean Loss: 1.7 \tMean Acc: 0.758\n",
      "Epoch: 1 \tStep: 3700 \tLoss: 1.923 \tMean Loss: 1.764 \tMean Acc: 0.758\n",
      "Epoch: 1 \tStep: 3800 \tLoss: 1.865 \tMean Loss: 1.637 \tMean Acc: 0.76\n",
      "Epoch: 1 \tStep: 3900 \tLoss: 1.464 \tMean Loss: 1.576 \tMean Acc: 0.763\n",
      "Epoch: 1 \tStep: 4000 \tLoss: 1.462 \tMean Loss: 1.664 \tMean Acc: 0.764\n",
      "Epoch: 1 \tStep: 4100 \tLoss: 1.495 \tMean Loss: 1.599 \tMean Acc: 0.765\n",
      "Epoch: 1 \tStep: 4200 \tLoss: 1.636 \tMean Loss: 1.634 \tMean Acc: 0.768\n",
      "Epoch: 1 \tStep: 4300 \tLoss: 1.684 \tMean Loss: 1.614 \tMean Acc: 0.769\n",
      "Epoch: 1 \tStep: 4400 \tLoss: 1.592 \tMean Loss: 1.688 \tMean Acc: 0.771\n",
      "Epoch: 1 \tStep: 4500 \tLoss: 1.48 \tMean Loss: 1.614 \tMean Acc: 0.772\n",
      "Epoch: 1 \tStep: 4600 \tLoss: 2.057 \tMean Loss: 1.577 \tMean Acc: 0.775\n",
      "Epoch: 1 \tStep: 4700 \tLoss: 1.702 \tMean Loss: 1.598 \tMean Acc: 0.777\n",
      "Epoch: 1 \tStep: 4800 \tLoss: 1.696 \tMean Loss: 1.65 \tMean Acc: 0.778\n",
      "Epoch: 1 \tStep: 4900 \tLoss: 1.529 \tMean Loss: 1.579 \tMean Acc: 0.78\n",
      "Epoch: 1 \tStep: 5000 \tLoss: 1.588 \tMean Loss: 1.645 \tMean Acc: 0.782\n",
      "Epoch: 1 \tStep: 5100 \tLoss: 1.462 \tMean Loss: 1.639 \tMean Acc: 0.783\n",
      "Epoch: 1 \tStep: 5200 \tLoss: 1.711 \tMean Loss: 1.595 \tMean Acc: 0.785\n",
      "Epoch: 1 \tStep: 5300 \tLoss: 1.551 \tMean Loss: 1.56 \tMean Acc: 0.787\n",
      "Epoch: 1 \tStep: 5400 \tLoss: 1.689 \tMean Loss: 1.591 \tMean Acc: 0.789\n",
      "Epoch: 1 \tStep: 5500 \tLoss: 1.462 \tMean Loss: 1.588 \tMean Acc: 0.791\n",
      "Epoch: 1 \tStep: 5600 \tLoss: 1.466 \tMean Loss: 1.525 \tMean Acc: 0.792\n",
      "Epoch: 1 \tStep: 5700 \tLoss: 1.651 \tMean Loss: 1.647 \tMean Acc: 0.793\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \n\u001b[1;32m     20\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 21\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# output\u001b[39;00m\n\u001b[1;32m     24\u001b[0m acc \u001b[38;5;241m=\u001b[39m multiclass_accuracy(outputs, labels)\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     93\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/adam.py:223\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    211\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    213\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    214\u001b[0m         group,\n\u001b[1;32m    215\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    220\u001b[0m         state_steps,\n\u001b[1;32m    221\u001b[0m     )\n\u001b[0;32m--> 223\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/optimizer.py:154\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/adam.py:784\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    782\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 784\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/adam.py:595\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    594\u001b[0m     ]\n\u001b[0;32m--> 595\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdevice_state_steps\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    599\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n\u001b[1;32m    601\u001b[0m     bias_correction2_sqrt \u001b[38;5;241m=\u001b[39m [bc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction2]  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/optim/adam.py:595\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    592\u001b[0m     bias_correction1 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    593\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    594\u001b[0m     ]\n\u001b[0;32m--> 595\u001b[0m     bias_correction2 \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m _get_value(step) \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m device_state_steps\n\u001b[1;32m    597\u001b[0m     ]\n\u001b[1;32m    599\u001b[0m     step_size \u001b[38;5;241m=\u001b[39m _stack_if_compiling([(lr \u001b[38;5;241m/\u001b[39m bc) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction1])\n\u001b[1;32m    601\u001b[0m     bias_correction2_sqrt \u001b[38;5;241m=\u001b[39m [bc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m bc \u001b[38;5;129;01min\u001b[39;00m bias_correction2]  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = QuanvolutionalCNN(model_type = 'classic').to(torch.device('cuda'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logging_steps = 100\n",
    "\n",
    "metric = MulticlassAccuracy()\n",
    "losses = np.array([])\n",
    "accs = np.array([])\n",
    "global_step = 0\n",
    "for epoch in range(10):\n",
    "    \n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        \n",
    "        images = images.unsqueeze(1).cuda()\n",
    "        # print(images.size(), images.unsqueeze(1).size())\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        outputs = model(images).cpu()  # Forward pass\n",
    "        # print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # output\n",
    "        acc = multiclass_accuracy(outputs, labels)\n",
    "        \n",
    "        metric.update(outputs, labels)\n",
    "        losses = np.append(losses, loss.item())\n",
    "        global_step += 1\n",
    "        if global_step % logging_steps == 0:\n",
    "            print(\"Epoch:\", epoch+1, \n",
    "                \"\\tStep:\", global_step, \n",
    "                # \"\\tAcc:\", round(float(acc), 3), \n",
    "                \"\\tLoss:\", round(loss.item(),3),\n",
    "                \"\\tMean Loss:\", round(float(losses[-30:].mean()), 3),\n",
    "                \"\\tMean Acc:\", round(float(metric.compute()), 3)\n",
    "                )\n",
    "        # break\n",
    "\n",
    "        # losses = np.append(losses, loss.item())\n",
    "\n",
    "        # print(\"After update:\", model.quanv.q_params.grad)\n",
    "        # print(f\"Epoch {epoch + 1}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "QuanvolutionalCNN(\n",
      "  (conv_block): Sequential(\n",
      "    (0): QuanvolutionLayerTest(\n",
      "      (kernel_circuits): <Quantum Torch Layer: func=circuit>\n",
      "    )\n",
      "    (1): ReLU()\n",
      "    (2): Conv2d(2, 128, kernel_size=(2, 2), stride=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): DynLinear()\n",
      "    (1): ReLU()\n",
      "    (2): DynLinear()\n",
      "  )\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = QuanvolutionalCNN(model_type = 'quantum').cuda()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8548181056976318\n",
      "Parameter containing:\n",
      "tensor([[4.2612, 1.3891, 3.0786, 6.0641, 3.4129, 4.0442, 5.7357, 0.8055, 1.6506,\n",
      "         2.1684]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.991566896438599\n",
      "Epoch: 1 \tStep: 1 \tTime Elapse: 12.848729848861694 \tLoss: 2.251 \tMean Loss: 2.251 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9134106636047363\n",
      "Parameter containing:\n",
      "tensor([[4.2605, 1.3860, 3.0686, 6.0648, 3.4107, 4.0523, 5.7449, 0.7969, 1.6506,\n",
      "         2.1784]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.887458086013794\n",
      "Epoch: 1 \tStep: 2 \tTime Elapse: 25.66702127456665 \tLoss: 2.211 \tMean Loss: 2.231 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8146569728851318\n",
      "Parameter containing:\n",
      "tensor([[4.2575, 1.3800, 3.0597, 6.0678, 3.4062, 4.0585, 5.7518, 0.7900, 1.6506,\n",
      "         2.1873]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.676741361618042\n",
      "Epoch: 1 \tStep: 3 \tTime Elapse: 38.175132274627686 \tLoss: 2.2 \tMean Loss: 2.22 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7847075462341309\n",
      "Parameter containing:\n",
      "tensor([[4.2538, 1.3736, 3.0507, 6.0714, 3.4009, 4.0626, 5.7592, 0.7824, 1.6506,\n",
      "         2.1963]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.766790390014648\n",
      "Epoch: 1 \tStep: 4 \tTime Elapse: 50.7430317401886 \tLoss: 2.219 \tMean Loss: 2.22 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6206419467926025\n",
      "Parameter containing:\n",
      "tensor([[4.2528, 1.3709, 3.0473, 6.0725, 3.3993, 4.0687, 5.7592, 0.7835, 1.6506,\n",
      "         2.2015]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.760431051254272\n",
      "Epoch: 1 \tStep: 5 \tTime Elapse: 63.140347480773926 \tLoss: 2.435 \tMean Loss: 2.263 \tMean Acc: 0.2\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6276764869689941\n",
      "Parameter containing:\n",
      "tensor([[4.2513, 1.3681, 3.0447, 6.0740, 3.3972, 4.0749, 5.7587, 0.7850, 1.6506,\n",
      "         2.2069]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.514349699020386\n",
      "Epoch: 1 \tStep: 6 \tTime Elapse: 75.29917788505554 \tLoss: 2.201 \tMean Loss: 2.253 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8125600814819336\n",
      "Parameter containing:\n",
      "tensor([[4.2487, 1.3639, 3.0474, 6.0766, 3.3948, 4.0822, 5.7576, 0.7874, 1.6506,\n",
      "         2.2133]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.509855508804321\n",
      "Epoch: 1 \tStep: 7 \tTime Elapse: 87.63859176635742 \tLoss: 2.201 \tMean Loss: 2.245 \tMean Acc: 0.214\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8110039234161377\n",
      "Parameter containing:\n",
      "tensor([[4.2479, 1.3621, 3.0500, 6.0775, 3.3946, 4.0904, 5.7537, 0.7923, 1.6506,\n",
      "         2.2197]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.506015539169312\n",
      "Epoch: 1 \tStep: 8 \tTime Elapse: 99.97160315513611 \tLoss: 2.428 \tMean Loss: 2.268 \tMean Acc: 0.188\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8343186378479004\n",
      "Parameter containing:\n",
      "tensor([[4.2478, 1.3609, 3.0519, 6.0777, 3.3948, 4.0990, 5.7483, 0.7986, 1.6506,\n",
      "         2.2249]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.484620094299316\n",
      "Epoch: 1 \tStep: 9 \tTime Elapse: 112.30627202987671 \tLoss: 2.426 \tMean Loss: 2.286 \tMean Acc: 0.167\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6279010772705078\n",
      "Parameter containing:\n",
      "tensor([[4.2476, 1.3597, 3.0528, 6.0780, 3.3948, 4.1079, 5.7421, 0.8054, 1.6506,\n",
      "         2.2300]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.496355533599854\n",
      "Epoch: 1 \tStep: 10 \tTime Elapse: 124.44625329971313 \tLoss: 2.421 \tMean Loss: 2.299 \tMean Acc: 0.15\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7690315246582031\n",
      "Parameter containing:\n",
      "tensor([[4.2483, 1.3595, 3.0533, 6.0776, 3.3956, 4.1153, 5.7382, 0.8102, 1.6506,\n",
      "         2.2362]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.474633932113647\n",
      "Epoch: 1 \tStep: 11 \tTime Elapse: 136.70681929588318 \tLoss: 2.252 \tMean Loss: 2.295 \tMean Acc: 0.159\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7862229347229004\n",
      "Parameter containing:\n",
      "tensor([[4.2497, 1.3603, 3.0543, 6.0763, 3.3974, 4.1234, 5.7328, 0.8163, 1.6506,\n",
      "         2.2418]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.911146402359009\n",
      "Epoch: 1 \tStep: 12 \tTime Elapse: 149.42029190063477 \tLoss: 2.391 \tMean Loss: 2.303 \tMean Acc: 0.146\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8111004829406738\n",
      "Parameter containing:\n",
      "tensor([[4.2504, 1.3601, 3.0547, 6.0758, 3.3982, 4.1321, 5.7265, 0.8233, 1.6506,\n",
      "         2.2472]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.921881198883057\n",
      "Epoch: 1 \tStep: 13 \tTime Elapse: 162.1691188812256 \tLoss: 2.387 \tMean Loss: 2.309 \tMean Acc: 0.135\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6229009628295898\n",
      "Parameter containing:\n",
      "tensor([[4.2480, 1.3570, 3.0540, 6.0781, 3.3960, 4.1409, 5.7200, 0.8303, 1.6506,\n",
      "         2.2525]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.904228925704956\n",
      "Epoch: 1 \tStep: 14 \tTime Elapse: 174.71239495277405 \tLoss: 2.307 \tMean Loss: 2.309 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7901511192321777\n",
      "Parameter containing:\n",
      "tensor([[4.2449, 1.3528, 3.0542, 6.0812, 3.3933, 4.1455, 5.7165, 0.8342, 1.6506,\n",
      "         2.2576]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.922673463821411\n",
      "Epoch: 1 \tStep: 15 \tTime Elapse: 187.44193148612976 \tLoss: 2.177 \tMean Loss: 2.3 \tMean Acc: 0.133\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7818851470947266\n",
      "Parameter containing:\n",
      "tensor([[4.2400, 1.3470, 3.0571, 6.0860, 3.3892, 4.1471, 5.7163, 0.8350, 1.6506,\n",
      "         2.2641]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.906167984008789\n",
      "Epoch: 1 \tStep: 16 \tTime Elapse: 200.14878678321838 \tLoss: 2.162 \tMean Loss: 2.292 \tMean Acc: 0.156\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.617631435394287\n",
      "Parameter containing:\n",
      "tensor([[4.2383, 1.3437, 3.0553, 6.0878, 3.3869, 4.1467, 5.7175, 0.8345, 1.6506,\n",
      "         2.2701]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.717395305633545\n",
      "Epoch: 1 \tStep: 17 \tTime Elapse: 212.49951791763306 \tLoss: 2.211 \tMean Loss: 2.287 \tMean Acc: 0.162\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.618274211883545\n",
      "Parameter containing:\n",
      "tensor([[4.2393, 1.3436, 3.0534, 6.0869, 3.3879, 4.1479, 5.7177, 0.8353, 1.6506,\n",
      "         2.2765]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.547581911087036\n",
      "Epoch: 1 \tStep: 18 \tTime Elapse: 224.6813669204712 \tLoss: 2.385 \tMean Loss: 2.292 \tMean Acc: 0.153\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.784060001373291\n",
      "Parameter containing:\n",
      "tensor([[4.2429, 1.3464, 3.0529, 6.0835, 3.3919, 4.1510, 5.7165, 0.8374, 1.6506,\n",
      "         2.2837]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.553444385528564\n",
      "Epoch: 1 \tStep: 19 \tTime Elapse: 237.03521370887756 \tLoss: 2.392 \tMean Loss: 2.298 \tMean Acc: 0.145\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7769584655761719\n",
      "Parameter containing:\n",
      "tensor([[4.2486, 1.3515, 3.0526, 6.0781, 3.3978, 4.1562, 5.7142, 0.8411, 1.6506,\n",
      "         2.2918]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.54404616355896\n",
      "Epoch: 1 \tStep: 20 \tTime Elapse: 249.37208914756775 \tLoss: 2.357 \tMean Loss: 2.301 \tMean Acc: 0.138\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8020884990692139\n",
      "Parameter containing:\n",
      "tensor([[4.2551, 1.3574, 3.0549, 6.0716, 3.4047, 4.1626, 5.7105, 0.8458, 1.6506,\n",
      "         2.3007]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618466138839722\n",
      "Epoch: 1 \tStep: 21 \tTime Elapse: 261.80840253829956 \tLoss: 2.38 \tMean Loss: 2.304 \tMean Acc: 0.131\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6247994899749756\n",
      "Parameter containing:\n",
      "tensor([[4.2622, 1.3639, 3.0579, 6.0647, 3.4122, 4.1696, 5.7060, 0.8512, 1.6506,\n",
      "         2.3095]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.534477949142456\n",
      "Epoch: 1 \tStep: 22 \tTime Elapse: 273.9836525917053 \tLoss: 2.372 \tMean Loss: 2.307 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8147776126861572\n",
      "Parameter containing:\n",
      "tensor([[4.2669, 1.3679, 3.0607, 6.0601, 3.4171, 4.1758, 5.7030, 0.8555, 1.6506,\n",
      "         2.3187]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.569650173187256\n",
      "Epoch: 1 \tStep: 23 \tTime Elapse: 286.3840069770813 \tLoss: 2.26 \tMean Loss: 2.305 \tMean Acc: 0.13\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7748606204986572\n",
      "Parameter containing:\n",
      "tensor([[4.2689, 1.3691, 3.0608, 6.0585, 3.4185, 4.1809, 5.7008, 0.8587, 1.6506,\n",
      "         2.3281]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.904256582260132\n",
      "Epoch: 1 \tStep: 24 \tTime Elapse: 299.0790436267853 \tLoss: 2.27 \tMean Loss: 2.304 \tMean Acc: 0.135\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8359813690185547\n",
      "Parameter containing:\n",
      "tensor([[4.2719, 1.3714, 3.0608, 6.0557, 3.4211, 4.1864, 5.6986, 0.8623, 1.6506,\n",
      "         2.3364]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.561092853546143\n",
      "Epoch: 1 \tStep: 25 \tTime Elapse: 311.4920001029968 \tLoss: 2.36 \tMean Loss: 2.306 \tMean Acc: 0.13\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6144392490386963\n",
      "Parameter containing:\n",
      "tensor([[4.2755, 1.3744, 3.0610, 6.0522, 3.4245, 4.1921, 5.6966, 0.8657, 1.6506,\n",
      "         2.3451]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.542292833328247\n",
      "Epoch: 1 \tStep: 26 \tTime Elapse: 323.664644241333 \tLoss: 2.347 \tMean Loss: 2.308 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8123948574066162\n",
      "Parameter containing:\n",
      "tensor([[4.2808, 1.3792, 3.0588, 6.0468, 3.4294, 4.1982, 5.6953, 0.8689, 1.6506,\n",
      "         2.3546]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.498288631439209\n",
      "Epoch: 1 \tStep: 27 \tTime Elapse: 335.9908678531647 \tLoss: 2.256 \tMean Loss: 2.306 \tMean Acc: 0.12\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8245675563812256\n",
      "Parameter containing:\n",
      "tensor([[4.2867, 1.3844, 3.0557, 6.0409, 3.4350, 4.2051, 5.6928, 0.8728, 1.6506,\n",
      "         2.3644]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.51715612411499\n",
      "Epoch: 1 \tStep: 28 \tTime Elapse: 348.3486545085907 \tLoss: 2.341 \tMean Loss: 2.307 \tMean Acc: 0.116\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6186280250549316\n",
      "Parameter containing:\n",
      "tensor([[4.2935, 1.3906, 3.0509, 6.0338, 3.4416, 4.2085, 5.6936, 0.8739, 1.6506,\n",
      "         2.3743]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00774884223938\n",
      "Epoch: 1 \tStep: 29 \tTime Elapse: 360.9909725189209 \tLoss: 2.097 \tMean Loss: 2.3 \tMean Acc: 0.138\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.62107253074646\n",
      "Parameter containing:\n",
      "tensor([[4.2995, 1.3960, 3.0464, 6.0277, 3.4473, 4.2129, 5.6931, 0.8760, 1.6506,\n",
      "         2.3847]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.918187379837036\n",
      "Epoch: 1 \tStep: 30 \tTime Elapse: 373.5462529659271 \tLoss: 2.346 \tMean Loss: 2.301 \tMean Acc: 0.133\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7832775115966797\n",
      "Parameter containing:\n",
      "tensor([[4.3052, 1.4011, 3.0425, 6.0218, 3.4528, 4.2182, 5.6917, 0.8790, 1.6506,\n",
      "         2.3953]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.92720651626587\n",
      "Epoch: 1 \tStep: 31 \tTime Elapse: 386.27272391319275 \tLoss: 2.386 \tMean Loss: 2.306 \tMean Acc: 0.129\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8029499053955078\n",
      "Parameter containing:\n",
      "tensor([[4.3089, 1.4042, 3.0383, 6.0181, 3.4561, 4.2219, 5.6911, 0.8812, 1.6506,\n",
      "         2.4046]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.896429538726807\n",
      "Epoch: 1 \tStep: 32 \tTime Elapse: 398.9880385398865 \tLoss: 2.204 \tMean Loss: 2.306 \tMean Acc: 0.133\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8079657554626465\n",
      "Parameter containing:\n",
      "tensor([[4.3104, 1.4049, 3.0342, 6.0169, 3.4567, 4.2255, 5.6906, 0.8831, 1.6506,\n",
      "         2.4143]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.891864538192749\n",
      "Epoch: 1 \tStep: 33 \tTime Elapse: 411.70396518707275 \tLoss: 2.195 \tMean Loss: 2.306 \tMean Acc: 0.136\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6162238121032715\n",
      "Parameter containing:\n",
      "tensor([[4.3126, 1.4066, 3.0309, 6.0150, 3.4582, 4.2283, 5.6907, 0.8846, 1.6506,\n",
      "         2.4230]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.883158206939697\n",
      "Epoch: 1 \tStep: 34 \tTime Elapse: 424.2192623615265 \tLoss: 2.219 \tMean Loss: 2.306 \tMean Acc: 0.14\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8005120754241943\n",
      "Parameter containing:\n",
      "tensor([[4.3139, 1.4075, 3.0278, 6.0139, 3.4589, 4.2332, 5.6889, 0.8875, 1.6506,\n",
      "         2.4325]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.896267175674438\n",
      "Epoch: 1 \tStep: 35 \tTime Elapse: 436.9319944381714 \tLoss: 2.394 \tMean Loss: 2.304 \tMean Acc: 0.136\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.816702127456665\n",
      "Parameter containing:\n",
      "tensor([[4.3146, 1.4078, 3.0248, 6.0135, 3.4589, 4.2398, 5.6858, 0.8916, 1.6506,\n",
      "         2.4429]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.89157748222351\n",
      "Epoch: 1 \tStep: 36 \tTime Elapse: 449.6564779281616 \tLoss: 2.39 \tMean Loss: 2.31 \tMean Acc: 0.132\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.816922664642334\n",
      "Parameter containing:\n",
      "tensor([[4.3151, 1.4079, 3.0222, 6.0133, 3.4588, 4.2471, 5.6819, 0.8964, 1.6506,\n",
      "         2.4532]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.552231073379517\n",
      "Epoch: 1 \tStep: 37 \tTime Elapse: 462.04189109802246 \tLoss: 2.425 \tMean Loss: 2.318 \tMean Acc: 0.128\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6265833377838135\n",
      "Parameter containing:\n",
      "tensor([[4.3155, 1.4079, 3.0201, 6.0132, 3.4586, 4.2555, 5.6769, 0.9021, 1.6506,\n",
      "         2.4639]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.584477663040161\n",
      "Epoch: 1 \tStep: 38 \tTime Elapse: 474.2689197063446 \tLoss: 2.393 \tMean Loss: 2.317 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8014791011810303\n",
      "Parameter containing:\n",
      "tensor([[4.3150, 1.4071, 3.0182, 6.0140, 3.4574, 4.2630, 5.6726, 0.9070, 1.6506,\n",
      "         2.4738]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.553727388381958\n",
      "Epoch: 1 \tStep: 39 \tTime Elapse: 486.6403343677521 \tLoss: 2.205 \tMean Loss: 2.309 \tMean Acc: 0.128\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.803300142288208\n",
      "Parameter containing:\n",
      "tensor([[4.3139, 1.4056, 3.0173, 6.0156, 3.4555, 4.2717, 5.6673, 0.9130, 1.6506,\n",
      "         2.4847]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.916631937026978\n",
      "Epoch: 1 \tStep: 40 \tTime Elapse: 499.37629866600037 \tLoss: 2.375 \tMean Loss: 2.308 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6237766742706299\n",
      "Parameter containing:\n",
      "tensor([[4.3136, 1.4049, 3.0162, 6.0161, 3.4546, 4.2812, 5.6609, 0.9197, 1.6506,\n",
      "         2.4961]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.078506231307983\n",
      "Epoch: 1 \tStep: 41 \tTime Elapse: 512.0946218967438 \tLoss: 2.35 \tMean Loss: 2.311 \tMean Acc: 0.122\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6412336826324463\n",
      "Parameter containing:\n",
      "tensor([[4.3121, 1.4028, 3.0152, 6.0179, 3.4523, 4.2911, 5.6542, 0.9267, 1.6506,\n",
      "         2.5077]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.909255027770996\n",
      "Epoch: 1 \tStep: 42 \tTime Elapse: 524.6611108779907 \tLoss: 2.3 \tMean Loss: 2.308 \tMean Acc: 0.119\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.787750244140625\n",
      "Parameter containing:\n",
      "tensor([[4.3110, 1.4010, 3.0143, 6.0194, 3.4503, 4.3015, 5.6474, 0.9338, 1.6506,\n",
      "         2.5199]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.91040301322937\n",
      "Epoch: 1 \tStep: 43 \tTime Elapse: 537.3751327991486 \tLoss: 2.338 \tMean Loss: 2.306 \tMean Acc: 0.116\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8027687072753906\n",
      "Parameter containing:\n",
      "tensor([[4.3096, 1.3990, 3.0134, 6.0211, 3.4482, 4.3104, 5.6420, 0.9399, 1.6506,\n",
      "         2.5308]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.899120807647705\n",
      "Epoch: 1 \tStep: 44 \tTime Elapse: 550.0931315422058 \tLoss: 2.275 \tMean Loss: 2.305 \tMean Acc: 0.119\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.807917594909668\n",
      "Parameter containing:\n",
      "tensor([[4.3071, 1.3960, 3.0122, 6.0239, 3.4447, 4.3191, 5.6371, 0.9456, 1.6506,\n",
      "         2.5418]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.904514074325562\n",
      "Epoch: 1 \tStep: 45 \tTime Elapse: 562.8223121166229 \tLoss: 2.224 \tMean Loss: 2.307 \tMean Acc: 0.122\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6095898151397705\n",
      "Parameter containing:\n",
      "tensor([[4.3029, 1.3914, 3.0089, 6.0285, 3.4394, 4.3282, 5.6320, 0.9515, 1.6506,\n",
      "         2.5532]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.911520719528198\n",
      "Epoch: 1 \tStep: 46 \tTime Elapse: 575.3595933914185 \tLoss: 2.293 \tMean Loss: 2.311 \tMean Acc: 0.12\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7839124202728271\n",
      "Parameter containing:\n",
      "tensor([[4.2997, 1.3877, 3.0047, 6.0321, 3.4351, 4.3354, 5.6287, 0.9562, 1.6506,\n",
      "         2.5645]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.895084857940674\n",
      "Epoch: 1 \tStep: 47 \tTime Elapse: 588.0555682182312 \tLoss: 2.232 \tMean Loss: 2.312 \tMean Acc: 0.128\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7922790050506592\n",
      "Parameter containing:\n",
      "tensor([[4.2946, 1.3823, 2.9990, 6.0376, 3.4289, 4.3400, 5.6267, 0.9596, 1.6506,\n",
      "         2.5754]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.54013705253601\n",
      "Epoch: 1 \tStep: 48 \tTime Elapse: 600.4040200710297 \tLoss: 2.202 \tMean Loss: 2.306 \tMean Acc: 0.135\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8155932426452637\n",
      "Parameter containing:\n",
      "tensor([[4.2890, 1.3765, 2.9950, 6.0434, 3.4226, 4.3449, 5.6245, 0.9630, 1.6506,\n",
      "         2.5861]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.546307563781738\n",
      "Epoch: 1 \tStep: 49 \tTime Elapse: 612.7818977832794 \tLoss: 2.313 \tMean Loss: 2.303 \tMean Acc: 0.133\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6276743412017822\n",
      "Parameter containing:\n",
      "tensor([[4.2836, 1.3708, 2.9890, 6.0491, 3.4164, 4.3484, 5.6234, 0.9655, 1.6506,\n",
      "         2.5958]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.527229309082031\n",
      "Epoch: 1 \tStep: 50 \tTime Elapse: 624.9529983997345 \tLoss: 2.256 \tMean Loss: 2.3 \tMean Acc: 0.135\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.795428991317749\n",
      "Parameter containing:\n",
      "tensor([[4.2807, 1.3676, 2.9848, 6.0524, 3.4128, 4.3532, 5.6216, 0.9686, 1.6506,\n",
      "         2.6063]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.911103248596191\n",
      "Epoch: 1 \tStep: 51 \tTime Elapse: 637.6753721237183 \tLoss: 2.316 \tMean Loss: 2.298 \tMean Acc: 0.132\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.803133487701416\n",
      "Parameter containing:\n",
      "tensor([[4.2788, 1.3655, 2.9810, 6.0546, 3.4103, 4.3592, 5.6189, 0.9724, 1.6506,\n",
      "         2.6170]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.907678365707397\n",
      "Epoch: 1 \tStep: 52 \tTime Elapse: 650.4023349285126 \tLoss: 2.367 \tMean Loss: 2.298 \tMean Acc: 0.13\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6399955749511719\n",
      "Parameter containing:\n",
      "tensor([[4.2787, 1.3651, 2.9794, 6.0551, 3.4098, 4.3660, 5.6153, 0.9765, 1.6506,\n",
      "         2.6279]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.030117511749268\n",
      "Epoch: 1 \tStep: 53 \tTime Elapse: 663.0884463787079 \tLoss: 2.343 \tMean Loss: 2.3 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6413929462432861\n",
      "Parameter containing:\n",
      "tensor([[4.2778, 1.3640, 2.9766, 6.0563, 3.4086, 4.3706, 5.6129, 0.9798, 1.6506,\n",
      "         2.6371]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.525171279907227\n",
      "Epoch: 1 \tStep: 54 \tTime Elapse: 675.2713642120361 \tLoss: 2.232 \tMean Loss: 2.299 \tMean Acc: 0.13\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.914433240890503\n",
      "Parameter containing:\n",
      "tensor([[4.2766, 1.3625, 2.9739, 6.0578, 3.4070, 4.3761, 5.6098, 0.9835, 1.6506,\n",
      "         2.6463]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.566394805908203\n",
      "Epoch: 1 \tStep: 55 \tTime Elapse: 687.7679605484009 \tLoss: 2.372 \tMean Loss: 2.3 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7898123264312744\n",
      "Parameter containing:\n",
      "tensor([[4.2757, 1.3613, 2.9728, 6.0589, 3.4059, 4.3802, 5.6089, 0.9860, 1.6506,\n",
      "         2.6545]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.557588577270508\n",
      "Epoch: 1 \tStep: 56 \tTime Elapse: 700.1316084861755 \tLoss: 2.222 \tMean Loss: 2.295 \tMean Acc: 0.129\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8252732753753662\n",
      "Parameter containing:\n",
      "tensor([[4.2756, 1.3610, 2.9728, 6.0592, 3.4056, 4.3854, 5.6070, 0.9889, 1.6506,\n",
      "         2.6628]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.541484832763672\n",
      "Epoch: 1 \tStep: 57 \tTime Elapse: 712.514684677124 \tLoss: 2.323 \tMean Loss: 2.298 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6286911964416504\n",
      "Parameter containing:\n",
      "tensor([[4.2761, 1.3609, 2.9732, 6.0591, 3.4058, 4.3912, 5.6045, 0.9923, 1.6506,\n",
      "         2.6714]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.55088496208191\n",
      "Epoch: 1 \tStep: 58 \tTime Elapse: 724.7107083797455 \tLoss: 2.341 \tMean Loss: 2.298 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7759571075439453\n",
      "Parameter containing:\n",
      "tensor([[4.2753, 1.3598, 2.9719, 6.0600, 3.4049, 4.3958, 5.6030, 0.9952, 1.6506,\n",
      "         2.6791]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.588075160980225\n",
      "Epoch: 1 \tStep: 59 \tTime Elapse: 737.090470790863 \tLoss: 2.242 \tMean Loss: 2.302 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8000860214233398\n",
      "Parameter containing:\n",
      "tensor([[4.2733, 1.3576, 2.9698, 6.0621, 3.4027, 4.4009, 5.6009, 0.9983, 1.6506,\n",
      "         2.6870]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.554574251174927\n",
      "Epoch: 1 \tStep: 60 \tTime Elapse: 749.4614295959473 \tLoss: 2.355 \tMean Loss: 2.303 \tMean Acc: 0.125\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8323020935058594\n",
      "Parameter containing:\n",
      "tensor([[4.2716, 1.3558, 2.9677, 6.0639, 3.4009, 4.4069, 5.5982, 1.0018, 1.6506,\n",
      "         2.6954]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.561042308807373\n",
      "Epoch: 1 \tStep: 61 \tTime Elapse: 761.8707356452942 \tLoss: 2.38 \tMean Loss: 2.302 \tMean Acc: 0.123\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6232259273529053\n",
      "Parameter containing:\n",
      "tensor([[4.2699, 1.3539, 2.9651, 6.0656, 3.3991, 4.4133, 5.5948, 1.0056, 1.6506,\n",
      "         2.7038]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.92138385772705\n",
      "Epoch: 1 \tStep: 62 \tTime Elapse: 774.4319026470184 \tLoss: 2.36 \tMean Loss: 2.308 \tMean Acc: 0.121\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8082656860351562\n",
      "Parameter containing:\n",
      "tensor([[4.2688, 1.3524, 2.9619, 6.0668, 3.3978, 4.4182, 5.5926, 1.0086, 1.6506,\n",
      "         2.7122]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.901129722595215\n",
      "Epoch: 1 \tStep: 63 \tTime Elapse: 787.1568551063538 \tLoss: 2.208 \tMean Loss: 2.308 \tMean Acc: 0.123\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.814668893814087\n",
      "Parameter containing:\n",
      "tensor([[4.2673, 1.3502, 2.9565, 6.0683, 3.3959, 4.4217, 5.5909, 1.0112, 1.6506,\n",
      "         2.7194]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.589070320129395\n",
      "Epoch: 1 \tStep: 64 \tTime Elapse: 799.5771808624268 \tLoss: 2.199 \tMean Loss: 2.307 \tMean Acc: 0.129\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.758406162261963\n",
      "Parameter containing:\n",
      "tensor([[4.2657, 1.3477, 2.9516, 6.0700, 3.3940, 4.4253, 5.5889, 1.0137, 1.6506,\n",
      "         2.7267]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.743777990341187\n",
      "Epoch: 1 \tStep: 65 \tTime Elapse: 812.0957877635956 \tLoss: 2.354 \tMean Loss: 2.306 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7644171714782715\n",
      "Parameter containing:\n",
      "tensor([[4.2640, 1.3453, 2.9467, 6.0716, 3.3920, 4.4287, 5.5868, 1.0161, 1.6506,\n",
      "         2.7335]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.578670024871826\n",
      "Epoch: 1 \tStep: 66 \tTime Elapse: 824.4554235935211 \tLoss: 2.321 \tMean Loss: 2.304 \tMean Acc: 0.129\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.92515230178833\n",
      "Parameter containing:\n",
      "tensor([[4.2621, 1.3428, 2.9416, 6.0734, 3.3898, 4.4327, 5.5843, 1.0187, 1.6506,\n",
      "         2.7404]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.613490581512451\n",
      "Epoch: 1 \tStep: 67 \tTime Elapse: 837.0095875263214 \tLoss: 2.328 \tMean Loss: 2.301 \tMean Acc: 0.127\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.946045160293579\n",
      "Parameter containing:\n",
      "tensor([[4.2613, 1.3412, 2.9366, 6.0742, 3.3885, 4.4332, 5.5849, 1.0194, 1.6506,\n",
      "         2.7450]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.839128494262695\n",
      "Epoch: 1 \tStep: 68 \tTime Elapse: 849.8110244274139 \tLoss: 2.141 \tMean Loss: 2.292 \tMean Acc: 0.136\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9678688049316406\n",
      "Parameter containing:\n",
      "tensor([[4.2588, 1.3379, 2.9316, 6.0766, 3.3857, 4.4338, 5.5850, 1.0203, 1.6506,\n",
      "         2.7497]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00625467300415\n",
      "Epoch: 1 \tStep: 69 \tTime Elapse: 862.8021385669708 \tLoss: 2.295 \tMean Loss: 2.295 \tMean Acc: 0.134\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.762190580368042\n",
      "Parameter containing:\n",
      "tensor([[4.2561, 1.3343, 2.9270, 6.0791, 3.3829, 4.4325, 5.5866, 1.0205, 1.6506,\n",
      "         2.7529]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.001275300979614\n",
      "Epoch: 1 \tStep: 70 \tTime Elapse: 875.5818293094635 \tLoss: 2.206 \tMean Loss: 2.29 \tMean Acc: 0.139\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9468994140625\n",
      "Parameter containing:\n",
      "tensor([[4.2526, 1.3298, 2.9221, 6.0823, 3.3792, 4.4331, 5.5869, 1.0214, 1.6506,\n",
      "         2.7571]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.636313915252686\n",
      "Epoch: 1 \tStep: 71 \tTime Elapse: 888.1809508800507 \tLoss: 2.306 \tMean Loss: 2.288 \tMean Acc: 0.137\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9598736763000488\n",
      "Parameter containing:\n",
      "tensor([[4.2495, 1.3258, 2.9175, 6.0851, 3.3759, 4.4347, 5.5863, 1.0228, 1.6506,\n",
      "         2.7620]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62616777420044\n",
      "Epoch: 1 \tStep: 72 \tTime Elapse: 900.7836863994598 \tLoss: 2.363 \tMean Loss: 2.29 \tMean Acc: 0.135\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.923079490661621\n",
      "Parameter containing:\n",
      "tensor([[4.2447, 1.3200, 2.9121, 6.0894, 3.3711, 4.4348, 5.5862, 1.0236, 1.6506,\n",
      "         2.7656]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.975227355957031\n",
      "Epoch: 1 \tStep: 73 \tTime Elapse: 913.697919845581 \tLoss: 2.217 \tMean Loss: 2.286 \tMean Acc: 0.137\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7530112266540527\n",
      "Parameter containing:\n",
      "tensor([[4.2403, 1.3145, 2.9069, 6.0933, 3.3666, 4.4348, 5.5860, 1.0242, 1.6506,\n",
      "         2.7695]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.839137315750122\n",
      "Epoch: 1 \tStep: 74 \tTime Elapse: 926.3067982196808 \tLoss: 2.29 \tMean Loss: 2.287 \tMean Acc: 0.139\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8943572044372559\n",
      "Parameter containing:\n",
      "tensor([[4.2347, 1.3077, 2.9009, 6.0982, 3.3612, 4.4354, 5.5850, 1.0254, 1.6506,\n",
      "         2.7743]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.653109073638916\n",
      "Epoch: 1 \tStep: 75 \tTime Elapse: 938.870142698288 \tLoss: 2.282 \tMean Loss: 2.289 \tMean Acc: 0.14\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9525165557861328\n",
      "Parameter containing:\n",
      "tensor([[4.2297, 1.3016, 2.8958, 6.1026, 3.3563, 4.4369, 5.5834, 1.0268, 1.6506,\n",
      "         2.7794]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.612677335739136\n",
      "Epoch: 1 \tStep: 76 \tTime Elapse: 951.4519286155701 \tLoss: 2.397 \tMean Loss: 2.292 \tMean Acc: 0.138\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7570624351501465\n",
      "Parameter containing:\n",
      "tensor([[4.2250, 1.2961, 2.8910, 6.1066, 3.3518, 4.4392, 5.5814, 1.0286, 1.6506,\n",
      "         2.7852]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.834622144699097\n",
      "Epoch: 1 \tStep: 77 \tTime Elapse: 964.0595722198486 \tLoss: 2.371 \tMean Loss: 2.297 \tMean Acc: 0.136\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.772864818572998\n",
      "Parameter containing:\n",
      "tensor([[4.2219, 1.2916, 2.8877, 6.1095, 3.3487, 4.4384, 5.5825, 1.0289, 1.6506,\n",
      "         2.7882]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.658795356750488\n",
      "Epoch: 1 \tStep: 78 \tTime Elapse: 976.5079185962677 \tLoss: 2.156 \tMean Loss: 2.295 \tMean Acc: 0.141\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9409234523773193\n",
      "Parameter containing:\n",
      "tensor([[4.2173, 1.2857, 2.8822, 6.1134, 3.3444, 4.4355, 5.5851, 1.0282, 1.6506,\n",
      "         2.7899]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.657777070999146\n",
      "Epoch: 1 \tStep: 79 \tTime Elapse: 989.1228702068329 \tLoss: 2.158 \tMean Loss: 2.29 \tMean Acc: 0.146\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9516737461090088\n",
      "Parameter containing:\n",
      "tensor([[4.2148, 1.2818, 2.8782, 6.1157, 3.3418, 4.4342, 5.5866, 1.0283, 1.6506,\n",
      "         2.7930]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638550519943237\n",
      "Epoch: 1 \tStep: 80 \tTime Elapse: 1001.7294611930847 \tLoss: 2.303 \tMean Loss: 2.292 \tMean Acc: 0.144\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9522202014923096\n",
      "Parameter containing:\n",
      "tensor([[4.2125, 1.2781, 2.8747, 6.1178, 3.3393, 4.4347, 5.5869, 1.0291, 1.6506,\n",
      "         2.7973]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.858344316482544\n",
      "Epoch: 1 \tStep: 81 \tTime Elapse: 1014.5561323165894 \tLoss: 2.359 \tMean Loss: 2.293 \tMean Acc: 0.142\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7638797760009766\n",
      "Parameter containing:\n",
      "tensor([[4.2107, 1.2753, 2.8726, 6.1196, 3.3373, 4.4360, 5.5863, 1.0304, 1.6506,\n",
      "         2.8024]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.622558116912842\n",
      "Epoch: 1 \tStep: 82 \tTime Elapse: 1026.958886384964 \tLoss: 2.339 \tMean Loss: 2.292 \tMean Acc: 0.14\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9303898811340332\n",
      "Parameter containing:\n",
      "tensor([[4.2080, 1.2716, 2.8696, 6.1219, 3.3347, 4.4371, 5.5858, 1.0316, 1.6506,\n",
      "         2.8075]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.639281511306763\n",
      "Epoch: 1 \tStep: 83 \tTime Elapse: 1039.5442831516266 \tLoss: 2.272 \tMean Loss: 2.29 \tMean Acc: 0.142\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.957869529724121\n",
      "Parameter containing:\n",
      "tensor([[4.2057, 1.2683, 2.8667, 6.1240, 3.3324, 4.4392, 5.5847, 1.0331, 1.6506,\n",
      "         2.8132]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.871151447296143\n",
      "Epoch: 1 \tStep: 84 \tTime Elapse: 1052.389845609665 \tLoss: 2.372 \tMean Loss: 2.294 \tMean Acc: 0.14\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.969123363494873\n",
      "Parameter containing:\n",
      "tensor([[4.2023, 1.2638, 2.8641, 6.1268, 3.3295, 4.4390, 5.5847, 1.0339, 1.6506,\n",
      "         2.8178]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.87586522102356\n",
      "Epoch: 1 \tStep: 85 \tTime Elapse: 1065.2508387565613 \tLoss: 2.149 \tMean Loss: 2.287 \tMean Acc: 0.144\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.793590784072876\n",
      "Parameter containing:\n",
      "tensor([[4.1989, 1.2590, 2.8594, 6.1295, 3.3263, 4.4383, 5.5845, 1.0347, 1.6506,\n",
      "         2.8223]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.836079835891724\n",
      "Epoch: 1 \tStep: 86 \tTime Elapse: 1077.897207736969 \tLoss: 2.285 \tMean Loss: 2.289 \tMean Acc: 0.145\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9741370677947998\n",
      "Parameter containing:\n",
      "tensor([[4.1978, 1.2563, 2.8575, 6.1307, 3.3250, 4.4376, 5.5850, 1.0353, 1.6506,\n",
      "         2.8265]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.850834846496582\n",
      "Epoch: 1 \tStep: 87 \tTime Elapse: 1090.7382535934448 \tLoss: 2.213 \tMean Loss: 2.285 \tMean Acc: 0.147\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.985743761062622\n",
      "Parameter containing:\n",
      "tensor([[4.1979, 1.2549, 2.8566, 6.1309, 3.3248, 4.4367, 5.5862, 1.0357, 1.6506,\n",
      "         2.8303]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.774163246154785\n",
      "Epoch: 1 \tStep: 88 \tTime Elapse: 1103.514620065689 \tLoss: 2.285 \tMean Loss: 2.284 \tMean Acc: 0.148\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.740774154663086\n",
      "Parameter containing:\n",
      "tensor([[4.1977, 1.2531, 2.8541, 6.1313, 3.3242, 4.4331, 5.5893, 1.0350, 1.6506,\n",
      "         2.8317]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.988762378692627\n",
      "Epoch: 1 \tStep: 89 \tTime Elapse: 1116.2601280212402 \tLoss: 2.195 \tMean Loss: 2.282 \tMean Acc: 0.152\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7599363327026367\n",
      "Parameter containing:\n",
      "tensor([[4.2007, 1.2544, 2.8501, 6.1294, 3.3258, 4.4281, 5.5939, 1.0335, 1.6506,\n",
      "         2.8320]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.825103044509888\n",
      "Epoch: 1 \tStep: 90 \tTime Elapse: 1128.862023115158 \tLoss: 2.195 \tMean Loss: 2.277 \tMean Acc: 0.156\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9603681564331055\n",
      "Parameter containing:\n",
      "tensor([[4.2013, 1.2535, 2.8429, 6.1291, 3.3255, 4.4242, 5.5976, 1.0325, 1.6506,\n",
      "         2.8335]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.852263450622559\n",
      "Epoch: 1 \tStep: 91 \tTime Elapse: 1141.6909408569336 \tLoss: 2.205 \tMean Loss: 2.271 \tMean Acc: 0.157\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.977701187133789\n",
      "Parameter containing:\n",
      "tensor([[4.2029, 1.2536, 2.8367, 6.1281, 3.3261, 4.4198, 5.6019, 1.0313, 1.6506,\n",
      "         2.8351]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.84404706954956\n",
      "Epoch: 1 \tStep: 92 \tTime Elapse: 1154.5295014381409 \tLoss: 2.202 \tMean Loss: 2.266 \tMean Acc: 0.158\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.0112030506134033\n",
      "Parameter containing:\n",
      "tensor([[4.2028, 1.2520, 2.8297, 6.1284, 3.3254, 4.4147, 5.6064, 1.0298, 1.6506,\n",
      "         2.8360]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00244426727295\n",
      "Epoch: 1 \tStep: 93 \tTime Elapse: 1167.559084892273 \tLoss: 2.278 \tMean Loss: 2.268 \tMean Acc: 0.159\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8102836608886719\n",
      "Parameter containing:\n",
      "tensor([[4.1998, 1.2475, 2.8191, 6.1308, 3.3221, 4.4080, 5.6113, 1.0277, 1.6506,\n",
      "         2.8358]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.627781867980957\n",
      "Epoch: 1 \tStep: 94 \tTime Elapse: 1180.0147387981415 \tLoss: 2.083 \tMean Loss: 2.264 \tMean Acc: 0.162\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9639501571655273\n",
      "Parameter containing:\n",
      "tensor([[4.1957, 1.2418, 2.8078, 6.1341, 3.3179, 4.4014, 5.6160, 1.0259, 1.6506,\n",
      "         2.8356]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.672328472137451\n",
      "Epoch: 1 \tStep: 95 \tTime Elapse: 1192.6679255962372 \tLoss: 2.242 \tMean Loss: 2.26 \tMean Acc: 0.163\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9892504215240479\n",
      "Parameter containing:\n",
      "tensor([[4.1898, 1.2344, 2.7960, 6.1386, 3.3122, 4.3933, 5.6221, 1.0233, 1.6506,\n",
      "         2.8343]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.644037008285522\n",
      "Epoch: 1 \tStep: 96 \tTime Elapse: 1205.317842721939 \tLoss: 2.037 \tMean Loss: 2.251 \tMean Acc: 0.167\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9454452991485596\n",
      "Parameter containing:\n",
      "tensor([[4.1858, 1.2287, 2.7862, 6.1418, 3.3080, 4.3862, 5.6277, 1.0210, 1.6506,\n",
      "         2.8335]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.654704332351685\n",
      "Epoch: 1 \tStep: 97 \tTime Elapse: 1217.934165239334 \tLoss: 2.353 \tMean Loss: 2.252 \tMean Acc: 0.165\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.80069899559021\n",
      "Parameter containing:\n",
      "tensor([[4.1839, 1.2253, 2.7803, 6.1435, 3.3056, 4.3809, 5.6321, 1.0194, 1.6506,\n",
      "         2.8341]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62013864517212\n",
      "Epoch: 1 \tStep: 98 \tTime Elapse: 1230.3714888095856 \tLoss: 2.284 \tMean Loss: 2.256 \tMean Acc: 0.163\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9825024604797363\n",
      "Parameter containing:\n",
      "tensor([[4.1813, 1.2213, 2.7744, 6.1456, 3.3027, 4.3762, 5.6359, 1.0182, 1.6506,\n",
      "         2.8355]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.612507581710815\n",
      "Epoch: 1 \tStep: 99 \tTime Elapse: 1242.9822058677673 \tLoss: 2.3 \tMean Loss: 2.257 \tMean Acc: 0.164\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9733467102050781\n",
      "Parameter containing:\n",
      "tensor([[4.1776, 1.2162, 2.7680, 6.1485, 3.2990, 4.3716, 5.6401, 1.0169, 1.6506,\n",
      "         2.8370]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.987323760986328\n",
      "Epoch: 1 \tStep: 100 \tTime Elapse: 1255.9599573612213 \tLoss: 2.217 \tMean Loss: 2.257 \tMean Acc: 0.168\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7770955562591553\n",
      "Parameter containing:\n",
      "tensor([[4.1735, 1.2106, 2.7599, 6.1517, 3.2950, 4.3664, 5.6445, 1.0154, 1.6506,\n",
      "         2.8386]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.80892825126648\n",
      "Epoch: 1 \tStep: 101 \tTime Elapse: 1268.5619506835938 \tLoss: 2.184 \tMean Loss: 2.253 \tMean Acc: 0.168\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8115928173065186\n",
      "Parameter containing:\n",
      "tensor([[4.1686, 1.2043, 2.7507, 6.1552, 3.2903, 4.3615, 5.6489, 1.0140, 1.6506,\n",
      "         2.8408]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59616732597351\n",
      "Epoch: 1 \tStep: 102 \tTime Elapse: 1280.9864122867584 \tLoss: 2.256 \tMean Loss: 2.249 \tMean Acc: 0.169\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9587922096252441\n",
      "Parameter containing:\n",
      "tensor([[4.1637, 1.1980, 2.7402, 6.1588, 3.2857, 4.3562, 5.6535, 1.0125, 1.6506,\n",
      "         2.8429]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.619199514389038\n",
      "Epoch: 1 \tStep: 103 \tTime Elapse: 1293.5801672935486 \tLoss: 2.156 \tMean Loss: 2.247 \tMean Acc: 0.17\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.0020792484283447\n",
      "Parameter containing:\n",
      "tensor([[4.1580, 1.1908, 2.7286, 6.1629, 3.2802, 4.3506, 5.6577, 1.0110, 1.6506,\n",
      "         2.8447]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.617384910583496\n",
      "Epoch: 1 \tStep: 104 \tTime Elapse: 1306.2168562412262 \tLoss: 2.184 \tMean Loss: 2.244 \tMean Acc: 0.171\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9986305236816406\n",
      "Parameter containing:\n",
      "tensor([[4.1508, 1.1825, 2.7166, 6.1678, 3.2743, 4.3455, 5.6618, 1.0096, 1.6506,\n",
      "         2.8464]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.619872331619263\n",
      "Epoch: 1 \tStep: 105 \tTime Elapse: 1318.8516347408295 \tLoss: 2.256 \tMean Loss: 2.243 \tMean Acc: 0.171\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.795081377029419\n",
      "Parameter containing:\n",
      "tensor([[4.1445, 1.1749, 2.7062, 6.1722, 3.2689, 4.3418, 5.6648, 1.0087, 1.6506,\n",
      "         2.8489]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.608770370483398\n",
      "Epoch: 1 \tStep: 106 \tTime Elapse: 1331.2718651294708 \tLoss: 2.385 \tMean Loss: 2.243 \tMean Acc: 0.17\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9867541790008545\n",
      "Parameter containing:\n",
      "tensor([[4.1392, 1.1684, 2.6971, 6.1759, 3.2643, 4.3396, 5.6667, 1.0084, 1.6506,\n",
      "         2.8528]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.586281061172485\n",
      "Epoch: 1 \tStep: 107 \tTime Elapse: 1343.8607158660889 \tLoss: 2.367 \tMean Loss: 2.242 \tMean Acc: 0.168\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.005295753479004\n",
      "Parameter containing:\n",
      "tensor([[4.1343, 1.1623, 2.6888, 6.1793, 3.2601, 4.3386, 5.6677, 1.0085, 1.6506,\n",
      "         2.8573]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.647998571395874\n",
      "Epoch: 1 \tStep: 108 \tTime Elapse: 1356.5305688381195 \tLoss: 2.379 \tMean Loss: 2.25 \tMean Acc: 0.167\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9660508632659912\n",
      "Parameter containing:\n",
      "tensor([[4.1312, 1.1576, 2.6828, 6.1817, 3.2569, 4.3390, 5.6682, 1.0093, 1.6506,\n",
      "         2.8633]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.619093418121338\n",
      "Epoch: 1 \tStep: 109 \tTime Elapse: 1369.1313619613647 \tLoss: 2.294 \tMean Loss: 2.254 \tMean Acc: 0.165\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.783315658569336\n",
      "Parameter containing:\n",
      "tensor([[4.1280, 1.1529, 2.6769, 6.1841, 3.2537, 4.3389, 5.6685, 1.0099, 1.6506,\n",
      "         2.8687]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.644126892089844\n",
      "Epoch: 1 \tStep: 110 \tTime Elapse: 1381.5751328468323 \tLoss: 2.321 \tMean Loss: 2.255 \tMean Acc: 0.166\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9907402992248535\n",
      "Parameter containing:\n",
      "tensor([[4.1241, 1.1471, 2.6683, 6.1867, 3.2498, 4.3382, 5.6694, 1.0104, 1.6506,\n",
      "         2.8731]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.647535800933838\n",
      "Epoch: 1 \tStep: 111 \tTime Elapse: 1394.2297315597534 \tLoss: 2.149 \tMean Loss: 2.248 \tMean Acc: 0.169\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9838721752166748\n",
      "Parameter containing:\n",
      "tensor([[4.1208, 1.1420, 2.6616, 6.1890, 3.2463, 4.3368, 5.6710, 1.0103, 1.6506,\n",
      "         2.8762]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64022946357727\n",
      "Epoch: 1 \tStep: 112 \tTime Elapse: 1406.8705732822418 \tLoss: 2.243 \tMean Loss: 2.245 \tMean Acc: 0.17\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7614405155181885\n",
      "Parameter containing:\n",
      "tensor([[4.1182, 1.1376, 2.6535, 6.1909, 3.2431, 4.3337, 5.6738, 1.0098, 1.6506,\n",
      "         2.8786]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.8081533908844\n",
      "Epoch: 1 \tStep: 113 \tTime Elapse: 1419.4578256607056 \tLoss: 2.15 \tMean Loss: 2.241 \tMean Acc: 0.173\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7465369701385498\n",
      "Parameter containing:\n",
      "tensor([[4.1143, 1.1316, 2.6431, 6.1933, 3.2394, 4.3292, 5.6784, 1.0085, 1.6506,\n",
      "         2.8792]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.611458778381348\n",
      "Epoch: 1 \tStep: 114 \tTime Elapse: 1431.8328759670258 \tLoss: 2.098 \tMean Loss: 2.232 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9213922023773193\n",
      "Parameter containing:\n",
      "tensor([[4.1128, 1.1280, 2.6348, 6.1946, 3.2371, 4.3259, 5.6823, 1.0076, 1.6506,\n",
      "         2.8810]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.629359483718872\n",
      "Epoch: 1 \tStep: 115 \tTime Elapse: 1444.3996472358704 \tLoss: 2.343 \tMean Loss: 2.238 \tMean Acc: 0.174\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9352717399597168\n",
      "Parameter containing:\n",
      "tensor([[4.1111, 1.1242, 2.6274, 6.1959, 3.2349, 4.3234, 5.6855, 1.0071, 1.6506,\n",
      "         2.8841]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.839346408843994\n",
      "Epoch: 1 \tStep: 116 \tTime Elapse: 1457.1909799575806 \tLoss: 2.271 \tMean Loss: 2.238 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9510080814361572\n",
      "Parameter containing:\n",
      "tensor([[4.1087, 1.1196, 2.6191, 6.1975, 3.2324, 4.3201, 5.6895, 1.0062, 1.6506,\n",
      "         2.8857]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.836936473846436\n",
      "Epoch: 1 \tStep: 117 \tTime Elapse: 1469.9946658611298 \tLoss: 2.246 \tMean Loss: 2.239 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.760122299194336\n",
      "Parameter containing:\n",
      "tensor([[4.1062, 1.1149, 2.6084, 6.1991, 3.2295, 4.3163, 5.6928, 1.0052, 1.6506,\n",
      "         2.8870]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.839425802230835\n",
      "Epoch: 1 \tStep: 118 \tTime Elapse: 1482.6110956668854 \tLoss: 2.189 \tMean Loss: 2.235 \tMean Acc: 0.176\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9160161018371582\n",
      "Parameter containing:\n",
      "tensor([[4.1041, 1.1108, 2.5983, 6.2004, 3.2270, 4.3120, 5.6966, 1.0040, 1.6506,\n",
      "         2.8873]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.831379413604736\n",
      "Epoch: 1 \tStep: 119 \tTime Elapse: 1495.374627828598 \tLoss: 2.23 \tMean Loss: 2.237 \tMean Acc: 0.176\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9674358367919922\n",
      "Parameter containing:\n",
      "tensor([[4.1056, 1.1102, 2.5908, 6.2002, 3.2261, 4.3097, 5.6990, 1.0036, 1.6506,\n",
      "         2.8902]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.993815422058105\n",
      "Epoch: 1 \tStep: 120 \tTime Elapse: 1508.3525519371033 \tLoss: 2.32 \tMean Loss: 2.241 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.946242094039917\n",
      "Parameter containing:\n",
      "tensor([[4.1078, 1.1102, 2.5845, 6.1997, 3.2254, 4.3090, 5.7000, 1.0040, 1.6506,\n",
      "         2.8951]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.006171703338623\n",
      "Epoch: 1 \tStep: 121 \tTime Elapse: 1521.3207983970642 \tLoss: 2.312 \tMean Loss: 2.244 \tMean Acc: 0.174\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7384986877441406\n",
      "Parameter containing:\n",
      "tensor([[4.1096, 1.1097, 2.5784, 6.1994, 3.2246, 4.3088, 5.7007, 1.0046, 1.6506,\n",
      "         2.9002]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.022024154663086\n",
      "Epoch: 1 \tStep: 122 \tTime Elapse: 1534.0979409217834 \tLoss: 2.181 \tMean Loss: 2.244 \tMean Acc: 0.174\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9867470264434814\n",
      "Parameter containing:\n",
      "tensor([[4.1102, 1.1081, 2.5709, 6.1994, 3.2233, 4.3077, 5.7019, 1.0046, 1.6506,\n",
      "         2.9038]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.007322072982788\n",
      "Epoch: 1 \tStep: 123 \tTime Elapse: 1547.1084697246552 \tLoss: 2.245 \tMean Loss: 2.243 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9540364742279053\n",
      "Parameter containing:\n",
      "tensor([[4.1120, 1.1076, 2.5636, 6.1990, 3.2225, 4.3065, 5.7032, 1.0048, 1.6506,\n",
      "         2.9080]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.654284000396729\n",
      "Epoch: 1 \tStep: 124 \tTime Elapse: 1559.7352938652039 \tLoss: 2.137 \tMean Loss: 2.244 \tMean Acc: 0.175\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.736328125\n",
      "Parameter containing:\n",
      "tensor([[4.1140, 1.1075, 2.5577, 6.1985, 3.2219, 4.3060, 5.7039, 1.0052, 1.6506,\n",
      "         2.9126]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.174862623214722\n",
      "Epoch: 1 \tStep: 125 \tTime Elapse: 1572.6645030975342 \tLoss: 2.419 \tMean Loss: 2.25 \tMean Acc: 0.174\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7486121654510498\n",
      "Parameter containing:\n",
      "tensor([[4.1169, 1.1085, 2.5538, 6.1975, 3.2218, 4.3068, 5.7035, 1.0061, 1.6506,\n",
      "         2.9179]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.987396717071533\n",
      "Epoch: 1 \tStep: 126 \tTime Elapse: 1585.4172322750092 \tLoss: 2.403 \tMean Loss: 2.262 \tMean Acc: 0.173\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9243614673614502\n",
      "Parameter containing:\n",
      "tensor([[4.1187, 1.1085, 2.5484, 6.1970, 3.2211, 4.3065, 5.7041, 1.0064, 1.6506,\n",
      "         2.9217]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.012120246887207\n",
      "Epoch: 1 \tStep: 127 \tTime Elapse: 1598.3715538978577 \tLoss: 2.237 \tMean Loss: 2.259 \tMean Acc: 0.173\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.979107141494751\n",
      "Parameter containing:\n",
      "tensor([[4.1189, 1.1067, 2.5405, 6.1971, 3.2196, 4.3041, 5.7062, 1.0060, 1.6506,\n",
      "         2.9232]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.998261213302612\n",
      "Epoch: 1 \tStep: 128 \tTime Elapse: 1611.3658339977264 \tLoss: 2.043 \tMean Loss: 2.251 \tMean Acc: 0.176\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.973534107208252\n",
      "Parameter containing:\n",
      "tensor([[4.1198, 1.1060, 2.5363, 6.1969, 3.2187, 4.3017, 5.7080, 1.0058, 1.6506,\n",
      "         2.9253]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00413727760315\n",
      "Epoch: 1 \tStep: 129 \tTime Elapse: 1624.3597033023834 \tLoss: 2.323 \tMean Loss: 2.251 \tMean Acc: 0.174\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7695918083190918\n",
      "Parameter containing:\n",
      "tensor([[4.1211, 1.1057, 2.5330, 6.1965, 3.2180, 4.3000, 5.7093, 1.0058, 1.6506,\n",
      "         2.9279]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.975283145904541\n",
      "Epoch: 1 \tStep: 130 \tTime Elapse: 1637.121416568756 \tLoss: 2.411 \tMean Loss: 2.258 \tMean Acc: 0.173\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.957263708114624\n",
      "Parameter containing:\n",
      "tensor([[4.1231, 1.1060, 2.5310, 6.1959, 3.2176, 4.2993, 5.7098, 1.0062, 1.6506,\n",
      "         2.9317]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.982594728469849\n",
      "Epoch: 1 \tStep: 131 \tTime Elapse: 1650.077971458435 \tLoss: 2.362 \tMean Loss: 2.264 \tMean Acc: 0.172\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9803028106689453\n",
      "Parameter containing:\n",
      "tensor([[4.1251, 1.1065, 2.5296, 6.1952, 3.2173, 4.2999, 5.7087, 1.0072, 1.6506,\n",
      "         2.9368]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.6578688621521\n",
      "Epoch: 1 \tStep: 132 \tTime Elapse: 1662.733883857727 \tLoss: 2.364 \tMean Loss: 2.267 \tMean Acc: 0.17\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9335014820098877\n",
      "Parameter containing:\n",
      "tensor([[4.1287, 1.1081, 2.5289, 6.1939, 3.2177, 4.3016, 5.7067, 1.0086, 1.6506,\n",
      "         2.9433]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59764838218689\n",
      "Epoch: 1 \tStep: 133 \tTime Elapse: 1675.2825055122375 \tLoss: 2.277 \tMean Loss: 2.271 \tMean Acc: 0.169\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7604119777679443\n",
      "Parameter containing:\n",
      "tensor([[4.1284, 1.1060, 2.5235, 6.1941, 3.2163, 4.3010, 5.7065, 1.0089, 1.6506,\n",
      "         2.9463]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.640263557434082\n",
      "Epoch: 1 \tStep: 134 \tTime Elapse: 1687.6998007297516 \tLoss: 2.122 \tMean Loss: 2.269 \tMean Acc: 0.172\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9807496070861816\n",
      "Parameter containing:\n",
      "tensor([[4.1273, 1.1032, 2.5175, 6.1946, 3.2145, 4.2995, 5.7072, 1.0090, 1.6506,\n",
      "         2.9481]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.63968801498413\n",
      "Epoch: 1 \tStep: 135 \tTime Elapse: 1700.336810350418 \tLoss: 2.225 \tMean Loss: 2.268 \tMean Acc: 0.172\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9858131408691406\n",
      "Parameter containing:\n",
      "tensor([[4.1264, 1.1008, 2.5126, 6.1950, 3.2128, 4.2990, 5.7069, 1.0093, 1.6506,\n",
      "         2.9510]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.995768070220947\n",
      "Epoch: 1 \tStep: 136 \tTime Elapse: 1713.3349606990814 \tLoss: 2.358 \tMean Loss: 2.267 \tMean Acc: 0.171\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7930114269256592\n",
      "Parameter containing:\n",
      "tensor([[4.1261, 1.0990, 2.5086, 6.1952, 3.2116, 4.2992, 5.7061, 1.0099, 1.6506,\n",
      "         2.9543]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.166963815689087\n",
      "Epoch: 1 \tStep: 137 \tTime Elapse: 1726.3109982013702 \tLoss: 2.412 \tMean Loss: 2.269 \tMean Acc: 0.17\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.750809907913208\n",
      "Parameter containing:\n",
      "tensor([[4.1294, 1.1006, 2.5063, 6.1940, 3.2120, 4.2998, 5.7059, 1.0106, 1.6506,\n",
      "         2.9592]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.9942045211792\n",
      "Epoch: 1 \tStep: 138 \tTime Elapse: 1739.0727107524872 \tLoss: 2.166 \tMean Loss: 2.262 \tMean Acc: 0.172\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.955261468887329\n",
      "Parameter containing:\n",
      "tensor([[4.1307, 1.0998, 2.5015, 6.1936, 3.2113, 4.2981, 5.7079, 1.0106, 1.6506,\n",
      "         2.9619]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.66191053390503\n",
      "Epoch: 1 \tStep: 139 \tTime Elapse: 1751.7057602405548 \tLoss: 1.965 \tMean Loss: 2.251 \tMean Acc: 0.176\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9840521812438965\n",
      "Parameter containing:\n",
      "tensor([[4.1314, 1.0986, 2.4970, 6.1934, 3.2104, 4.2962, 5.7099, 1.0106, 1.6506,\n",
      "         2.9645]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.883618593215942\n",
      "Epoch: 1 \tStep: 140 \tTime Elapse: 1764.5916481018066 \tLoss: 2.167 \tMean Loss: 2.246 \tMean Acc: 0.177\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.985685110092163\n",
      "Parameter containing:\n",
      "tensor([[4.1339, 1.0991, 2.4945, 6.1925, 3.2105, 4.2934, 5.7120, 1.0105, 1.6506,\n",
      "         2.9667]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.8677978515625\n",
      "Epoch: 1 \tStep: 141 \tTime Elapse: 1777.4613258838654 \tLoss: 2.284 \tMean Loss: 2.25 \tMean Acc: 0.177\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7794065475463867\n",
      "Parameter containing:\n",
      "tensor([[4.1357, 1.0990, 2.4904, 6.1918, 3.2101, 4.2917, 5.7128, 1.0107, 1.6506,\n",
      "         2.9701]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.889577388763428\n",
      "Epoch: 1 \tStep: 142 \tTime Elapse: 1790.1470575332642 \tLoss: 2.291 \tMean Loss: 2.252 \tMean Acc: 0.178\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9470124244689941\n",
      "Parameter containing:\n",
      "tensor([[4.1386, 1.1001, 2.4864, 6.1907, 3.2105, 4.2883, 5.7148, 1.0105, 1.6506,\n",
      "         2.9722]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.900034666061401\n",
      "Epoch: 1 \tStep: 143 \tTime Elapse: 1803.0104806423187 \tLoss: 2.103 \tMean Loss: 2.25 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9747576713562012\n",
      "Parameter containing:\n",
      "tensor([[4.1368, 1.0968, 2.4780, 6.1915, 3.2086, 4.2846, 5.7174, 1.0101, 1.6506,\n",
      "         2.9737]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.867056846618652\n",
      "Epoch: 1 \tStep: 144 \tTime Elapse: 1815.8689727783203 \tLoss: 2.122 \tMean Loss: 2.251 \tMean Acc: 0.182\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9977953433990479\n",
      "Parameter containing:\n",
      "tensor([[4.1351, 1.0937, 2.4692, 6.1922, 3.2066, 4.2820, 5.7190, 1.0100, 1.6506,\n",
      "         2.9758]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.856772184371948\n",
      "Epoch: 1 \tStep: 145 \tTime Elapse: 1828.7398772239685 \tLoss: 2.369 \tMean Loss: 2.252 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7520842552185059\n",
      "Parameter containing:\n",
      "tensor([[4.1340, 1.0913, 2.4623, 6.1927, 3.2050, 4.2811, 5.7194, 1.0104, 1.6506,\n",
      "         2.9793]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.61899209022522\n",
      "Epoch: 1 \tStep: 146 \tTime Elapse: 1841.1274616718292 \tLoss: 2.357 \tMean Loss: 2.255 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.94730806350708\n",
      "Parameter containing:\n",
      "tensor([[4.1313, 1.0872, 2.4533, 6.1938, 3.2024, 4.2789, 5.7204, 1.0104, 1.6506,\n",
      "         2.9819]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.840998411178589\n",
      "Epoch: 1 \tStep: 147 \tTime Elapse: 1853.9321377277374 \tLoss: 2.075 \tMean Loss: 2.249 \tMean Acc: 0.182\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9706358909606934\n",
      "Parameter containing:\n",
      "tensor([[4.1317, 1.0862, 2.4494, 6.1938, 3.2014, 4.2750, 5.7222, 1.0101, 1.6506,\n",
      "         2.9830]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.865366220474243\n",
      "Epoch: 1 \tStep: 148 \tTime Elapse: 1866.7848012447357 \tLoss: 2.075 \tMean Loss: 2.245 \tMean Acc: 0.182\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7714595794677734\n",
      "Parameter containing:\n",
      "tensor([[4.1302, 1.0835, 2.4435, 6.1944, 3.1994, 4.2724, 5.7233, 1.0100, 1.6506,\n",
      "         2.9849]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.77112078666687\n",
      "Epoch: 1 \tStep: 149 \tTime Elapse: 1879.3436620235443 \tLoss: 2.292 \tMean Loss: 2.247 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7930598258972168\n",
      "Parameter containing:\n",
      "tensor([[4.1287, 1.0810, 2.4380, 6.1950, 3.1975, 4.2706, 5.7239, 1.0100, 1.6506,\n",
      "         2.9870]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.620636224746704\n",
      "Epoch: 1 \tStep: 150 \tTime Elapse: 1891.7745578289032 \tLoss: 2.419 \tMean Loss: 2.251 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9708900451660156\n",
      "Parameter containing:\n",
      "tensor([[4.1278, 1.0792, 2.4337, 6.1954, 3.1960, 4.2698, 5.7237, 1.0104, 1.6506,\n",
      "         2.9900]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.65570068359375\n",
      "Epoch: 1 \tStep: 151 \tTime Elapse: 1904.4176936149597 \tLoss: 2.383 \tMean Loss: 2.253 \tMean Acc: 0.179\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.0113275051116943\n",
      "Parameter containing:\n",
      "tensor([[4.1231, 1.0734, 2.4253, 6.1972, 3.1924, 4.2700, 5.7227, 1.0110, 1.6506,\n",
      "         2.9940]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.56701135635376\n",
      "Epoch: 1 \tStep: 152 \tTime Elapse: 1917.0128283500671 \tLoss: 2.108 \tMean Loss: 2.25 \tMean Acc: 0.179\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.983625888824463\n",
      "Parameter containing:\n",
      "tensor([[4.1167, 1.0662, 2.4146, 6.1996, 3.1878, 4.2704, 5.7216, 1.0117, 1.6506,\n",
      "         2.9982]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.641472578048706\n",
      "Epoch: 1 \tStep: 153 \tTime Elapse: 1929.6540298461914 \tLoss: 2.278 \tMean Loss: 2.252 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8051104545593262\n",
      "Parameter containing:\n",
      "tensor([[4.1112, 1.0598, 2.4051, 6.2016, 3.1839, 4.2712, 5.7202, 1.0125, 1.6506,\n",
      "         3.0025]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.623650312423706\n",
      "Epoch: 1 \tStep: 154 \tTime Elapse: 1942.0998129844666 \tLoss: 2.403 \tMean Loss: 2.26 \tMean Acc: 0.179\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9649996757507324\n",
      "Parameter containing:\n",
      "tensor([[4.1057, 1.0531, 2.3938, 6.2037, 3.1796, 4.2693, 5.7205, 1.0128, 1.6506,\n",
      "         3.0053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.656709432601929\n",
      "Epoch: 1 \tStep: 155 \tTime Elapse: 1954.737816810608 \tLoss: 1.907 \tMean Loss: 2.243 \tMean Acc: 0.182\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.0071215629577637\n",
      "Parameter containing:\n",
      "tensor([[4.1010, 1.0471, 2.3837, 6.2054, 3.1759, 4.2686, 5.7202, 1.0132, 1.6506,\n",
      "         3.0088]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.86324405670166\n",
      "Epoch: 1 \tStep: 156 \tTime Elapse: 1967.625411748886 \tLoss: 2.392 \tMean Loss: 2.243 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9308173656463623\n",
      "Parameter containing:\n",
      "tensor([[4.0968, 1.0420, 2.3746, 6.2070, 3.1726, 4.2689, 5.7191, 1.0139, 1.6506,\n",
      "         3.0133]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.629927158355713\n",
      "Epoch: 1 \tStep: 157 \tTime Elapse: 1980.2019510269165 \tLoss: 2.385 \tMean Loss: 2.248 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7676918506622314\n",
      "Parameter containing:\n",
      "tensor([[4.0934, 1.0377, 2.3666, 6.2083, 3.1697, 4.2703, 5.7172, 1.0149, 1.6506,\n",
      "         3.0186]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.602333307266235\n",
      "Epoch: 1 \tStep: 158 \tTime Elapse: 1992.588497877121 \tLoss: 2.394 \tMean Loss: 2.26 \tMean Acc: 0.179\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9507992267608643\n",
      "Parameter containing:\n",
      "tensor([[4.0904, 1.0339, 2.3594, 6.2095, 3.1672, 4.2720, 5.7153, 1.0158, 1.6506,\n",
      "         3.0238]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.613512754440308\n",
      "Epoch: 1 \tStep: 159 \tTime Elapse: 2005.1689112186432 \tLoss: 2.413 \tMean Loss: 2.263 \tMean Acc: 0.178\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.967226266860962\n",
      "Parameter containing:\n",
      "tensor([[4.0874, 1.0302, 2.3520, 6.2106, 3.1647, 4.2710, 5.7157, 1.0161, 1.6506,\n",
      "         3.0260]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.875687599182129\n",
      "Epoch: 1 \tStep: 160 \tTime Elapse: 2018.0287737846375 \tLoss: 2.046 \tMean Loss: 2.25 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.75935959815979\n",
      "Parameter containing:\n",
      "tensor([[4.0871, 1.0288, 2.3460, 6.2113, 3.1633, 4.2709, 5.7154, 1.0166, 1.6506,\n",
      "         3.0297]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.013345718383789\n",
      "Epoch: 1 \tStep: 161 \tTime Elapse: 2030.8175854682922 \tLoss: 2.296 \tMean Loss: 2.248 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7541792392730713\n",
      "Parameter containing:\n",
      "tensor([[4.0869, 1.0275, 2.3394, 6.2118, 3.1622, 4.2714, 5.7138, 1.0173, 1.6506,\n",
      "         3.0344]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.852605104446411\n",
      "Epoch: 1 \tStep: 162 \tTime Elapse: 2043.4422118663788 \tLoss: 2.302 \tMean Loss: 2.246 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.934166669845581\n",
      "Parameter containing:\n",
      "tensor([[4.0870, 1.0265, 2.3335, 6.2123, 3.1611, 4.2712, 5.7129, 1.0178, 1.6506,\n",
      "         3.0380]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.631980180740356\n",
      "Epoch: 1 \tStep: 163 \tTime Elapse: 2056.0249524116516 \tLoss: 2.199 \tMean Loss: 2.244 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.950237512588501\n",
      "Parameter containing:\n",
      "tensor([[4.0868, 1.0252, 2.3278, 6.2128, 3.1601, 4.2706, 5.7116, 1.0184, 1.6506,\n",
      "         3.0418]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.653748750686646\n",
      "Epoch: 1 \tStep: 164 \tTime Elapse: 2068.645835876465 \tLoss: 2.297 \tMean Loss: 2.249 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9641425609588623\n",
      "Parameter containing:\n",
      "tensor([[4.0879, 1.0249, 2.3237, 6.2130, 3.1596, 4.2708, 5.7100, 1.0190, 1.6506,\n",
      "         3.0463]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.982313632965088\n",
      "Epoch: 1 \tStep: 165 \tTime Elapse: 2081.608740091324 \tLoss: 2.336 \tMean Loss: 2.253 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7432596683502197\n",
      "Parameter containing:\n",
      "tensor([[4.0878, 1.0235, 2.3187, 6.2134, 3.1586, 4.2712, 5.7081, 1.0197, 1.6506,\n",
      "         3.0510]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.997454166412354\n",
      "Epoch: 1 \tStep: 166 \tTime Elapse: 2094.3663132190704 \tLoss: 2.199 \tMean Loss: 2.248 \tMean Acc: 0.181\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9283671379089355\n",
      "Parameter containing:\n",
      "tensor([[4.0877, 1.0223, 2.3143, 6.2137, 3.1578, 4.2722, 5.7062, 1.0204, 1.6506,\n",
      "         3.0558]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.663331747055054\n",
      "Epoch: 1 \tStep: 167 \tTime Elapse: 2106.974331855774 \tLoss: 2.38 \tMean Loss: 2.247 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9661259651184082\n",
      "Parameter containing:\n",
      "tensor([[4.0872, 1.0207, 2.3095, 6.2141, 3.1570, 4.2720, 5.7053, 1.0209, 1.6506,\n",
      "         3.0592]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.637707710266113\n",
      "Epoch: 1 \tStep: 168 \tTime Elapse: 2119.5951175689697 \tLoss: 2.247 \tMean Loss: 2.249 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.934502124786377\n",
      "Parameter containing:\n",
      "tensor([[4.0887, 1.0207, 2.3071, 6.2142, 3.1569, 4.2717, 5.7047, 1.0214, 1.6506,\n",
      "         3.0627]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.616822719573975\n",
      "Epoch: 1 \tStep: 169 \tTime Elapse: 2132.1631832122803 \tLoss: 2.282 \tMean Loss: 2.26 \tMean Acc: 0.18\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7414653301239014\n",
      "Parameter containing:\n",
      "tensor([[4.0884, 1.0187, 2.3023, 6.2144, 3.1562, 4.2683, 5.7066, 1.0214, 1.6506,\n",
      "         3.0631]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.60184121131897\n",
      "Epoch: 1 \tStep: 170 \tTime Elapse: 2144.5237634181976 \tLoss: 1.889 \tMean Loss: 2.251 \tMean Acc: 0.184\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9454059600830078\n",
      "Parameter containing:\n",
      "tensor([[4.0893, 1.0170, 2.2968, 6.2146, 3.1559, 4.2634, 5.7093, 1.0212, 1.6506,\n",
      "         3.0620]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.6161949634552\n",
      "Epoch: 1 \tStep: 171 \tTime Elapse: 2157.101926088333 \tLoss: 2.103 \tMean Loss: 2.245 \tMean Acc: 0.186\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9365670680999756\n",
      "Parameter containing:\n",
      "tensor([[4.0919, 1.0168, 2.2931, 6.2145, 3.1562, 4.2588, 5.7120, 1.0211, 1.6506,\n",
      "         3.0619]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.622286796569824\n",
      "Epoch: 1 \tStep: 172 \tTime Elapse: 2169.677761554718 \tLoss: 2.262 \tMean Loss: 2.244 \tMean Acc: 0.186\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.768040418624878\n",
      "Parameter containing:\n",
      "tensor([[4.0949, 1.0170, 2.2903, 6.2144, 3.1568, 4.2532, 5.7156, 1.0207, 1.6506,\n",
      "         3.0605]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.759047031402588\n",
      "Epoch: 1 \tStep: 173 \tTime Elapse: 2182.2220063209534 \tLoss: 2.23 \tMean Loss: 2.248 \tMean Acc: 0.186\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.79681396484375\n",
      "Parameter containing:\n",
      "tensor([[4.0993, 1.0182, 2.2884, 6.2140, 3.1579, 4.2467, 5.7194, 1.0204, 1.6506,\n",
      "         3.0587]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.648118257522583\n",
      "Epoch: 1 \tStep: 174 \tTime Elapse: 2194.6836018562317 \tLoss: 2.105 \tMean Loss: 2.247 \tMean Acc: 0.188\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9793412685394287\n",
      "Parameter containing:\n",
      "tensor([[4.1035, 1.0191, 2.2853, 6.2137, 3.1589, 4.2385, 5.7245, 1.0197, 1.6506,\n",
      "         3.0556]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628264904022217\n",
      "Epoch: 1 \tStep: 175 \tTime Elapse: 2207.3081839084625 \tLoss: 1.969 \tMean Loss: 2.234 \tMean Acc: 0.191\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.004305124282837\n",
      "Parameter containing:\n",
      "tensor([[4.1072, 1.0195, 2.2810, 6.2135, 3.1596, 4.2306, 5.7295, 1.0190, 1.6506,\n",
      "         3.0523]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59933590888977\n",
      "Epoch: 1 \tStep: 176 \tTime Elapse: 2219.9287497997284 \tLoss: 2.261 \tMean Loss: 2.231 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9933207035064697\n",
      "Parameter containing:\n",
      "tensor([[4.1105, 1.0196, 2.2758, 6.2132, 3.1602, 4.2235, 5.7334, 1.0186, 1.6506,\n",
      "         3.0502]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.616227865219116\n",
      "Epoch: 1 \tStep: 177 \tTime Elapse: 2232.554711818695 \tLoss: 2.218 \tMean Loss: 2.236 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8130409717559814\n",
      "Parameter containing:\n",
      "tensor([[4.1109, 1.0170, 2.2675, 6.2134, 3.1596, 4.2163, 5.7374, 1.0182, 1.6506,\n",
      "         3.0485]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64313268661499\n",
      "Epoch: 1 \tStep: 178 \tTime Elapse: 2245.0275468826294 \tLoss: 2.104 \tMean Loss: 2.237 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9835114479064941\n",
      "Parameter containing:\n",
      "tensor([[4.1135, 1.0165, 2.2610, 6.2132, 3.1599, 4.2085, 5.7418, 1.0176, 1.6506,\n",
      "         3.0465]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.58711838722229\n",
      "Epoch: 1 \tStep: 179 \tTime Elapse: 2257.6146097183228 \tLoss: 2.103 \tMean Loss: 2.23 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9964957237243652\n",
      "Parameter containing:\n",
      "tensor([[4.1156, 1.0150, 2.2530, 6.2130, 3.1598, 4.1995, 5.7468, 1.0169, 1.6506,\n",
      "         3.0437]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.617330551147461\n",
      "Epoch: 1 \tStep: 180 \tTime Elapse: 2270.2451527118683 \tLoss: 1.906 \tMean Loss: 2.213 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.949662208557129\n",
      "Parameter containing:\n",
      "tensor([[4.1177, 1.0138, 2.2458, 6.2129, 3.1599, 4.1915, 5.7511, 1.0163, 1.6506,\n",
      "         3.0413]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.611865758895874\n",
      "Epoch: 1 \tStep: 181 \tTime Elapse: 2282.8231048583984 \tLoss: 2.418 \tMean Loss: 2.214 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.804105281829834\n",
      "Parameter containing:\n",
      "tensor([[4.1199, 1.0131, 2.2400, 6.2127, 3.1601, 4.1848, 5.7548, 1.0158, 1.6506,\n",
      "         3.0397]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.609666585922241\n",
      "Epoch: 1 \tStep: 182 \tTime Elapse: 2295.2534120082855 \tLoss: 2.408 \tMean Loss: 2.224 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.008963108062744\n",
      "Parameter containing:\n",
      "tensor([[4.1213, 1.0115, 2.2332, 6.2127, 3.1599, 4.1785, 5.7581, 1.0154, 1.6506,\n",
      "         3.0384]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.625558614730835\n",
      "Epoch: 1 \tStep: 183 \tTime Elapse: 2307.9043493270874 \tLoss: 2.214 \tMean Loss: 2.222 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9841017723083496\n",
      "Parameter containing:\n",
      "tensor([[4.1231, 1.0106, 2.2272, 6.2125, 3.1600, 4.1721, 5.7617, 1.0149, 1.6506,\n",
      "         3.0368]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.620941162109375\n",
      "Epoch: 1 \tStep: 184 \tTime Elapse: 2320.527408838272 \tLoss: 2.251 \tMean Loss: 2.217 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8115084171295166\n",
      "Parameter containing:\n",
      "tensor([[4.1235, 1.0084, 2.2197, 6.2125, 3.1595, 4.1668, 5.7648, 1.0147, 1.6506,\n",
      "         3.0364]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.763152599334717\n",
      "Epoch: 1 \tStep: 185 \tTime Elapse: 2333.118205308914 \tLoss: 2.27 \tMean Loss: 2.229 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7733633518218994\n",
      "Parameter containing:\n",
      "tensor([[4.1235, 1.0057, 2.2117, 6.2126, 3.1589, 4.1622, 5.7675, 1.0145, 1.6506,\n",
      "         3.0367]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.6490638256073\n",
      "Epoch: 1 \tStep: 186 \tTime Elapse: 2345.5575721263885 \tLoss: 2.232 \tMean Loss: 2.224 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9680657386779785\n",
      "Parameter containing:\n",
      "tensor([[4.1233, 1.0029, 2.2036, 6.2127, 3.1581, 4.1585, 5.7696, 1.0145, 1.6506,\n",
      "         3.0374]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650671482086182\n",
      "Epoch: 1 \tStep: 187 \tTime Elapse: 2358.1927421092987 \tLoss: 2.242 \tMean Loss: 2.219 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9778850078582764\n",
      "Parameter containing:\n",
      "tensor([[4.1218, 0.9992, 2.1949, 6.2130, 3.1569, 4.1545, 5.7717, 1.0144, 1.6506,\n",
      "         3.0381]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.634995222091675\n",
      "Epoch: 1 \tStep: 188 \tTime Elapse: 2370.8224363327026 \tLoss: 2.254 \tMean Loss: 2.215 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.031390428543091\n",
      "Parameter containing:\n",
      "tensor([[4.1207, 0.9960, 2.1870, 6.2132, 3.1559, 4.1510, 5.7735, 1.0144, 1.6506,\n",
      "         3.0389]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.84757947921753\n",
      "Epoch: 1 \tStep: 189 \tTime Elapse: 2383.7193746566772 \tLoss: 2.253 \tMean Loss: 2.209 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.79107666015625\n",
      "Parameter containing:\n",
      "tensor([[4.1199, 0.9932, 2.1803, 6.2134, 3.1550, 4.1479, 5.7751, 1.0144, 1.6506,\n",
      "         3.0399]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.627087593078613\n",
      "Epoch: 1 \tStep: 190 \tTime Elapse: 2396.154884815216 \tLoss: 2.416 \tMean Loss: 2.222 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9543039798736572\n",
      "Parameter containing:\n",
      "tensor([[4.1201, 0.9916, 2.1753, 6.2134, 3.1546, 4.1459, 5.7761, 1.0146, 1.6506,\n",
      "         3.0416]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.612207889556885\n",
      "Epoch: 1 \tStep: 191 \tTime Elapse: 2408.7376761436462 \tLoss: 2.408 \tMean Loss: 2.225 \tMean Acc: 0.195\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.002371311187744\n",
      "Parameter containing:\n",
      "tensor([[4.1184, 0.9884, 2.1685, 6.2137, 3.1535, 4.1445, 5.7766, 1.0149, 1.6506,\n",
      "         3.0442]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.895747184753418\n",
      "Epoch: 1 \tStep: 192 \tTime Elapse: 2421.65252161026 \tLoss: 2.24 \tMean Loss: 2.223 \tMean Acc: 0.195\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9246690273284912\n",
      "Parameter containing:\n",
      "tensor([[4.1171, 0.9856, 2.1627, 6.2138, 3.1526, 4.1434, 5.7768, 1.0153, 1.6506,\n",
      "         3.0467]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85766339302063\n",
      "Epoch: 1 \tStep: 193 \tTime Elapse: 2434.4514095783234 \tLoss: 2.423 \tMean Loss: 2.231 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8105452060699463\n",
      "Parameter containing:\n",
      "tensor([[4.1184, 0.9849, 2.1592, 6.2138, 3.1527, 4.1431, 5.7767, 1.0158, 1.6506,\n",
      "         3.0503]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.805004835128784\n",
      "Epoch: 1 \tStep: 194 \tTime Elapse: 2447.083530664444 \tLoss: 2.297 \tMean Loss: 2.231 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9930815696716309\n",
      "Parameter containing:\n",
      "tensor([[4.1180, 0.9828, 2.1541, 6.2139, 3.1522, 4.1427, 5.7765, 1.0163, 1.6506,\n",
      "         3.0537]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.846338987350464\n",
      "Epoch: 1 \tStep: 195 \tTime Elapse: 2459.9396498203278 \tLoss: 2.264 \tMean Loss: 2.228 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.986725091934204\n",
      "Parameter containing:\n",
      "tensor([[4.1155, 0.9788, 2.1458, 6.2142, 3.1507, 4.1422, 5.7765, 1.0168, 1.6506,\n",
      "         3.0574]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.860982894897461\n",
      "Epoch: 1 \tStep: 196 \tTime Elapse: 2472.8093490600586 \tLoss: 2.047 \tMean Loss: 2.223 \tMean Acc: 0.195\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8010883331298828\n",
      "Parameter containing:\n",
      "tensor([[4.1133, 0.9753, 2.1385, 6.2144, 3.1495, 4.1419, 5.7764, 1.0173, 1.6506,\n",
      "         3.0610]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.027557849884033\n",
      "Epoch: 1 \tStep: 197 \tTime Elapse: 2485.6544346809387 \tLoss: 2.416 \tMean Loss: 2.224 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7934730052947998\n",
      "Parameter containing:\n",
      "tensor([[4.1119, 0.9727, 2.1329, 6.2146, 3.1486, 4.1421, 5.7759, 1.0179, 1.6506,\n",
      "         3.0648]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.609434843063354\n",
      "Epoch: 1 \tStep: 198 \tTime Elapse: 2498.0741431713104 \tLoss: 2.406 \tMean Loss: 2.23 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9623692035675049\n",
      "Parameter containing:\n",
      "tensor([[4.1115, 0.9709, 2.1287, 6.2147, 3.1482, 4.1430, 5.7749, 1.0185, 1.6506,\n",
      "         3.0694]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.981953382492065\n",
      "Epoch: 1 \tStep: 199 \tTime Elapse: 2511.036484003067 \tLoss: 2.393 \tMean Loss: 2.233 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.951070785522461\n",
      "Parameter containing:\n",
      "tensor([[4.1104, 0.9686, 2.1241, 6.2149, 3.1474, 4.1432, 5.7738, 1.0191, 1.6506,\n",
      "         3.0737]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.971436738967896\n",
      "Epoch: 1 \tStep: 200 \tTime Elapse: 2523.97545003891 \tLoss: 2.254 \tMean Loss: 2.246 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9454936981201172\n",
      "Parameter containing:\n",
      "tensor([[4.1125, 0.9690, 2.1235, 6.2148, 3.1480, 4.1440, 5.7725, 1.0198, 1.6506,\n",
      "         3.0787]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.99734902381897\n",
      "Epoch: 1 \tStep: 201 \tTime Elapse: 2536.934828519821 \tLoss: 2.351 \tMean Loss: 2.254 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7470674514770508\n",
      "Parameter containing:\n",
      "tensor([[4.1165, 0.9705, 2.1239, 6.2147, 3.1492, 4.1453, 5.7705, 1.0206, 1.6506,\n",
      "         3.0851]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.949563026428223\n",
      "Epoch: 1 \tStep: 202 \tTime Elapse: 2549.648087978363 \tLoss: 2.177 \tMean Loss: 2.251 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.938331127166748\n",
      "Parameter containing:\n",
      "tensor([[4.1202, 0.9719, 2.1240, 6.2146, 3.1504, 4.1468, 5.7683, 1.0214, 1.6506,\n",
      "         3.0914]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.97517991065979\n",
      "Epoch: 1 \tStep: 203 \tTime Elapse: 2562.5777311325073 \tLoss: 2.188 \tMean Loss: 2.25 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9551122188568115\n",
      "Parameter containing:\n",
      "tensor([[4.1272, 0.9763, 2.1276, 6.2142, 3.1530, 4.1475, 5.7663, 1.0222, 1.6506,\n",
      "         3.0986]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.011088609695435\n",
      "Epoch: 1 \tStep: 204 \tTime Elapse: 2575.5605370998383 \tLoss: 2.185 \tMean Loss: 2.252 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9465749263763428\n",
      "Parameter containing:\n",
      "tensor([[4.1337, 0.9804, 2.1311, 6.2138, 3.1554, 4.1483, 5.7643, 1.0230, 1.6506,\n",
      "         3.1053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.980592489242554\n",
      "Epoch: 1 \tStep: 205 \tTime Elapse: 2588.5044162273407 \tLoss: 2.416 \tMean Loss: 2.267 \tMean Acc: 0.191\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7454273700714111\n",
      "Parameter containing:\n",
      "tensor([[4.1382, 0.9830, 2.1324, 6.2136, 3.1571, 4.1488, 5.7622, 1.0236, 1.6506,\n",
      "         3.1114]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.006174087524414\n",
      "Epoch: 1 \tStep: 206 \tTime Elapse: 2601.272768974304 \tLoss: 2.232 \tMean Loss: 2.266 \tMean Acc: 0.192\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9618632793426514\n",
      "Parameter containing:\n",
      "tensor([[4.1425, 0.9853, 2.1332, 6.2134, 3.1585, 4.1504, 5.7592, 1.0244, 1.6506,\n",
      "         3.1185]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.652760028839111\n",
      "Epoch: 1 \tStep: 207 \tTime Elapse: 2613.903783559799 \tLoss: 2.319 \tMean Loss: 2.27 \tMean Acc: 0.191\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9595329761505127\n",
      "Parameter containing:\n",
      "tensor([[4.1459, 0.9867, 2.1335, 6.2133, 3.1597, 4.1520, 5.7573, 1.0250, 1.6506,\n",
      "         3.1248]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.617586851119995\n",
      "Epoch: 1 \tStep: 208 \tTime Elapse: 2626.4974575042725 \tLoss: 2.215 \tMean Loss: 2.273 \tMean Acc: 0.191\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7525842189788818\n",
      "Parameter containing:\n",
      "tensor([[4.1452, 0.9840, 2.1282, 6.2138, 3.1588, 4.1534, 5.7550, 1.0256, 1.6506,\n",
      "         3.1310]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.838040590286255\n",
      "Epoch: 1 \tStep: 209 \tTime Elapse: 2639.1044557094574 \tLoss: 2.022 \tMean Loss: 2.271 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7872579097747803\n",
      "Parameter containing:\n",
      "tensor([[4.1438, 0.9808, 2.1227, 6.2144, 3.1577, 4.1541, 5.7534, 1.0261, 1.6506,\n",
      "         3.1362]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638063669204712\n",
      "Epoch: 1 \tStep: 210 \tTime Elapse: 2651.546614408493 \tLoss: 2.294 \tMean Loss: 2.284 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9417729377746582\n",
      "Parameter containing:\n",
      "tensor([[4.1426, 0.9774, 2.1165, 6.2149, 3.1565, 4.1549, 5.7515, 1.0266, 1.6506,\n",
      "         3.1414]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.647578477859497\n",
      "Epoch: 1 \tStep: 211 \tTime Elapse: 2664.1525070667267 \tLoss: 2.241 \tMean Loss: 2.278 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9650728702545166\n",
      "Parameter containing:\n",
      "tensor([[4.1422, 0.9748, 2.1109, 6.2153, 3.1558, 4.1549, 5.7506, 1.0270, 1.6506,\n",
      "         3.1454]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.630970239639282\n",
      "Epoch: 1 \tStep: 212 \tTime Elapse: 2676.7650809288025 \tLoss: 2.185 \tMean Loss: 2.27 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9720368385314941\n",
      "Parameter containing:\n",
      "tensor([[4.1388, 0.9699, 2.1013, 6.2160, 3.1537, 4.1540, 5.7502, 1.0274, 1.6506,\n",
      "         3.1480]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.861806631088257\n",
      "Epoch: 1 \tStep: 213 \tTime Elapse: 2689.6153128147125 \tLoss: 1.996 \tMean Loss: 2.263 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7603981494903564\n",
      "Parameter containing:\n",
      "tensor([[4.1356, 0.9655, 2.0927, 6.2167, 3.1517, 4.1523, 5.7506, 1.0278, 1.6506,\n",
      "         3.1495]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.843445301055908\n",
      "Epoch: 1 \tStep: 214 \tTime Elapse: 2702.2359323501587 \tLoss: 2.192 \tMean Loss: 2.261 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9272820949554443\n",
      "Parameter containing:\n",
      "tensor([[4.1331, 0.9618, 2.0852, 6.2173, 3.1501, 4.1515, 5.7503, 1.0281, 1.6506,\n",
      "         3.1517]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.845451354980469\n",
      "Epoch: 1 \tStep: 215 \tTime Elapse: 2715.024854183197 \tLoss: 2.396 \tMean Loss: 2.265 \tMean Acc: 0.195\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9498870372772217\n",
      "Parameter containing:\n",
      "tensor([[4.1334, 0.9607, 2.0802, 6.2176, 3.1498, 4.1512, 5.7500, 1.0284, 1.6506,\n",
      "         3.1549]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.037838459014893\n",
      "Epoch: 1 \tStep: 216 \tTime Elapse: 2728.029088497162 \tLoss: 2.277 \tMean Loss: 2.267 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.923583984375\n",
      "Parameter containing:\n",
      "tensor([[4.1343, 0.9604, 2.0763, 6.2178, 3.1498, 4.1524, 5.7485, 1.0286, 1.6506,\n",
      "         3.1594]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.991587162017822\n",
      "Epoch: 1 \tStep: 217 \tTime Elapse: 2740.96102809906 \tLoss: 2.353 \tMean Loss: 2.27 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.75260329246521\n",
      "Parameter containing:\n",
      "tensor([[4.1346, 0.9595, 2.0711, 6.2181, 3.1495, 4.1534, 5.7475, 1.0287, 1.6506,\n",
      "         3.1642]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.983739137649536\n",
      "Epoch: 1 \tStep: 218 \tTime Elapse: 2753.7142119407654 \tLoss: 2.166 \tMean Loss: 2.267 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9706873893737793\n",
      "Parameter containing:\n",
      "tensor([[4.1365, 0.9600, 2.0686, 6.2182, 3.1500, 4.1548, 5.7465, 1.0288, 1.6506,\n",
      "         3.1698]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.009418725967407\n",
      "Epoch: 1 \tStep: 219 \tTime Elapse: 2766.7105944156647 \tLoss: 2.284 \tMean Loss: 2.268 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9630768299102783\n",
      "Parameter containing:\n",
      "tensor([[4.1383, 0.9605, 2.0662, 6.2182, 3.1504, 4.1560, 5.7456, 1.0289, 1.6506,\n",
      "         3.1749]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.000499725341797\n",
      "Epoch: 1 \tStep: 220 \tTime Elapse: 2779.6923854351044 \tLoss: 2.178 \tMean Loss: 2.26 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7664077281951904\n",
      "Parameter containing:\n",
      "tensor([[4.1396, 0.9606, 2.0636, 6.2184, 3.1507, 4.1567, 5.7452, 1.0289, 1.6506,\n",
      "         3.1791]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.124925136566162\n",
      "Epoch: 1 \tStep: 221 \tTime Elapse: 2792.6005969047546 \tLoss: 2.207 \tMean Loss: 2.254 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7636094093322754\n",
      "Parameter containing:\n",
      "tensor([[4.1412, 0.9610, 2.0616, 6.2184, 3.1512, 4.1582, 5.7441, 1.0289, 1.6506,\n",
      "         3.1843]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.988587617874146\n",
      "Epoch: 1 \tStep: 222 \tTime Elapse: 2805.3697652816772 \tLoss: 2.393 \tMean Loss: 2.259 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9466986656188965\n",
      "Parameter containing:\n",
      "tensor([[4.1421, 0.9608, 2.0590, 6.2185, 3.1513, 4.1595, 5.7432, 1.0289, 1.6506,\n",
      "         3.1891]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.99470853805542\n",
      "Epoch: 1 \tStep: 223 \tTime Elapse: 2818.32772397995 \tLoss: 2.238 \tMean Loss: 2.253 \tMean Acc: 0.193\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9552466869354248\n",
      "Parameter containing:\n",
      "tensor([[4.1426, 0.9602, 2.0564, 6.2186, 3.1513, 4.1609, 5.7428, 1.0288, 1.6506,\n",
      "         3.1942]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.03347635269165\n",
      "Epoch: 1 \tStep: 224 \tTime Elapse: 2831.3333933353424 \tLoss: 2.135 \tMean Loss: 2.247 \tMean Acc: 0.194\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9741418361663818\n",
      "Parameter containing:\n",
      "tensor([[4.1415, 0.9578, 2.0519, 6.2189, 3.1504, 4.1610, 5.7431, 1.0287, 1.6506,\n",
      "         3.1978]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64450979232788\n",
      "Epoch: 1 \tStep: 225 \tTime Elapse: 2843.9683969020844 \tLoss: 2.055 \tMean Loss: 2.24 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.812577247619629\n",
      "Parameter containing:\n",
      "tensor([[4.1405, 0.9558, 2.0481, 6.2191, 3.1498, 4.1620, 5.7427, 1.0286, 1.6506,\n",
      "         3.2020]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.629850625991821\n",
      "Epoch: 1 \tStep: 226 \tTime Elapse: 2856.427541732788 \tLoss: 2.405 \tMean Loss: 2.252 \tMean Acc: 0.195\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9625270366668701\n",
      "Parameter containing:\n",
      "tensor([[4.1381, 0.9519, 2.0419, 6.2194, 3.1484, 4.1613, 5.7436, 1.0287, 1.6506,\n",
      "         3.2041]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.630891799926758\n",
      "Epoch: 1 \tStep: 227 \tTime Elapse: 2869.038022518158 \tLoss: 1.977 \tMean Loss: 2.238 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9762241840362549\n",
      "Parameter containing:\n",
      "tensor([[4.1359, 0.9483, 2.0364, 6.2197, 3.1473, 4.1617, 5.7439, 1.0286, 1.6506,\n",
      "         3.2071]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.642249345779419\n",
      "Epoch: 1 \tStep: 228 \tTime Elapse: 2881.675096988678 \tLoss: 2.393 \tMean Loss: 2.237 \tMean Acc: 0.196\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9525084495544434\n",
      "Parameter containing:\n",
      "tensor([[4.1338, 0.9447, 2.0306, 6.2200, 3.1461, 4.1616, 5.7442, 1.0286, 1.6506,\n",
      "         3.2095]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.60697340965271\n",
      "Epoch: 1 \tStep: 229 \tTime Elapse: 2894.2509479522705 \tLoss: 2.203 \tMean Loss: 2.231 \tMean Acc: 0.197\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7834177017211914\n",
      "Parameter containing:\n",
      "tensor([[4.1320, 0.9409, 2.0250, 6.2203, 3.1451, 4.1597, 5.7455, 1.0287, 1.6506,\n",
      "         3.2104]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650390625\n",
      "Epoch: 1 \tStep: 230 \tTime Elapse: 2906.701585292816 \tLoss: 2.053 \tMean Loss: 2.224 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9795937538146973\n",
      "Parameter containing:\n",
      "tensor([[4.1297, 0.9368, 2.0190, 6.2205, 3.1439, 4.1576, 5.7470, 1.0288, 1.6506,\n",
      "         3.2110]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.629726648330688\n",
      "Epoch: 1 \tStep: 231 \tTime Elapse: 2919.3289744853973 \tLoss: 2.201 \tMean Loss: 2.219 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.978440284729004\n",
      "Parameter containing:\n",
      "tensor([[4.1273, 0.9325, 2.0129, 6.2207, 3.1426, 4.1554, 5.7487, 1.0290, 1.6506,\n",
      "         3.2113]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.025827884674072\n",
      "Epoch: 1 \tStep: 232 \tTime Elapse: 2932.351712703705 \tLoss: 2.218 \tMean Loss: 2.221 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7851226329803467\n",
      "Parameter containing:\n",
      "tensor([[4.1269, 0.9302, 2.0090, 6.2209, 3.1422, 4.1532, 5.7513, 1.0291, 1.6506,\n",
      "         3.2110]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.182717084884644\n",
      "Epoch: 1 \tStep: 233 \tTime Elapse: 2945.336104154587 \tLoss: 2.284 \tMean Loss: 2.224 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.773963212966919\n",
      "Parameter containing:\n",
      "tensor([[4.1268, 0.9283, 2.0059, 6.2211, 3.1420, 4.1517, 5.7534, 1.0292, 1.6506,\n",
      "         3.2112]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.991214036941528\n",
      "Epoch: 1 \tStep: 234 \tTime Elapse: 2958.117953300476 \tLoss: 2.417 \tMean Loss: 2.231 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9519388675689697\n",
      "Parameter containing:\n",
      "tensor([[4.1272, 0.9271, 2.0038, 6.2212, 3.1420, 4.1496, 5.7556, 1.0293, 1.6506,\n",
      "         3.2110]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.002827167510986\n",
      "Epoch: 1 \tStep: 235 \tTime Elapse: 2971.0889377593994 \tLoss: 2.19 \tMean Loss: 2.224 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9752380847930908\n",
      "Parameter containing:\n",
      "tensor([[4.1269, 0.9253, 2.0010, 6.2214, 3.1417, 4.1476, 5.7581, 1.0295, 1.6506,\n",
      "         3.2106]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.997199773788452\n",
      "Epoch: 1 \tStep: 236 \tTime Elapse: 2984.0777792930603 \tLoss: 2.232 \tMean Loss: 2.224 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9906775951385498\n",
      "Parameter containing:\n",
      "tensor([[4.1271, 0.9242, 1.9981, 6.2215, 3.1416, 4.1444, 5.7609, 1.0296, 1.6506,\n",
      "         3.2092]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638012647628784\n",
      "Epoch: 1 \tStep: 237 \tTime Elapse: 2996.7231180667877 \tLoss: 2.149 \tMean Loss: 2.218 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.789538860321045\n",
      "Parameter containing:\n",
      "tensor([[4.1264, 0.9224, 1.9941, 6.2216, 3.1412, 4.1410, 5.7637, 1.0299, 1.6506,\n",
      "         3.2075]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.99340295791626\n",
      "Epoch: 1 \tStep: 238 \tTime Elapse: 3009.522929906845 \tLoss: 2.236 \tMean Loss: 2.219 \tMean Acc: 0.2\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9576692581176758\n",
      "Parameter containing:\n",
      "tensor([[4.1260, 0.9209, 1.9905, 6.2217, 3.1409, 4.1388, 5.7659, 1.0299, 1.6506,\n",
      "         3.2070]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64631700515747\n",
      "Epoch: 1 \tStep: 239 \tTime Elapse: 3022.1433248519897 \tLoss: 2.391 \tMean Loss: 2.231 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.02935791015625\n",
      "Parameter containing:\n",
      "tensor([[4.1242, 0.9182, 1.9851, 6.2218, 3.1401, 4.1368, 5.7679, 1.0300, 1.6506,\n",
      "         3.2065]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.61585807800293\n",
      "Epoch: 1 \tStep: 240 \tTime Elapse: 3034.805334329605 \tLoss: 2.237 \tMean Loss: 2.229 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.946990728378296\n",
      "Parameter containing:\n",
      "tensor([[4.1218, 0.9149, 1.9789, 6.2218, 3.1390, 4.1348, 5.7700, 1.0301, 1.6506,\n",
      "         3.2058]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.672549962997437\n",
      "Epoch: 1 \tStep: 241 \tTime Elapse: 3047.441431045532 \tLoss: 2.223 \tMean Loss: 2.229 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7914819717407227\n",
      "Parameter containing:\n",
      "tensor([[4.1197, 0.9118, 1.9730, 6.2219, 3.1381, 4.1329, 5.7721, 1.0302, 1.6506,\n",
      "         3.2053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.598351240158081\n",
      "Epoch: 1 \tStep: 242 \tTime Elapse: 3059.848272562027 \tLoss: 2.225 \tMean Loss: 2.23 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9996702671051025\n",
      "Parameter containing:\n",
      "tensor([[4.1178, 0.9090, 1.9677, 6.2219, 3.1372, 4.1313, 5.7739, 1.0302, 1.6506,\n",
      "         3.2049]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59803557395935\n",
      "Epoch: 1 \tStep: 243 \tTime Elapse: 3072.46217751503 \tLoss: 2.412 \tMean Loss: 2.244 \tMean Acc: 0.199\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9872572422027588\n",
      "Parameter containing:\n",
      "tensor([[4.1167, 0.9070, 1.9636, 6.2220, 3.1367, 4.1308, 5.7748, 1.0301, 1.6506,\n",
      "         3.2058]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.585180044174194\n",
      "Epoch: 1 \tStep: 244 \tTime Elapse: 3085.0519721508026 \tLoss: 2.389 \tMean Loss: 2.251 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8039970397949219\n",
      "Parameter containing:\n",
      "tensor([[4.1147, 0.9044, 1.9584, 6.2220, 3.1359, 4.1299, 5.7759, 1.0300, 1.6506,\n",
      "         3.2062]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.774722814559937\n",
      "Epoch: 1 \tStep: 245 \tTime Elapse: 3097.6469445228577 \tLoss: 2.23 \tMean Loss: 2.245 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7877159118652344\n",
      "Parameter containing:\n",
      "tensor([[4.1132, 0.9022, 1.9537, 6.2221, 3.1352, 4.1296, 5.7764, 1.0298, 1.6506,\n",
      "         3.2075]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.658902883529663\n",
      "Epoch: 1 \tStep: 246 \tTime Elapse: 3110.1103541851044 \tLoss: 2.164 \tMean Loss: 2.241 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9687392711639404\n",
      "Parameter containing:\n",
      "tensor([[4.1128, 0.9006, 1.9498, 6.2222, 3.1351, 4.1286, 5.7774, 1.0297, 1.6506,\n",
      "         3.2082]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.631712913513184\n",
      "Epoch: 1 \tStep: 247 \tTime Elapse: 3122.7271122932434 \tLoss: 2.242 \tMean Loss: 2.238 \tMean Acc: 0.198\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.003148317337036\n",
      "Parameter containing:\n",
      "tensor([[4.1126, 0.8987, 1.9455, 6.2222, 3.1351, 4.1243, 5.7803, 1.0298, 1.6506,\n",
      "         3.2063]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.617596864700317\n",
      "Epoch: 1 \tStep: 248 \tTime Elapse: 3135.364716529846 \tLoss: 1.705 \tMean Loss: 2.222 \tMean Acc: 0.202\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9862792491912842\n",
      "Parameter containing:\n",
      "tensor([[4.1123, 0.8968, 1.9415, 6.2223, 3.1351, 4.1202, 5.7831, 1.0300, 1.6506,\n",
      "         3.2046]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618662357330322\n",
      "Epoch: 1 \tStep: 249 \tTime Elapse: 3147.9858684539795 \tLoss: 2.196 \tMean Loss: 2.219 \tMean Acc: 0.202\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.823547124862671\n",
      "Parameter containing:\n",
      "tensor([[4.1124, 0.8953, 1.9382, 6.2224, 3.1352, 4.1169, 5.7853, 1.0301, 1.6506,\n",
      "         3.2035]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628315210342407\n",
      "Epoch: 1 \tStep: 250 \tTime Elapse: 3160.4549849033356 \tLoss: 2.404 \tMean Loss: 2.227 \tMean Acc: 0.201\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.967911958694458\n",
      "Parameter containing:\n",
      "tensor([[4.1125, 0.8937, 1.9347, 6.2225, 3.1354, 4.1117, 5.7890, 1.0304, 1.6506,\n",
      "         3.2002]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.876710414886475\n",
      "Epoch: 1 \tStep: 251 \tTime Elapse: 3173.316000699997 \tLoss: 2.028 \tMean Loss: 2.221 \tMean Acc: 0.202\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9946684837341309\n",
      "Parameter containing:\n",
      "tensor([[4.1156, 0.8947, 1.9329, 6.2228, 3.1368, 4.1063, 5.7914, 1.0307, 1.6506,\n",
      "         3.1970]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85077166557312\n",
      "Epoch: 1 \tStep: 252 \tTime Elapse: 3186.178188562393 \tLoss: 2.184 \tMean Loss: 2.214 \tMean Acc: 0.202\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9438772201538086\n",
      "Parameter containing:\n",
      "tensor([[4.1203, 0.8965, 1.9315, 6.2231, 3.1389, 4.1003, 5.7951, 1.0311, 1.6506,\n",
      "         3.1935]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.992926597595215\n",
      "Epoch: 1 \tStep: 253 \tTime Elapse: 3199.131643295288 \tLoss: 1.959 \tMean Loss: 2.205 \tMean Acc: 0.205\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7710902690887451\n",
      "Parameter containing:\n",
      "tensor([[4.1243, 0.8977, 1.9295, 6.2234, 3.1407, 4.0946, 5.7987, 1.0314, 1.6506,\n",
      "         3.1901]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.008334398269653\n",
      "Epoch: 1 \tStep: 254 \tTime Elapse: 3211.929856300354 \tLoss: 2.21 \tMean Loss: 2.207 \tMean Acc: 0.205\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.974194049835205\n",
      "Parameter containing:\n",
      "tensor([[4.1285, 0.8991, 1.9280, 6.2236, 3.1426, 4.0884, 5.8027, 1.0318, 1.6506,\n",
      "         3.1862]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.002825736999512\n",
      "Epoch: 1 \tStep: 255 \tTime Elapse: 3224.923410177231 \tLoss: 2.246 \tMean Loss: 2.213 \tMean Acc: 0.205\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9700391292572021\n",
      "Parameter containing:\n",
      "tensor([[4.1324, 0.9005, 1.9267, 6.2239, 3.1443, 4.0835, 5.8059, 1.0320, 1.6506,\n",
      "         3.1834]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.974565744400024\n",
      "Epoch: 1 \tStep: 256 \tTime Elapse: 3237.8847312927246 \tLoss: 2.41 \tMean Loss: 2.214 \tMean Acc: 0.204\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.78175950050354\n",
      "Parameter containing:\n",
      "tensor([[4.1363, 0.9021, 1.9262, 6.2241, 3.1460, 4.0795, 5.8085, 1.0322, 1.6506,\n",
      "         3.1814]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.163273811340332\n",
      "Epoch: 1 \tStep: 257 \tTime Elapse: 3250.8463711738586 \tLoss: 2.418 \tMean Loss: 2.228 \tMean Acc: 0.203\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.747469425201416\n",
      "Parameter containing:\n",
      "tensor([[4.1375, 0.9015, 1.9229, 6.2244, 3.1466, 4.0757, 5.8116, 1.0324, 1.6506,\n",
      "         3.1793]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.004192590713501\n",
      "Epoch: 1 \tStep: 258 \tTime Elapse: 3263.6185779571533 \tLoss: 2.127 \tMean Loss: 2.219 \tMean Acc: 0.204\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.056504011154175\n",
      "Parameter containing:\n",
      "tensor([[4.1431, 0.9041, 1.9243, 6.2244, 3.1490, 4.0714, 5.8152, 1.0326, 1.6506,\n",
      "         3.1773]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.657482147216797\n",
      "Epoch: 1 \tStep: 259 \tTime Elapse: 3276.349030017853 \tLoss: 2.172 \tMean Loss: 2.218 \tMean Acc: 0.205\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  2.0037009716033936\n",
      "Parameter containing:\n",
      "tensor([[4.1482, 0.9065, 1.9258, 6.2244, 3.1513, 4.0671, 5.8187, 1.0327, 1.6506,\n",
      "         3.1755]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.976337194442749\n",
      "Epoch: 1 \tStep: 260 \tTime Elapse: 3289.3459277153015 \tLoss: 2.236 \tMean Loss: 2.224 \tMean Acc: 0.205\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9899427890777588\n",
      "Parameter containing:\n",
      "tensor([[4.1531, 0.9089, 1.9273, 6.2244, 3.1534, 4.0636, 5.8216, 1.0329, 1.6506,\n",
      "         3.1741]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.992457866668701\n",
      "Epoch: 1 \tStep: 261 \tTime Elapse: 3302.344863653183 \tLoss: 2.419 \tMean Loss: 2.232 \tMean Acc: 0.204\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8222229480743408\n",
      "Parameter containing:\n",
      "tensor([[4.1571, 0.9102, 1.9276, 6.2244, 3.1551, 4.0603, 5.8248, 1.0330, 1.6506,\n",
      "         3.1727]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.994877099990845\n",
      "Epoch: 1 \tStep: 262 \tTime Elapse: 3315.17897605896 \tLoss: 2.166 \tMean Loss: 2.23 \tMean Acc: 0.204\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.957690954208374\n",
      "Parameter containing:\n",
      "tensor([[4.1581, 0.9084, 1.9231, 6.2248, 3.1554, 4.0572, 5.8277, 1.0330, 1.6506,\n",
      "         3.1720]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.003838062286377\n",
      "Epoch: 1 \tStep: 263 \tTime Elapse: 3328.158062696457 \tLoss: 1.873 \tMean Loss: 2.216 \tMean Acc: 0.206\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9693684577941895\n",
      "Parameter containing:\n",
      "tensor([[4.1585, 0.9063, 1.9175, 6.2253, 3.1554, 4.0549, 5.8307, 1.0330, 1.6506,\n",
      "         3.1721]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.670384883880615\n",
      "Epoch: 1 \tStep: 264 \tTime Elapse: 3340.814648628235 \tLoss: 2.043 \tMean Loss: 2.204 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9369347095489502\n",
      "Parameter containing:\n",
      "tensor([[4.1606, 0.9060, 1.9147, 6.2254, 3.1562, 4.0530, 5.8334, 1.0330, 1.6506,\n",
      "         3.1728]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628609895706177\n",
      "Epoch: 1 \tStep: 265 \tTime Elapse: 3353.3968698978424 \tLoss: 2.346 \tMean Loss: 2.209 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7699525356292725\n",
      "Parameter containing:\n",
      "tensor([[4.1616, 0.9046, 1.9107, 6.2257, 3.1564, 4.0517, 5.8356, 1.0329, 1.6506,\n",
      "         3.1741]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.627192974090576\n",
      "Epoch: 1 \tStep: 266 \tTime Elapse: 3365.810620546341 \tLoss: 2.21 \tMean Loss: 2.208 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9829182624816895\n",
      "Parameter containing:\n",
      "tensor([[4.1613, 0.9022, 1.9056, 6.2261, 3.1561, 4.0510, 5.8372, 1.0328, 1.6506,\n",
      "         3.1760]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59922981262207\n",
      "Epoch: 1 \tStep: 267 \tTime Elapse: 3378.4091312885284 \tLoss: 2.219 \tMean Loss: 2.211 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9700796604156494\n",
      "Parameter containing:\n",
      "tensor([[4.1595, 0.8986, 1.8990, 6.2267, 3.1550, 4.0508, 5.8381, 1.0327, 1.6506,\n",
      "         3.1779]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.579037189483643\n",
      "Epoch: 1 \tStep: 268 \tTime Elapse: 3390.977203130722 \tLoss: 2.269 \tMean Loss: 2.212 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8037464618682861\n",
      "Parameter containing:\n",
      "tensor([[4.1585, 0.8959, 1.8934, 6.2272, 3.1544, 4.0505, 5.8386, 1.0326, 1.6506,\n",
      "         3.1798]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.038311958312988\n",
      "Epoch: 1 \tStep: 269 \tTime Elapse: 3403.8360419273376 \tLoss: 2.226 \tMean Loss: 2.206 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7796788215637207\n",
      "Parameter containing:\n",
      "tensor([[4.1584, 0.8942, 1.8893, 6.2276, 3.1541, 4.0508, 5.8387, 1.0324, 1.6506,\n",
      "         3.1823]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.626417636871338\n",
      "Epoch: 1 \tStep: 270 \tTime Elapse: 3416.2595751285553 \tLoss: 2.398 \tMean Loss: 2.212 \tMean Acc: 0.206\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9607548713684082\n",
      "Parameter containing:\n",
      "tensor([[4.1567, 0.8909, 1.8829, 6.2281, 3.1531, 4.0510, 5.8390, 1.0322, 1.6506,\n",
      "         3.1845]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.878005266189575\n",
      "Epoch: 1 \tStep: 271 \tTime Elapse: 3429.1147499084473 \tLoss: 1.995 \tMean Loss: 2.204 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9595341682434082\n",
      "Parameter containing:\n",
      "tensor([[4.1538, 0.8868, 1.8754, 6.2287, 3.1515, 4.0507, 5.8396, 1.0321, 1.6506,\n",
      "         3.1861]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.824917793273926\n",
      "Epoch: 1 \tStep: 272 \tTime Elapse: 3441.916834115982 \tLoss: 1.987 \tMean Loss: 2.196 \tMean Acc: 0.209\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9930427074432373\n",
      "Parameter containing:\n",
      "tensor([[4.1512, 0.8831, 1.8687, 6.2293, 3.1501, 4.0507, 5.8400, 1.0320, 1.6506,\n",
      "         3.1879]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.018150091171265\n",
      "Epoch: 1 \tStep: 273 \tTime Elapse: 3454.9448051452637 \tLoss: 2.422 \tMean Loss: 2.196 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7696335315704346\n",
      "Parameter containing:\n",
      "tensor([[4.1492, 0.8802, 1.8627, 6.2298, 3.1490, 4.0507, 5.8402, 1.0319, 1.6506,\n",
      "         3.1893]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.651164531707764\n",
      "Epoch: 1 \tStep: 274 \tTime Elapse: 3467.382565021515 \tLoss: 2.171 \tMean Loss: 2.189 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9474296569824219\n",
      "Parameter containing:\n",
      "tensor([[4.1501, 0.8791, 1.8587, 6.2300, 3.1490, 4.0511, 5.8391, 1.0316, 1.6506,\n",
      "         3.1925]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.619630098342896\n",
      "Epoch: 1 \tStep: 275 \tTime Elapse: 3479.9661226272583 \tLoss: 2.142 \tMean Loss: 2.186 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9886987209320068\n",
      "Parameter containing:\n",
      "tensor([[4.1515, 0.8783, 1.8559, 6.2301, 3.1491, 4.0521, 5.8373, 1.0312, 1.6506,\n",
      "         3.1964]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.020333051681519\n",
      "Epoch: 1 \tStep: 276 \tTime Elapse: 3492.992159128189 \tLoss: 2.371 \tMean Loss: 2.193 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.95098876953125\n",
      "Parameter containing:\n",
      "tensor([[4.1531, 0.8780, 1.8538, 6.2302, 3.1494, 4.0532, 5.8356, 1.0309, 1.6506,\n",
      "         3.2003]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.830393314361572\n",
      "Epoch: 1 \tStep: 277 \tTime Elapse: 3505.7904567718506 \tLoss: 2.422 \tMean Loss: 2.199 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7716007232666016\n",
      "Parameter containing:\n",
      "tensor([[4.1560, 0.8787, 1.8526, 6.2302, 3.1502, 4.0549, 5.8330, 1.0304, 1.6506,\n",
      "         3.2047]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83688759803772\n",
      "Epoch: 1 \tStep: 278 \tTime Elapse: 3518.4157180786133 \tLoss: 2.339 \tMean Loss: 2.22 \tMean Acc: 0.206\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9561715126037598\n",
      "Parameter containing:\n",
      "tensor([[4.1582, 0.8788, 1.8506, 6.2302, 3.1507, 4.0565, 5.8308, 1.0299, 1.6506,\n",
      "         3.2093]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.839179754257202\n",
      "Epoch: 1 \tStep: 279 \tTime Elapse: 3531.227554798126 \tLoss: 2.129 \tMean Loss: 2.218 \tMean Acc: 0.206\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9693472385406494\n",
      "Parameter containing:\n",
      "tensor([[4.1594, 0.8781, 1.8479, 6.2303, 3.1509, 4.0583, 5.8290, 1.0293, 1.6506,\n",
      "         3.2145]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.854721784591675\n",
      "Epoch: 1 \tStep: 280 \tTime Elapse: 3544.068578720093 \tLoss: 2.081 \tMean Loss: 2.207 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7654259204864502\n",
      "Parameter containing:\n",
      "tensor([[4.1598, 0.8768, 1.8441, 6.2304, 3.1507, 4.0591, 5.8280, 1.0287, 1.6506,\n",
      "         3.2189]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.000443696975708\n",
      "Epoch: 1 \tStep: 281 \tTime Elapse: 3556.850637435913 \tLoss: 2.096 \tMean Loss: 2.209 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7629413604736328\n",
      "Parameter containing:\n",
      "tensor([[4.1618, 0.8768, 1.8422, 6.2304, 3.1513, 4.0595, 5.8280, 1.0283, 1.6506,\n",
      "         3.2226]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.86900544166565\n",
      "Epoch: 1 \tStep: 282 \tTime Elapse: 3569.4994649887085 \tLoss: 2.341 \tMean Loss: 2.215 \tMean Acc: 0.207\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9613687992095947\n",
      "Parameter containing:\n",
      "tensor([[4.1644, 0.8771, 1.8404, 6.2303, 3.1519, 4.0601, 5.8282, 1.0277, 1.6506,\n",
      "         3.2262]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.648604393005371\n",
      "Epoch: 1 \tStep: 283 \tTime Elapse: 3582.126035451889 \tLoss: 2.175 \tMean Loss: 2.222 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9716026782989502\n",
      "Parameter containing:\n",
      "tensor([[4.1669, 0.8769, 1.8377, 6.2301, 3.1524, 4.0607, 5.8280, 1.0271, 1.6506,\n",
      "         3.2304]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62349009513855\n",
      "Epoch: 1 \tStep: 284 \tTime Elapse: 3594.7383625507355 \tLoss: 2.12 \tMean Loss: 2.219 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9862122535705566\n",
      "Parameter containing:\n",
      "tensor([[4.1700, 0.8773, 1.8361, 6.2299, 3.1532, 4.0611, 5.8279, 1.0265, 1.6506,\n",
      "         3.2340]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.646039009094238\n",
      "Epoch: 1 \tStep: 285 \tTime Elapse: 3607.3872079849243 \tLoss: 2.286 \tMean Loss: 2.22 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7547852993011475\n",
      "Parameter containing:\n",
      "tensor([[4.1729, 0.8778, 1.8348, 6.2297, 3.1541, 4.0622, 5.8274, 1.0257, 1.6506,\n",
      "         3.2382]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.636712074279785\n",
      "Epoch: 1 \tStep: 286 \tTime Elapse: 3619.795434474945 \tLoss: 2.223 \tMean Loss: 2.214 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9302911758422852\n",
      "Parameter containing:\n",
      "tensor([[4.1758, 0.8786, 1.8336, 6.2295, 3.1550, 4.0627, 5.8269, 1.0249, 1.6506,\n",
      "         3.2422]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638993263244629\n",
      "Epoch: 1 \tStep: 287 \tTime Elapse: 3632.381180047989 \tLoss: 2.224 \tMean Loss: 2.208 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9716796875\n",
      "Parameter containing:\n",
      "tensor([[4.1774, 0.8783, 1.8311, 6.2294, 3.1553, 4.0634, 5.8262, 1.0242, 1.6506,\n",
      "         3.2461]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.646255254745483\n",
      "Epoch: 1 \tStep: 288 \tTime Elapse: 3645.01597905159 \tLoss: 2.205 \tMean Loss: 2.21 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.934701681137085\n",
      "Parameter containing:\n",
      "tensor([[4.1783, 0.8775, 1.8278, 6.2294, 3.1554, 4.0630, 5.8262, 1.0238, 1.6506,\n",
      "         3.2483]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.61264419555664\n",
      "Epoch: 1 \tStep: 289 \tTime Elapse: 3657.580574989319 \tLoss: 2.252 \tMean Loss: 2.213 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7694358825683594\n",
      "Parameter containing:\n",
      "tensor([[4.1791, 0.8768, 1.8248, 6.2295, 3.1554, 4.0632, 5.8259, 1.0233, 1.6506,\n",
      "         3.2509]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.631545543670654\n",
      "Epoch: 1 \tStep: 290 \tTime Elapse: 3669.999785900116 \tLoss: 2.397 \tMean Loss: 2.218 \tMean Acc: 0.208\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9479482173919678\n",
      "Parameter containing:\n",
      "tensor([[4.1786, 0.8746, 1.8204, 6.2297, 3.1549, 4.0642, 5.8243, 1.0224, 1.6506,\n",
      "         3.2549]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.614683389663696\n",
      "Epoch: 1 \tStep: 291 \tTime Elapse: 3682.579665184021 \tLoss: 2.175 \tMean Loss: 2.21 \tMean Acc: 0.209\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9401228427886963\n",
      "Parameter containing:\n",
      "tensor([[4.1811, 0.8744, 1.8180, 6.2294, 3.1555, 4.0640, 5.8237, 1.0219, 1.6506,\n",
      "         3.2575]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.647920608520508\n",
      "Epoch: 1 \tStep: 292 \tTime Elapse: 3695.184505224228 \tLoss: 2.14 \tMean Loss: 2.209 \tMean Acc: 0.21\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.765648603439331\n",
      "Parameter containing:\n",
      "tensor([[4.1834, 0.8741, 1.8154, 6.2292, 3.1559, 4.0644, 5.8224, 1.0211, 1.6506,\n",
      "         3.2611]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.7736337184906\n",
      "Epoch: 1 \tStep: 293 \tTime Elapse: 3707.740224123001 \tLoss: 2.26 \tMean Loss: 2.222 \tMean Acc: 0.211\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7190122604370117\n",
      "Parameter containing:\n",
      "tensor([[4.1860, 0.8735, 1.8114, 6.2289, 3.1563, 4.0638, 5.8221, 1.0205, 1.6506,\n",
      "         3.2632]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.02467942237854\n",
      "Epoch: 1 \tStep: 294 \tTime Elapse: 3720.5029425621033 \tLoss: 1.82 \tMean Loss: 2.215 \tMean Acc: 0.213\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9353368282318115\n",
      "Parameter containing:\n",
      "tensor([[4.1870, 0.8720, 1.8062, 6.2288, 3.1560, 4.0638, 5.8212, 1.0196, 1.6506,\n",
      "         3.2660]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00824761390686\n",
      "Epoch: 1 \tStep: 295 \tTime Elapse: 3733.4629135131836 \tLoss: 2.106 \tMean Loss: 2.207 \tMean Acc: 0.214\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9605708122253418\n",
      "Parameter containing:\n",
      "tensor([[4.1851, 0.8681, 1.7977, 6.2293, 3.1543, 4.0629, 5.8206, 1.0190, 1.6506,\n",
      "         3.2678]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.988589763641357\n",
      "Epoch: 1 \tStep: 296 \tTime Elapse: 3746.42875790596 \tLoss: 1.944 \tMean Loss: 2.198 \tMean Acc: 0.216\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9682800769805908\n",
      "Parameter containing:\n",
      "tensor([[4.1826, 0.8638, 1.7890, 6.2298, 3.1524, 4.0616, 5.8200, 1.0185, 1.6506,\n",
      "         3.2691]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64136028289795\n",
      "Epoch: 1 \tStep: 297 \tTime Elapse: 3759.0547273159027 \tLoss: 2.213 \tMean Loss: 2.198 \tMean Acc: 0.216\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8277876377105713\n",
      "Parameter containing:\n",
      "tensor([[4.1817, 0.8605, 1.7815, 6.2301, 3.1511, 4.0598, 5.8195, 1.0180, 1.6506,\n",
      "         3.2698]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.605188846588135\n",
      "Epoch: 1 \tStep: 298 \tTime Elapse: 3771.50541472435 \tLoss: 2.277 \tMean Loss: 2.198 \tMean Acc: 0.216\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9402265548706055\n",
      "Parameter containing:\n",
      "tensor([[4.1804, 0.8574, 1.7737, 6.2304, 3.1498, 4.0579, 5.8193, 1.0175, 1.6506,\n",
      "         3.2705]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.603089809417725\n",
      "Epoch: 1 \tStep: 299 \tTime Elapse: 3784.0650861263275 \tLoss: 2.215 \tMean Loss: 2.198 \tMean Acc: 0.217\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.988022804260254\n",
      "Parameter containing:\n",
      "tensor([[4.1784, 0.8531, 1.7643, 6.2308, 3.1481, 4.0532, 5.8206, 1.0177, 1.6506,\n",
      "         3.2683]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.86399793624878\n",
      "Epoch: 1 \tStep: 300 \tTime Elapse: 3796.9345364570618 \tLoss: 1.65 \tMean Loss: 2.173 \tMean Acc: 0.219\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.932328462600708\n",
      "Parameter containing:\n",
      "tensor([[4.1761, 0.8485, 1.7546, 6.2312, 3.1463, 4.0476, 5.8225, 1.0181, 1.6506,\n",
      "         3.2649]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.896194696426392\n",
      "Epoch: 1 \tStep: 301 \tTime Elapse: 3809.7796630859375 \tLoss: 2.001 \tMean Loss: 2.173 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7290451526641846\n",
      "Parameter containing:\n",
      "tensor([[4.1741, 0.8444, 1.7461, 6.2315, 3.1447, 4.0427, 5.8242, 1.0183, 1.6506,\n",
      "         3.2622]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.066052436828613\n",
      "Epoch: 1 \tStep: 302 \tTime Elapse: 3822.591420650482 \tLoss: 2.418 \tMean Loss: 2.187 \tMean Acc: 0.219\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9453225135803223\n",
      "Parameter containing:\n",
      "tensor([[4.1719, 0.8404, 1.7377, 6.2318, 3.1432, 4.0382, 5.8258, 1.0185, 1.6506,\n",
      "         3.2598]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.635412216186523\n",
      "Epoch: 1 \tStep: 303 \tTime Elapse: 3835.1890008449554 \tLoss: 2.204 \tMean Loss: 2.18 \tMean Acc: 0.219\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9420032501220703\n",
      "Parameter containing:\n",
      "tensor([[4.1708, 0.8374, 1.7311, 6.2321, 3.1421, 4.0333, 5.8278, 1.0189, 1.6506,\n",
      "         3.2566]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.599842071533203\n",
      "Epoch: 1 \tStep: 304 \tTime Elapse: 3847.7475192546844 \tLoss: 1.91 \tMean Loss: 2.171 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7628366947174072\n",
      "Parameter containing:\n",
      "tensor([[4.1700, 0.8349, 1.7253, 6.2324, 3.1412, 4.0295, 5.8292, 1.0190, 1.6506,\n",
      "         3.2546]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.793091773986816\n",
      "Epoch: 1 \tStep: 305 \tTime Elapse: 3860.319972515106 \tLoss: 2.413 \tMean Loss: 2.18 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7940409183502197\n",
      "Parameter containing:\n",
      "tensor([[4.1684, 0.8319, 1.7189, 6.2326, 3.1400, 4.0277, 5.8294, 1.0185, 1.6506,\n",
      "         3.2551]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.614806413650513\n",
      "Epoch: 1 \tStep: 306 \tTime Elapse: 3872.7456357479095 \tLoss: 2.166 \tMean Loss: 2.173 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9454150199890137\n",
      "Parameter containing:\n",
      "tensor([[4.1671, 0.8292, 1.7139, 6.2328, 3.1391, 4.0255, 5.8295, 1.0184, 1.6506,\n",
      "         3.2544]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.614587545394897\n",
      "Epoch: 1 \tStep: 307 \tTime Elapse: 3885.3223152160645 \tLoss: 2.297 \tMean Loss: 2.169 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9929566383361816\n",
      "Parameter containing:\n",
      "tensor([[4.1656, 0.8263, 1.7087, 6.2329, 3.1381, 4.0236, 5.8297, 1.0183, 1.6506,\n",
      "         3.2540]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.03147578239441\n",
      "Epoch: 1 \tStep: 308 \tTime Elapse: 3898.363600730896 \tLoss: 2.201 \tMean Loss: 2.165 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.986565113067627\n",
      "Parameter containing:\n",
      "tensor([[4.1645, 0.8238, 1.7044, 6.2331, 3.1372, 4.0220, 5.8294, 1.0180, 1.6506,\n",
      "         3.2541]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.627508640289307\n",
      "Epoch: 1 \tStep: 309 \tTime Elapse: 3910.9941062927246 \tLoss: 2.173 \tMean Loss: 2.166 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7921719551086426\n",
      "Parameter containing:\n",
      "tensor([[4.1635, 0.8213, 1.7002, 6.2332, 3.1366, 4.0208, 5.8292, 1.0177, 1.6506,\n",
      "         3.2544]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.625492095947266\n",
      "Epoch: 1 \tStep: 310 \tTime Elapse: 3923.428507089615 \tLoss: 2.225 \tMean Loss: 2.171 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9909746646881104\n",
      "Parameter containing:\n",
      "tensor([[4.1617, 0.8179, 1.6949, 6.2333, 3.1356, 4.0195, 5.8299, 1.0172, 1.6506,\n",
      "         3.2551]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.662307739257812\n",
      "Epoch: 1 \tStep: 311 \tTime Elapse: 3936.0984358787537 \tLoss: 2.027 \tMean Loss: 2.169 \tMean Acc: 0.221\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9858746528625488\n",
      "Parameter containing:\n",
      "tensor([[4.1617, 0.8163, 1.6922, 6.2335, 3.1353, 4.0182, 5.8303, 1.0168, 1.6506,\n",
      "         3.2559]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.641931772232056\n",
      "Epoch: 1 \tStep: 312 \tTime Elapse: 3948.7443327903748 \tLoss: 2.356 \tMean Loss: 2.169 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.950676679611206\n",
      "Parameter containing:\n",
      "tensor([[4.1623, 0.8154, 1.6900, 6.2337, 3.1353, 4.0174, 5.8302, 1.0162, 1.6506,\n",
      "         3.2570]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628334760665894\n",
      "Epoch: 1 \tStep: 313 \tTime Elapse: 3961.3401358127594 \tLoss: 2.137 \tMean Loss: 2.168 \tMean Acc: 0.22\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7722463607788086\n",
      "Parameter containing:\n",
      "tensor([[4.1641, 0.8154, 1.6884, 6.2340, 3.1359, 4.0145, 5.8314, 1.0162, 1.6506,\n",
      "         3.2556]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.624463319778442\n",
      "Epoch: 1 \tStep: 314 \tTime Elapse: 3973.753881454468 \tLoss: 1.844 \tMean Loss: 2.159 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9957287311553955\n",
      "Parameter containing:\n",
      "tensor([[4.1641, 0.8140, 1.6850, 6.2342, 3.1358, 4.0117, 5.8326, 1.0160, 1.6506,\n",
      "         3.2547]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.852383375167847\n",
      "Epoch: 1 \tStep: 315 \tTime Elapse: 3986.618564605713 \tLoss: 1.985 \tMean Loss: 2.149 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9724714756011963\n",
      "Parameter containing:\n",
      "tensor([[4.1639, 0.8123, 1.6813, 6.2343, 3.1356, 4.0077, 5.8343, 1.0162, 1.6506,\n",
      "         3.2524]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64692211151123\n",
      "Epoch: 1 \tStep: 316 \tTime Elapse: 3999.25470495224 \tLoss: 2.048 \tMean Loss: 2.143 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8114714622497559\n",
      "Parameter containing:\n",
      "tensor([[4.1646, 0.8111, 1.6783, 6.2344, 3.1358, 4.0038, 5.8362, 1.0163, 1.6506,\n",
      "         3.2503]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.776082277297974\n",
      "Epoch: 1 \tStep: 317 \tTime Elapse: 4011.8585391044617 \tLoss: 2.234 \tMean Loss: 2.143 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7757253646850586\n",
      "Parameter containing:\n",
      "tensor([[4.1658, 0.8106, 1.6764, 6.2346, 3.1363, 3.9985, 5.8384, 1.0170, 1.6506,\n",
      "         3.2457]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.00769329071045\n",
      "Epoch: 1 \tStep: 318 \tTime Elapse: 4024.658648967743 \tLoss: 2.26 \tMean Loss: 2.145 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.961501121520996\n",
      "Parameter containing:\n",
      "tensor([[4.1658, 0.8093, 1.6740, 6.2347, 3.1363, 3.9916, 5.8407, 1.0182, 1.6506,\n",
      "         3.2391]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.859776258468628\n",
      "Epoch: 1 \tStep: 319 \tTime Elapse: 4037.4965052604675 \tLoss: 2.053 \tMean Loss: 2.138 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.971445083618164\n",
      "Parameter containing:\n",
      "tensor([[4.1637, 0.8062, 1.6692, 6.2347, 3.1356, 3.9861, 5.8422, 1.0191, 1.6506,\n",
      "         3.2342]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.838825464248657\n",
      "Epoch: 1 \tStep: 320 \tTime Elapse: 4050.3236939907074 \tLoss: 2.224 \tMean Loss: 2.133 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9749860763549805\n",
      "Parameter containing:\n",
      "tensor([[4.1620, 0.8034, 1.6645, 6.2347, 3.1350, 3.9812, 5.8434, 1.0199, 1.6506,\n",
      "         3.2300]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.685400485992432\n",
      "Epoch: 1 \tStep: 321 \tTime Elapse: 4063.0030534267426 \tLoss: 2.239 \tMean Loss: 2.135 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7670893669128418\n",
      "Parameter containing:\n",
      "tensor([[4.1580, 0.7987, 1.6573, 6.2345, 3.1335, 3.9792, 5.8428, 1.0198, 1.6506,\n",
      "         3.2296]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.673099994659424\n",
      "Epoch: 1 \tStep: 322 \tTime Elapse: 4075.4601707458496 \tLoss: 2.22 \tMean Loss: 2.137 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9615812301635742\n",
      "Parameter containing:\n",
      "tensor([[4.1543, 0.7943, 1.6503, 6.2342, 3.1321, 3.9796, 5.8409, 1.0191, 1.6506,\n",
      "         3.2328]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.641814231872559\n",
      "Epoch: 1 \tStep: 323 \tTime Elapse: 4088.0798873901367 \tLoss: 2.357 \tMean Loss: 2.141 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9764671325683594\n",
      "Parameter containing:\n",
      "tensor([[4.1499, 0.7893, 1.6428, 6.2339, 3.1305, 3.9809, 5.8382, 1.0180, 1.6506,\n",
      "         3.2373]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650698900222778\n",
      "Epoch: 1 \tStep: 324 \tTime Elapse: 4100.724094867706 \tLoss: 2.2 \tMean Loss: 2.153 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9547522068023682\n",
      "Parameter containing:\n",
      "tensor([[4.1471, 0.7853, 1.6373, 6.2338, 3.1295, 3.9812, 5.8365, 1.0171, 1.6506,\n",
      "         3.2407]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83451771736145\n",
      "Epoch: 1 \tStep: 325 \tTime Elapse: 4113.530083179474 \tLoss: 2.237 \tMean Loss: 2.158 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7817468643188477\n",
      "Parameter containing:\n",
      "tensor([[4.1444, 0.7817, 1.6323, 6.2336, 3.1286, 3.9812, 5.8353, 1.0164, 1.6506,\n",
      "         3.2436]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.872248411178589\n",
      "Epoch: 1 \tStep: 326 \tTime Elapse: 4126.201067209244 \tLoss: 2.196 \tMean Loss: 2.166 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9272160530090332\n",
      "Parameter containing:\n",
      "tensor([[4.1420, 0.7783, 1.6277, 6.2335, 3.1277, 3.9830, 5.8329, 1.0151, 1.6506,\n",
      "         3.2488]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.866512298583984\n",
      "Epoch: 1 \tStep: 327 \tTime Elapse: 4139.011280536652 \tLoss: 2.373 \tMean Loss: 2.171 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9786441326141357\n",
      "Parameter containing:\n",
      "tensor([[4.1400, 0.7752, 1.6232, 6.2334, 3.1271, 3.9846, 5.8307, 1.0139, 1.6506,\n",
      "         3.2533]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.849378108978271\n",
      "Epoch: 1 \tStep: 328 \tTime Elapse: 4151.856260061264 \tLoss: 2.201 \tMean Loss: 2.169 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7711009979248047\n",
      "Parameter containing:\n",
      "tensor([[4.1383, 0.7725, 1.6196, 6.2334, 3.1266, 3.9865, 5.8285, 1.0127, 1.6506,\n",
      "         3.2580]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.79634976387024\n",
      "Epoch: 1 \tStep: 329 \tTime Elapse: 4164.440362215042 \tLoss: 2.412 \tMean Loss: 2.175 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7785520553588867\n",
      "Parameter containing:\n",
      "tensor([[4.1373, 0.7703, 1.6165, 6.2334, 3.1263, 3.9896, 5.8252, 1.0111, 1.6506,\n",
      "         3.2641]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.611688375473022\n",
      "Epoch: 1 \tStep: 330 \tTime Elapse: 4176.847408771515 \tLoss: 2.382 \tMean Loss: 2.2 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9580104351043701\n",
      "Parameter containing:\n",
      "tensor([[4.1365, 0.7683, 1.6136, 6.2335, 3.1262, 3.9925, 5.8222, 1.0096, 1.6506,\n",
      "         3.2698]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.657441139221191\n",
      "Epoch: 1 \tStep: 331 \tTime Elapse: 4189.4847667217255 \tLoss: 2.182 \tMean Loss: 2.206 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9765775203704834\n",
      "Parameter containing:\n",
      "tensor([[4.1358, 0.7665, 1.6110, 6.2335, 3.1261, 3.9952, 5.8193, 1.0082, 1.6506,\n",
      "         3.2752]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618734121322632\n",
      "Epoch: 1 \tStep: 332 \tTime Elapse: 4202.097194671631 \tLoss: 2.419 \tMean Loss: 2.206 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9659712314605713\n",
      "Parameter containing:\n",
      "tensor([[4.1357, 0.7648, 1.6087, 6.2337, 3.1263, 3.9969, 5.8175, 1.0069, 1.6506,\n",
      "         3.2794]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.63894510269165\n",
      "Epoch: 1 \tStep: 333 \tTime Elapse: 4214.718705177307 \tLoss: 2.033 \tMean Loss: 2.2 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7682530879974365\n",
      "Parameter containing:\n",
      "tensor([[4.1352, 0.7630, 1.6060, 6.2338, 3.1262, 3.9988, 5.8157, 1.0055, 1.6506,\n",
      "         3.2840]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.61479640007019\n",
      "Epoch: 1 \tStep: 334 \tTime Elapse: 4227.119203329086 \tLoss: 2.256 \tMean Loss: 2.212 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9567983150482178\n",
      "Parameter containing:\n",
      "tensor([[4.1347, 0.7615, 1.6036, 6.2338, 3.1262, 4.0006, 5.8138, 1.0041, 1.6506,\n",
      "         3.2884]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.68182921409607\n",
      "Epoch: 1 \tStep: 335 \tTime Elapse: 4239.774780511856 \tLoss: 2.412 \tMean Loss: 2.212 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9861514568328857\n",
      "Parameter containing:\n",
      "tensor([[4.1342, 0.7601, 1.6014, 6.2339, 3.1261, 4.0024, 5.8120, 1.0028, 1.6506,\n",
      "         3.2925]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.842010021209717\n",
      "Epoch: 1 \tStep: 336 \tTime Elapse: 4252.619832277298 \tLoss: 2.417 \tMean Loss: 2.22 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9257545471191406\n",
      "Parameter containing:\n",
      "tensor([[4.1335, 0.7586, 1.5990, 6.2338, 3.1260, 4.0030, 5.8106, 1.0019, 1.6506,\n",
      "         3.2953]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.005611419677734\n",
      "Epoch: 1 \tStep: 337 \tTime Elapse: 4265.567594528198 \tLoss: 2.225 \tMean Loss: 2.218 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.807570457458496\n",
      "Parameter containing:\n",
      "tensor([[4.1331, 0.7575, 1.5971, 6.2339, 3.1260, 4.0041, 5.8089, 1.0009, 1.6506,\n",
      "         3.2983]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.026662349700928\n",
      "Epoch: 1 \tStep: 338 \tTime Elapse: 4278.418984413147 \tLoss: 2.413 \tMean Loss: 2.225 \tMean Acc: 0.221\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9655025005340576\n",
      "Parameter containing:\n",
      "tensor([[4.1315, 0.7551, 1.5930, 6.2336, 3.1258, 4.0052, 5.8077, 0.9997, 1.6506,\n",
      "         3.3013]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.026177644729614\n",
      "Epoch: 1 \tStep: 339 \tTime Elapse: 4291.427374839783 \tLoss: 1.904 \tMean Loss: 2.216 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9861271381378174\n",
      "Parameter containing:\n",
      "tensor([[4.1301, 0.7530, 1.5893, 6.2334, 3.1255, 4.0065, 5.8064, 0.9985, 1.6506,\n",
      "         3.3045]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.018620491027832\n",
      "Epoch: 1 \tStep: 340 \tTime Elapse: 4304.448892593384 \tLoss: 2.423 \tMean Loss: 2.222 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8018155097961426\n",
      "Parameter containing:\n",
      "tensor([[4.1297, 0.7514, 1.5871, 6.2335, 3.1256, 4.0072, 5.8057, 0.9973, 1.6506,\n",
      "         3.3070]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.163158655166626\n",
      "Epoch: 1 \tStep: 341 \tTime Elapse: 4317.430391073227 \tLoss: 2.214 \tMean Loss: 2.229 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7596561908721924\n",
      "Parameter containing:\n",
      "tensor([[4.1271, 0.7481, 1.5823, 6.2330, 3.1249, 4.0083, 5.8049, 0.9959, 1.6506,\n",
      "         3.3100]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.029398918151855\n",
      "Epoch: 1 \tStep: 342 \tTime Elapse: 4330.236233472824 \tLoss: 2.093 \tMean Loss: 2.22 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9768309593200684\n",
      "Parameter containing:\n",
      "tensor([[4.1237, 0.7439, 1.5763, 6.2324, 3.1238, 4.0089, 5.8048, 0.9945, 1.6506,\n",
      "         3.3128]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.027540683746338\n",
      "Epoch: 1 \tStep: 343 \tTime Elapse: 4343.257032632828 \tLoss: 2.065 \tMean Loss: 2.217 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9695112705230713\n",
      "Parameter containing:\n",
      "tensor([[4.1201, 0.7397, 1.5704, 6.2317, 3.1226, 4.0101, 5.8042, 0.9927, 1.6506,\n",
      "         3.3166]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.01112675666809\n",
      "Epoch: 1 \tStep: 344 \tTime Elapse: 4356.254568815231 \tLoss: 2.251 \tMean Loss: 2.231 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9967598915100098\n",
      "Parameter containing:\n",
      "tensor([[4.1168, 0.7359, 1.5648, 6.2310, 3.1215, 4.0113, 5.8031, 0.9911, 1.6506,\n",
      "         3.3202]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.633736371994019\n",
      "Epoch: 1 \tStep: 345 \tTime Elapse: 4368.901286125183 \tLoss: 2.305 \tMean Loss: 2.242 \tMean Acc: 0.222\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7623467445373535\n",
      "Parameter containing:\n",
      "tensor([[4.1137, 0.7321, 1.5597, 6.2304, 3.1205, 4.0117, 5.8021, 0.9902, 1.6506,\n",
      "         3.3223]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.595537900924683\n",
      "Epoch: 1 \tStep: 346 \tTime Elapse: 4381.276115894318 \tLoss: 2.179 \tMean Loss: 2.246 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9519243240356445\n",
      "Parameter containing:\n",
      "tensor([[4.1117, 0.7293, 1.5561, 6.2300, 3.1200, 4.0107, 5.8026, 0.9899, 1.6506,\n",
      "         3.3222]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.610973358154297\n",
      "Epoch: 1 \tStep: 347 \tTime Elapse: 4393.855256080627 \tLoss: 2.284 \tMean Loss: 2.248 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.984013557434082\n",
      "Parameter containing:\n",
      "tensor([[4.1105, 0.7271, 1.5536, 6.2299, 3.1197, 4.0085, 5.8035, 0.9898, 1.6506,\n",
      "         3.3213]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.640209913253784\n",
      "Epoch: 1 \tStep: 348 \tTime Elapse: 4406.49618434906 \tLoss: 2.185 \tMean Loss: 2.245 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9620661735534668\n",
      "Parameter containing:\n",
      "tensor([[4.1098, 0.7254, 1.5517, 6.2299, 3.1197, 4.0052, 5.8056, 0.9901, 1.6506,\n",
      "         3.3191]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64702296257019\n",
      "Epoch: 1 \tStep: 349 \tTime Elapse: 4419.1237642765045 \tLoss: 1.992 \tMean Loss: 2.243 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.791388988494873\n",
      "Parameter containing:\n",
      "tensor([[4.1108, 0.7242, 1.5507, 6.2304, 3.1205, 4.0029, 5.8070, 0.9894, 1.6506,\n",
      "         3.3187]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.609234094619751\n",
      "Epoch: 1 \tStep: 350 \tTime Elapse: 4431.5425679683685 \tLoss: 2.023 \tMean Loss: 2.236 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9669244289398193\n",
      "Parameter containing:\n",
      "tensor([[4.1117, 0.7228, 1.5493, 6.2308, 3.1212, 4.0014, 5.8083, 0.9883, 1.6506,\n",
      "         3.3194]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.623160123825073\n",
      "Epoch: 1 \tStep: 351 \tTime Elapse: 4444.149226427078 \tLoss: 2.279 \tMean Loss: 2.238 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9541800022125244\n",
      "Parameter containing:\n",
      "tensor([[4.1119, 0.7210, 1.5469, 6.2310, 3.1217, 3.9993, 5.8102, 0.9874, 1.6506,\n",
      "         3.3192]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.634916543960571\n",
      "Epoch: 1 \tStep: 352 \tTime Elapse: 4456.755293130875 \tLoss: 2.074 \tMean Loss: 2.233 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7813899517059326\n",
      "Parameter containing:\n",
      "tensor([[4.1129, 0.7194, 1.5445, 6.2314, 3.1227, 3.9988, 5.8107, 0.9861, 1.6506,\n",
      "         3.3209]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.835365295410156\n",
      "Epoch: 1 \tStep: 353 \tTime Elapse: 4469.388646602631 \tLoss: 2.147 \tMean Loss: 2.226 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.788837194442749\n",
      "Parameter containing:\n",
      "tensor([[4.1136, 0.7179, 1.5422, 6.2317, 3.1235, 3.9986, 5.8111, 0.9848, 1.6506,\n",
      "         3.3226]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.63241696357727\n",
      "Epoch: 1 \tStep: 354 \tTime Elapse: 4481.8268876075745 \tLoss: 2.418 \tMean Loss: 2.233 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.947779893875122\n",
      "Parameter containing:\n",
      "tensor([[4.1143, 0.7166, 1.5402, 6.2320, 3.1243, 3.9984, 5.8114, 0.9836, 1.6506,\n",
      "         3.3243]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.607314586639404\n",
      "Epoch: 1 \tStep: 355 \tTime Elapse: 4494.398971557617 \tLoss: 2.42 \tMean Loss: 2.239 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9986176490783691\n",
      "Parameter containing:\n",
      "tensor([[4.1149, 0.7152, 1.5384, 6.2322, 3.1250, 3.9998, 5.8102, 0.9819, 1.6506,\n",
      "         3.3276]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.648083686828613\n",
      "Epoch: 1 \tStep: 356 \tTime Elapse: 4507.062484502792 \tLoss: 2.38 \tMean Loss: 2.245 \tMean Acc: 0.223\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9684138298034668\n",
      "Parameter containing:\n",
      "tensor([[4.1171, 0.7144, 1.5375, 6.2328, 3.1266, 4.0005, 5.8094, 0.9803, 1.6506,\n",
      "         3.3301]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.613708734512329\n",
      "Epoch: 1 \tStep: 357 \tTime Elapse: 4519.660912036896 \tLoss: 1.913 \tMean Loss: 2.23 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7886805534362793\n",
      "Parameter containing:\n",
      "tensor([[4.1194, 0.7136, 1.5372, 6.2334, 3.1282, 4.0002, 5.8092, 0.9792, 1.6506,\n",
      "         3.3316]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.002237796783447\n",
      "Epoch: 1 \tStep: 358 \tTime Elapse: 4532.468522787094 \tLoss: 2.235 \tMean Loss: 2.231 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9520490169525146\n",
      "Parameter containing:\n",
      "tensor([[4.1215, 0.7131, 1.5371, 6.2340, 3.1297, 4.0001, 5.8088, 0.9781, 1.6506,\n",
      "         3.3332]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.8200364112854\n",
      "Epoch: 1 \tStep: 359 \tTime Elapse: 4545.256983757019 \tLoss: 2.407 \tMean Loss: 2.231 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9782440662384033\n",
      "Parameter containing:\n",
      "tensor([[4.1247, 0.7138, 1.5385, 6.2347, 3.1314, 3.9994, 5.8096, 0.9772, 1.6506,\n",
      "         3.3333]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.039903163909912\n",
      "Epoch: 1 \tStep: 360 \tTime Elapse: 4558.292043924332 \tLoss: 2.274 \tMean Loss: 2.227 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9804739952087402\n",
      "Parameter containing:\n",
      "tensor([[4.1285, 0.7145, 1.5400, 6.2354, 3.1335, 3.9987, 5.8101, 0.9765, 1.6506,\n",
      "         3.3332]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.992120265960693\n",
      "Epoch: 1 \tStep: 361 \tTime Elapse: 4571.281159162521 \tLoss: 2.141 \tMean Loss: 2.226 \tMean Acc: 0.224\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7667880058288574\n",
      "Parameter containing:\n",
      "tensor([[4.1341, 0.7165, 1.5429, 6.2363, 3.1363, 3.9945, 5.8136, 0.9774, 1.6506,\n",
      "         3.3288]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.376845598220825\n",
      "Epoch: 1 \tStep: 362 \tTime Elapse: 4584.441750764847 \tLoss: 1.863 \tMean Loss: 2.208 \tMean Acc: 0.225\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9543709754943848\n",
      "Parameter containing:\n",
      "tensor([[4.1383, 0.7175, 1.5443, 6.2371, 3.1386, 3.9902, 5.8173, 0.9782, 1.6506,\n",
      "         3.3245]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.869885206222534\n",
      "Epoch: 1 \tStep: 363 \tTime Elapse: 4597.282603263855 \tLoss: 1.975 \tMean Loss: 2.206 \tMean Acc: 0.226\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9740486145019531\n",
      "Parameter containing:\n",
      "tensor([[4.1416, 0.7178, 1.5440, 6.2378, 3.1404, 3.9868, 5.8197, 0.9783, 1.6506,\n",
      "         3.3219]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.86307668685913\n",
      "Epoch: 1 \tStep: 364 \tTime Elapse: 4610.136942863464 \tLoss: 2.187 \tMean Loss: 2.203 \tMean Acc: 0.226\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.761364221572876\n",
      "Parameter containing:\n",
      "tensor([[4.1447, 0.7178, 1.5432, 6.2384, 3.1422, 3.9837, 5.8220, 0.9780, 1.6506,\n",
      "         3.3198]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.005541324615479\n",
      "Epoch: 1 \tStep: 365 \tTime Elapse: 4622.920587778091 \tLoss: 2.192 \tMean Loss: 2.196 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7905683517456055\n",
      "Parameter containing:\n",
      "tensor([[4.1460, 0.7160, 1.5401, 6.2390, 3.1432, 3.9810, 5.8243, 0.9779, 1.6506,\n",
      "         3.3179]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.635597467422485\n",
      "Epoch: 1 \tStep: 366 \tTime Elapse: 4635.363570213318 \tLoss: 1.966 \tMean Loss: 2.181 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9412059783935547\n",
      "Parameter containing:\n",
      "tensor([[4.1464, 0.7138, 1.5363, 6.2395, 3.1439, 3.9802, 5.8248, 0.9770, 1.6506,\n",
      "         3.3183]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.632591009140015\n",
      "Epoch: 1 \tStep: 367 \tTime Elapse: 4647.953994512558 \tLoss: 2.351 \tMean Loss: 2.185 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9571263790130615\n",
      "Parameter containing:\n",
      "tensor([[4.1471, 0.7118, 1.5330, 6.2399, 3.1445, 3.9803, 5.8245, 0.9758, 1.6506,\n",
      "         3.3198]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.587315082550049\n",
      "Epoch: 1 \tStep: 368 \tTime Elapse: 4660.515845537186 \tLoss: 2.386 \tMean Loss: 2.184 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9588544368743896\n",
      "Parameter containing:\n",
      "tensor([[4.1467, 0.7097, 1.5284, 6.2404, 3.1448, 3.9797, 5.8244, 0.9747, 1.6506,\n",
      "         3.3207]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.616423606872559\n",
      "Epoch: 1 \tStep: 369 \tTime Elapse: 4673.107910394669 \tLoss: 2.084 \tMean Loss: 2.19 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7469482421875\n",
      "Parameter containing:\n",
      "tensor([[4.1487, 0.7088, 1.5274, 6.2407, 3.1458, 3.9779, 5.8257, 0.9740, 1.6506,\n",
      "         3.3205]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.565449476242065\n",
      "Epoch: 1 \tStep: 370 \tTime Elapse: 4685.437782526016 \tLoss: 2.225 \tMean Loss: 2.184 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8958370685577393\n",
      "Parameter containing:\n",
      "tensor([[4.1511, 0.7083, 1.5270, 6.2409, 3.1470, 3.9749, 5.8279, 0.9740, 1.6506,\n",
      "         3.3187]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618981838226318\n",
      "Epoch: 1 \tStep: 371 \tTime Elapse: 4697.969644784927 \tLoss: 2.238 \tMean Loss: 2.184 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.930983066558838\n",
      "Parameter containing:\n",
      "tensor([[4.1538, 0.7080, 1.5272, 6.2411, 3.1482, 3.9711, 5.8304, 0.9744, 1.6506,\n",
      "         3.3159]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.592726230621338\n",
      "Epoch: 1 \tStep: 372 \tTime Elapse: 4710.510568618774 \tLoss: 2.2 \tMean Loss: 2.188 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9265422821044922\n",
      "Parameter containing:\n",
      "tensor([[4.1565, 0.7079, 1.5276, 6.2413, 3.1494, 3.9680, 5.8325, 0.9746, 1.6506,\n",
      "         3.3136]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638873815536499\n",
      "Epoch: 1 \tStep: 373 \tTime Elapse: 4723.094587564468 \tLoss: 2.424 \tMean Loss: 2.2 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.732804536819458\n",
      "Parameter containing:\n",
      "tensor([[4.1600, 0.7085, 1.5291, 6.2413, 3.1510, 3.9651, 5.8343, 0.9747, 1.6506,\n",
      "         3.3117]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.552362442016602\n",
      "Epoch: 1 \tStep: 374 \tTime Elapse: 4735.397107124329 \tLoss: 2.397 \tMean Loss: 2.205 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9565374851226807\n",
      "Parameter containing:\n",
      "tensor([[4.1640, 0.7090, 1.5303, 6.2412, 3.1525, 3.9598, 5.8376, 0.9757, 1.6506,\n",
      "         3.3071]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.600634574890137\n",
      "Epoch: 1 \tStep: 375 \tTime Elapse: 4747.971054792404 \tLoss: 1.799 \tMean Loss: 2.188 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9671664237976074\n",
      "Parameter containing:\n",
      "tensor([[4.1677, 0.7093, 1.5314, 6.2411, 3.1539, 3.9567, 5.8396, 0.9758, 1.6506,\n",
      "         3.3053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.629084587097168\n",
      "Epoch: 1 \tStep: 376 \tTime Elapse: 4760.584218263626 \tLoss: 2.376 \tMean Loss: 2.195 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.793504238128662\n",
      "Parameter containing:\n",
      "tensor([[4.1711, 0.7095, 1.5322, 6.2410, 3.1551, 3.9554, 5.8403, 0.9752, 1.6506,\n",
      "         3.3053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.771907329559326\n",
      "Epoch: 1 \tStep: 377 \tTime Elapse: 4773.166079521179 \tLoss: 2.375 \tMean Loss: 2.198 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7501065731048584\n",
      "Parameter containing:\n",
      "tensor([[4.1748, 0.7101, 1.5336, 6.2408, 3.1565, 3.9535, 5.8419, 0.9749, 1.6506,\n",
      "         3.3045]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638618469238281\n",
      "Epoch: 1 \tStep: 378 \tTime Elapse: 4785.571904182434 \tLoss: 1.937 \tMean Loss: 2.189 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.923658847808838\n",
      "Parameter containing:\n",
      "tensor([[4.1784, 0.7108, 1.5352, 6.2405, 3.1579, 3.9520, 5.8433, 0.9745, 1.6506,\n",
      "         3.3040]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.984113693237305\n",
      "Epoch: 1 \tStep: 379 \tTime Elapse: 4798.496250629425 \tLoss: 2.423 \tMean Loss: 2.204 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.931415319442749\n",
      "Parameter containing:\n",
      "tensor([[4.1822, 0.7119, 1.5373, 6.2402, 3.1593, 3.9513, 5.8439, 0.9738, 1.6506,\n",
      "         3.3045]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.022623062133789\n",
      "Epoch: 1 \tStep: 380 \tTime Elapse: 4811.467175483704 \tLoss: 2.402 \tMean Loss: 2.216 \tMean Acc: 0.226\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.932018518447876\n",
      "Parameter containing:\n",
      "tensor([[4.1864, 0.7134, 1.5398, 6.2397, 3.1609, 3.9509, 5.8449, 0.9729, 1.6506,\n",
      "         3.3053]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.663045883178711\n",
      "Epoch: 1 \tStep: 381 \tTime Elapse: 4824.079218864441 \tLoss: 2.191 \tMean Loss: 2.213 \tMean Acc: 0.226\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7263154983520508\n",
      "Parameter containing:\n",
      "tensor([[4.1903, 0.7147, 1.5420, 6.2392, 3.1624, 3.9497, 5.8465, 0.9724, 1.6506,\n",
      "         3.3051]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.641862630844116\n",
      "Epoch: 1 \tStep: 382 \tTime Elapse: 4836.465034723282 \tLoss: 2.209 \tMean Loss: 2.218 \tMean Acc: 0.226\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9162113666534424\n",
      "Parameter containing:\n",
      "tensor([[4.1955, 0.7169, 1.5456, 6.2383, 3.1642, 3.9481, 5.8482, 0.9721, 1.6506,\n",
      "         3.3044]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.621002674102783\n",
      "Epoch: 1 \tStep: 383 \tTime Elapse: 4849.018779993057 \tLoss: 2.12 \tMean Loss: 2.217 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9724719524383545\n",
      "Parameter containing:\n",
      "tensor([[4.1996, 0.7184, 1.5482, 6.2376, 3.1655, 3.9458, 5.8497, 0.9720, 1.6506,\n",
      "         3.3033]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.622848987579346\n",
      "Epoch: 1 \tStep: 384 \tTime Elapse: 4861.63122344017 \tLoss: 2.19 \tMean Loss: 2.209 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9251294136047363\n",
      "Parameter containing:\n",
      "tensor([[4.2032, 0.7197, 1.5503, 6.2371, 3.1664, 3.9423, 5.8522, 0.9723, 1.6506,\n",
      "         3.3005]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.819889783859253\n",
      "Epoch: 1 \tStep: 385 \tTime Elapse: 4874.392917633057 \tLoss: 2.093 \tMean Loss: 2.198 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7501060962677002\n",
      "Parameter containing:\n",
      "tensor([[4.2065, 0.7207, 1.5519, 6.2366, 3.1670, 3.9386, 5.8546, 0.9727, 1.6506,\n",
      "         3.2975]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62855076789856\n",
      "Epoch: 1 \tStep: 386 \tTime Elapse: 4886.788851737976 \tLoss: 2.291 \tMean Loss: 2.195 \tMean Acc: 0.227\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9672424793243408\n",
      "Parameter containing:\n",
      "tensor([[4.2086, 0.7211, 1.5523, 6.2364, 3.1673, 3.9350, 5.8570, 0.9729, 1.6506,\n",
      "         3.2946]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.633021593093872\n",
      "Epoch: 1 \tStep: 387 \tTime Elapse: 4899.405703544617 \tLoss: 1.939 \tMean Loss: 2.196 \tMean Acc: 0.228\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9304842948913574\n",
      "Parameter containing:\n",
      "tensor([[4.2126, 0.7224, 1.5544, 6.2355, 3.1681, 3.9305, 5.8606, 0.9735, 1.6506,\n",
      "         3.2906]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.994510650634766\n",
      "Epoch: 1 \tStep: 388 \tTime Elapse: 4912.347515583038 \tLoss: 1.877 \tMean Loss: 2.184 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7373595237731934\n",
      "Parameter containing:\n",
      "tensor([[4.2169, 0.7240, 1.5571, 6.2345, 3.1691, 3.9279, 5.8626, 0.9732, 1.6506,\n",
      "         3.2892]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.779629945755005\n",
      "Epoch: 1 \tStep: 389 \tTime Elapse: 4924.8812084198 \tLoss: 2.305 \tMean Loss: 2.181 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7288622856140137\n",
      "Parameter containing:\n",
      "tensor([[4.2217, 0.7259, 1.5603, 6.2331, 3.1703, 3.9250, 5.8647, 0.9731, 1.6506,\n",
      "         3.2874]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.983484029769897\n",
      "Epoch: 1 \tStep: 390 \tTime Elapse: 4937.610601186752 \tLoss: 2.205 \tMean Loss: 2.179 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9085817337036133\n",
      "Parameter containing:\n",
      "tensor([[4.2283, 0.7285, 1.5656, 6.2311, 3.1724, 3.9210, 5.8672, 0.9733, 1.6506,\n",
      "         3.2848]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.982181787490845\n",
      "Epoch: 1 \tStep: 391 \tTime Elapse: 4950.517985582352 \tLoss: 2.059 \tMean Loss: 2.176 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9934816360473633\n",
      "Parameter containing:\n",
      "tensor([[4.2330, 0.7299, 1.5688, 6.2297, 3.1737, 3.9182, 5.8685, 0.9731, 1.6506,\n",
      "         3.2836]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.03233814239502\n",
      "Epoch: 1 \tStep: 392 \tTime Elapse: 4963.560550689697 \tLoss: 2.248 \tMean Loss: 2.189 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9791162014007568\n",
      "Parameter containing:\n",
      "tensor([[4.2342, 0.7292, 1.5680, 6.2298, 3.1728, 3.9178, 5.8673, 0.9720, 1.6506,\n",
      "         3.2854]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.01911211013794\n",
      "Epoch: 1 \tStep: 393 \tTime Elapse: 4976.575459241867 \tLoss: 2.228 \tMean Loss: 2.197 \tMean Acc: 0.229\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7702586650848389\n",
      "Parameter containing:\n",
      "tensor([[4.2374, 0.7301, 1.5698, 6.2289, 3.1733, 3.9147, 5.8685, 0.9719, 1.6506,\n",
      "         3.2837]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650326490402222\n",
      "Epoch: 1 \tStep: 394 \tTime Elapse: 4989.013258695602 \tLoss: 2.09 \tMean Loss: 2.194 \tMean Acc: 0.23\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9427249431610107\n",
      "Parameter containing:\n",
      "tensor([[4.2384, 0.7293, 1.5686, 6.2291, 3.1722, 3.9133, 5.8691, 0.9713, 1.6506,\n",
      "         3.2836]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.862786531448364\n",
      "Epoch: 1 \tStep: 395 \tTime Elapse: 5001.835766077042 \tLoss: 2.193 \tMean Loss: 2.194 \tMean Acc: 0.23\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9369430541992188\n",
      "Parameter containing:\n",
      "tensor([[4.2374, 0.7268, 1.5648, 6.2300, 3.1700, 3.9142, 5.8679, 0.9701, 1.6506,\n",
      "         3.2859]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.612583875656128\n",
      "Epoch: 1 \tStep: 396 \tTime Elapse: 5014.402549505234 \tLoss: 2.196 \tMean Loss: 2.202 \tMean Acc: 0.23\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9358694553375244\n",
      "Parameter containing:\n",
      "tensor([[4.2374, 0.7250, 1.5617, 6.2304, 3.1682, 3.9154, 5.8667, 0.9687, 1.6506,\n",
      "         3.2886]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62046217918396\n",
      "Epoch: 1 \tStep: 397 \tTime Elapse: 5026.975599527359 \tLoss: 2.087 \tMean Loss: 2.193 \tMean Acc: 0.231\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.719506025314331\n",
      "Parameter containing:\n",
      "tensor([[4.2362, 0.7226, 1.5573, 6.2313, 3.1660, 3.9179, 5.8642, 0.9665, 1.6506,\n",
      "         3.2933]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.607483148574829\n",
      "Epoch: 1 \tStep: 398 \tTime Elapse: 5039.319624185562 \tLoss: 2.258 \tMean Loss: 2.189 \tMean Acc: 0.231\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.948256254196167\n",
      "Parameter containing:\n",
      "tensor([[4.2353, 0.7203, 1.5536, 6.2320, 3.1638, 3.9200, 5.8619, 0.9645, 1.6506,\n",
      "         3.2977]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83479642868042\n",
      "Epoch: 1 \tStep: 399 \tTime Elapse: 5052.119189023972 \tLoss: 2.204 \tMean Loss: 2.193 \tMean Acc: 0.231\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9173784255981445\n",
      "Parameter containing:\n",
      "tensor([[4.2343, 0.7180, 1.5498, 6.2327, 3.1617, 3.9227, 5.8585, 0.9621, 1.6506,\n",
      "         3.3033]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.841452598571777\n",
      "Epoch: 1 \tStep: 400 \tTime Elapse: 5064.895095825195 \tLoss: 2.295 \tMean Loss: 2.195 \tMean Acc: 0.231\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.72914457321167\n",
      "Parameter containing:\n",
      "tensor([[4.2331, 0.7158, 1.5463, 6.2335, 3.1598, 3.9242, 5.8569, 0.9603, 1.6506,\n",
      "         3.3072]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.001965045928955\n",
      "Epoch: 1 \tStep: 401 \tTime Elapse: 5077.642968893051 \tLoss: 2.137 \tMean Loss: 2.192 \tMean Acc: 0.231\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7274000644683838\n",
      "Parameter containing:\n",
      "tensor([[4.2295, 0.7115, 1.5401, 6.2348, 3.1567, 3.9260, 5.8549, 0.9585, 1.6506,\n",
      "         3.3113]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.842303037643433\n",
      "Epoch: 1 \tStep: 402 \tTime Elapse: 5090.230016469955 \tLoss: 2.15 \tMean Loss: 2.19 \tMean Acc: 0.232\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9221172332763672\n",
      "Parameter containing:\n",
      "tensor([[4.2265, 0.7074, 1.5344, 6.2359, 3.1539, 3.9260, 5.8535, 0.9572, 1.6506,\n",
      "         3.3140]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.82621717453003\n",
      "Epoch: 1 \tStep: 403 \tTime Elapse: 5102.9951713085175 \tLoss: 2.091 \tMean Loss: 2.179 \tMean Acc: 0.233\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.949944257736206\n",
      "Parameter containing:\n",
      "tensor([[4.2236, 0.7034, 1.5290, 6.2370, 3.1513, 3.9253, 5.8523, 0.9561, 1.6506,\n",
      "         3.3160]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.82770562171936\n",
      "Epoch: 1 \tStep: 404 \tTime Elapse: 5115.789681196213 \tLoss: 2.154 \tMean Loss: 2.171 \tMean Acc: 0.233\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9391653537750244\n",
      "Parameter containing:\n",
      "tensor([[4.2209, 0.6997, 1.5242, 6.2379, 3.1488, 3.9247, 5.8512, 0.9552, 1.6506,\n",
      "         3.3178]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.630929470062256\n",
      "Epoch: 1 \tStep: 405 \tTime Elapse: 5128.37682723999 \tLoss: 2.416 \tMean Loss: 2.191 \tMean Acc: 0.232\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.886016845703125\n",
      "Parameter containing:\n",
      "tensor([[4.2192, 0.6967, 1.5201, 6.2387, 3.1469, 3.9261, 5.8489, 0.9533, 1.6506,\n",
      "         3.3220]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.630438327789307\n",
      "Epoch: 1 \tStep: 406 \tTime Elapse: 5140.910553693771 \tLoss: 2.317 \tMean Loss: 2.189 \tMean Acc: 0.232\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9388089179992676\n",
      "Parameter containing:\n",
      "tensor([[4.2169, 0.6929, 1.5150, 6.2395, 3.1448, 3.9279, 5.8471, 0.9512, 1.6506,\n",
      "         3.3263]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.60299825668335\n",
      "Epoch: 1 \tStep: 407 \tTime Elapse: 5153.469306468964 \tLoss: 2.054 \tMean Loss: 2.179 \tMean Acc: 0.232\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.966684341430664\n",
      "Parameter containing:\n",
      "tensor([[4.2153, 0.6893, 1.5105, 6.2402, 3.1431, 3.9254, 5.8470, 0.9513, 1.6506,\n",
      "         3.3257]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.620250940322876\n",
      "Epoch: 1 \tStep: 408 \tTime Elapse: 5166.073139667511 \tLoss: 1.722 \tMean Loss: 2.171 \tMean Acc: 0.234\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.950305461883545\n",
      "Parameter containing:\n",
      "tensor([[4.2144, 0.6856, 1.5065, 6.2408, 3.1417, 3.9224, 5.8470, 0.9514, 1.6506,\n",
      "         3.3249]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.836270809173584\n",
      "Epoch: 1 \tStep: 409 \tTime Elapse: 5178.8765733242035 \tLoss: 2.078 \tMean Loss: 2.16 \tMean Acc: 0.235\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7715823650360107\n",
      "Parameter containing:\n",
      "tensor([[4.2135, 0.6822, 1.5029, 6.2413, 3.1404, 3.9199, 5.8471, 0.9516, 1.6506,\n",
      "         3.3242]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.856595516204834\n",
      "Epoch: 1 \tStep: 410 \tTime Elapse: 5191.521815776825 \tLoss: 2.416 \tMean Loss: 2.16 \tMean Acc: 0.234\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9463365077972412\n",
      "Parameter containing:\n",
      "tensor([[4.2126, 0.6787, 1.4993, 6.2418, 3.1392, 3.9182, 5.8467, 0.9512, 1.6506,\n",
      "         3.3247]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.850735902786255\n",
      "Epoch: 1 \tStep: 411 \tTime Elapse: 5204.335697412491 \tLoss: 2.145 \tMean Loss: 2.159 \tMean Acc: 0.234\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.939708948135376\n",
      "Parameter containing:\n",
      "tensor([[4.2132, 0.6765, 1.4971, 6.2423, 3.1386, 3.9159, 5.8476, 0.9510, 1.6506,\n",
      "         3.3238]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.876033306121826\n",
      "Epoch: 1 \tStep: 412 \tTime Elapse: 5217.168639183044 \tLoss: 1.896 \tMean Loss: 2.148 \tMean Acc: 0.235\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7360656261444092\n",
      "Parameter containing:\n",
      "tensor([[4.2132, 0.6738, 1.4950, 6.2427, 3.1379, 3.9128, 5.8485, 0.9510, 1.6506,\n",
      "         3.3231]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.025467872619629\n",
      "Epoch: 1 \tStep: 413 \tTime Elapse: 5229.9469430446625 \tLoss: 2.112 \tMean Loss: 2.148 \tMean Acc: 0.235\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7285408973693848\n",
      "Parameter containing:\n",
      "tensor([[4.2129, 0.6707, 1.4923, 6.2431, 3.1373, 3.9093, 5.8501, 0.9514, 1.6506,\n",
      "         3.3213]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.858720541000366\n",
      "Epoch: 1 \tStep: 414 \tTime Elapse: 5242.551206111908 \tLoss: 2.004 \tMean Loss: 2.142 \tMean Acc: 0.236\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9057350158691406\n",
      "Parameter containing:\n",
      "tensor([[4.2132, 0.6680, 1.4903, 6.2434, 3.1369, 3.9066, 5.8509, 0.9513, 1.6506,\n",
      "         3.3207]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.643847703933716\n",
      "Epoch: 1 \tStep: 415 \tTime Elapse: 5255.118079423904 \tLoss: 2.163 \tMean Loss: 2.144 \tMean Acc: 0.236\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9452450275421143\n",
      "Parameter containing:\n",
      "tensor([[4.2154, 0.6661, 1.4902, 6.2439, 3.1374, 3.9039, 5.8525, 0.9511, 1.6506,\n",
      "         3.3194]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638224840164185\n",
      "Epoch: 1 \tStep: 416 \tTime Elapse: 5267.720851659775 \tLoss: 2.011 \tMean Loss: 2.135 \tMean Acc: 0.236\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9512481689453125\n",
      "Parameter containing:\n",
      "tensor([[4.2177, 0.6645, 1.4900, 6.2443, 3.1380, 3.9003, 5.8543, 0.9513, 1.6506,\n",
      "         3.3172]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.646626234054565\n",
      "Epoch: 1 \tStep: 417 \tTime Elapse: 5280.335481405258 \tLoss: 2.055 \tMean Loss: 2.139 \tMean Acc: 0.237\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7711632251739502\n",
      "Parameter containing:\n",
      "tensor([[4.2205, 0.6636, 1.4907, 6.2447, 3.1389, 3.8967, 5.8557, 0.9513, 1.6506,\n",
      "         3.3155]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.005463600158691\n",
      "Epoch: 1 \tStep: 418 \tTime Elapse: 5293.133677959442 \tLoss: 2.324 \tMean Loss: 2.154 \tMean Acc: 0.236\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.942697525024414\n",
      "Parameter containing:\n",
      "tensor([[4.2230, 0.6623, 1.4909, 6.2451, 3.1396, 3.8936, 5.8572, 0.9507, 1.6506,\n",
      "         3.3148]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.973532676696777\n",
      "Epoch: 1 \tStep: 419 \tTime Elapse: 5306.066723823547 \tLoss: 1.973 \tMean Loss: 2.143 \tMean Acc: 0.237\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9568219184875488\n",
      "Parameter containing:\n",
      "tensor([[4.2248, 0.6598, 1.4900, 6.2455, 3.1402, 3.8906, 5.8595, 0.9495, 1.6506,\n",
      "         3.3149]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.029094219207764\n",
      "Epoch: 1 \tStep: 420 \tTime Elapse: 5319.06983590126 \tLoss: 1.856 \tMean Loss: 2.131 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9387695789337158\n",
      "Parameter containing:\n",
      "tensor([[4.2248, 0.6557, 1.4868, 6.2457, 3.1401, 3.8891, 5.8613, 0.9477, 1.6506,\n",
      "         3.3164]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.013204574584961\n",
      "Epoch: 1 \tStep: 421 \tTime Elapse: 5332.03854227066 \tLoss: 1.995 \tMean Loss: 2.129 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7330665588378906\n",
      "Parameter containing:\n",
      "tensor([[4.2254, 0.6522, 1.4843, 6.2460, 3.1403, 3.8888, 5.8628, 0.9455, 1.6506,\n",
      "         3.3191]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.636391401290894\n",
      "Epoch: 1 \tStep: 422 \tTime Elapse: 5344.425514698029 \tLoss: 2.161 \tMean Loss: 2.126 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9544157981872559\n",
      "Parameter containing:\n",
      "tensor([[4.2267, 0.6492, 1.4829, 6.2462, 3.1407, 3.8879, 5.8643, 0.9436, 1.6506,\n",
      "         3.3214]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.604531049728394\n",
      "Epoch: 1 \tStep: 423 \tTime Elapse: 5357.0026795864105 \tLoss: 2.318 \tMean Loss: 2.129 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9461922645568848\n",
      "Parameter containing:\n",
      "tensor([[4.2287, 0.6467, 1.4814, 6.2464, 3.1414, 3.8864, 5.8660, 0.9419, 1.6506,\n",
      "         3.3227]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.57161021232605\n",
      "Epoch: 1 \tStep: 424 \tTime Elapse: 5369.5376060009 \tLoss: 1.984 \tMean Loss: 2.126 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.781381368637085\n",
      "Parameter containing:\n",
      "tensor([[4.2304, 0.6440, 1.4793, 6.2467, 3.1419, 3.8826, 5.8697, 0.9410, 1.6506,\n",
      "         3.3213]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.76565170288086\n",
      "Epoch: 1 \tStep: 425 \tTime Elapse: 5382.101492166519 \tLoss: 1.609 \tMean Loss: 2.106 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7336595058441162\n",
      "Parameter containing:\n",
      "tensor([[4.2317, 0.6412, 1.4769, 6.2468, 3.1424, 3.8781, 5.8740, 0.9407, 1.6506,\n",
      "         3.3187]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.604376316070557\n",
      "Epoch: 1 \tStep: 426 \tTime Elapse: 5394.459089517593 \tLoss: 1.994 \tMean Loss: 2.099 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9431421756744385\n",
      "Parameter containing:\n",
      "tensor([[4.2342, 0.6395, 1.4760, 6.2470, 3.1432, 3.8729, 5.8786, 0.9410, 1.6506,\n",
      "         3.3149]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.900567293167114\n",
      "Epoch: 1 \tStep: 427 \tTime Elapse: 5407.320141077042 \tLoss: 2.259 \tMean Loss: 2.105 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9623441696166992\n",
      "Parameter containing:\n",
      "tensor([[4.2378, 0.6395, 1.4765, 6.2471, 3.1444, 3.8672, 5.8831, 0.9415, 1.6506,\n",
      "         3.3105]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.845617532730103\n",
      "Epoch: 1 \tStep: 428 \tTime Elapse: 5420.145348548889 \tLoss: 2.125 \tMean Loss: 2.101 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9614362716674805\n",
      "Parameter containing:\n",
      "tensor([[4.2421, 0.6402, 1.4779, 6.2472, 3.1458, 3.8622, 5.8872, 0.9416, 1.6506,\n",
      "         3.3069]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85782790184021\n",
      "Epoch: 1 \tStep: 429 \tTime Elapse: 5432.981344461441 \tLoss: 2.148 \tMean Loss: 2.099 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.742720127105713\n",
      "Parameter containing:\n",
      "tensor([[4.2465, 0.6412, 1.4795, 6.2472, 3.1472, 3.8564, 5.8918, 0.9420, 1.6506,\n",
      "         3.3024]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85719108581543\n",
      "Epoch: 1 \tStep: 430 \tTime Elapse: 5445.59836602211 \tLoss: 1.922 \tMean Loss: 2.086 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9212558269500732\n",
      "Parameter containing:\n",
      "tensor([[4.2506, 0.6422, 1.4811, 6.2472, 3.1486, 3.8524, 5.8951, 0.9416, 1.6506,\n",
      "         3.3002]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.865185260772705\n",
      "Epoch: 1 \tStep: 431 \tTime Elapse: 5458.40206861496 \tLoss: 2.333 \tMean Loss: 2.093 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9501516819000244\n",
      "Parameter containing:\n",
      "tensor([[4.2543, 0.6430, 1.4829, 6.2472, 3.1498, 3.8478, 5.8995, 0.9411, 1.6506,\n",
      "         3.2977]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650692701339722\n",
      "Epoch: 1 \tStep: 432 \tTime Elapse: 5471.020056962967 \tLoss: 2.056 \tMean Loss: 2.09 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.94419264793396\n",
      "Parameter containing:\n",
      "tensor([[4.2583, 0.6439, 1.4850, 6.2471, 3.1511, 3.8445, 5.9027, 0.9403, 1.6506,\n",
      "         3.2963]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618142127990723\n",
      "Epoch: 1 \tStep: 433 \tTime Elapse: 5483.598994016647 \tLoss: 2.372 \tMean Loss: 2.099 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.767927885055542\n",
      "Parameter containing:\n",
      "tensor([[4.2641, 0.6455, 1.4883, 6.2467, 3.1529, 3.8418, 5.9055, 0.9387, 1.6506,\n",
      "         3.2964]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638092994689941\n",
      "Epoch: 1 \tStep: 434 \tTime Elapse: 5496.022214651108 \tLoss: 1.934 \tMean Loss: 2.092 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9645771980285645\n",
      "Parameter containing:\n",
      "tensor([[4.2695, 0.6467, 1.4914, 6.2463, 3.1544, 3.8386, 5.9070, 0.9373, 1.6506,\n",
      "         3.2965]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628670930862427\n",
      "Epoch: 1 \tStep: 435 \tTime Elapse: 5508.632426023483 \tLoss: 2.092 \tMean Loss: 2.081 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9548063278198242\n",
      "Parameter containing:\n",
      "tensor([[4.2740, 0.6475, 1.4935, 6.2461, 3.1555, 3.8369, 5.9074, 0.9349, 1.6506,\n",
      "         3.2991]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.598324537277222\n",
      "Epoch: 1 \tStep: 436 \tTime Elapse: 5521.202491760254 \tLoss: 2.227 \tMean Loss: 2.078 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7368323802947998\n",
      "Parameter containing:\n",
      "tensor([[4.2778, 0.6481, 1.4954, 6.2459, 3.1564, 3.8354, 5.9077, 0.9329, 1.6506,\n",
      "         3.3013]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.775848150253296\n",
      "Epoch: 1 \tStep: 437 \tTime Elapse: 5533.732485532761 \tLoss: 2.401 \tMean Loss: 2.09 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7418313026428223\n",
      "Parameter containing:\n",
      "tensor([[4.2819, 0.6489, 1.4977, 6.2455, 3.1575, 3.8333, 5.9088, 0.9309, 1.6506,\n",
      "         3.3031]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.613229751586914\n",
      "Epoch: 1 \tStep: 438 \tTime Elapse: 5546.104514598846 \tLoss: 2.102 \tMean Loss: 2.102 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9108104705810547\n",
      "Parameter containing:\n",
      "tensor([[4.2845, 0.6492, 1.4988, 6.2455, 3.1581, 3.8306, 5.9114, 0.9289, 1.6506,\n",
      "         3.3042]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.664775848388672\n",
      "Epoch: 1 \tStep: 439 \tTime Elapse: 5558.698237657547 \tLoss: 1.918 \tMean Loss: 2.097 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9211797714233398\n",
      "Parameter containing:\n",
      "tensor([[4.2868, 0.6492, 1.4993, 6.2455, 3.1586, 3.8288, 5.9137, 0.9266, 1.6506,\n",
      "         3.3063]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.652527809143066\n",
      "Epoch: 1 \tStep: 440 \tTime Elapse: 5571.289110660553 \tLoss: 2.138 \tMean Loss: 2.088 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9290618896484375\n",
      "Parameter containing:\n",
      "tensor([[4.2889, 0.6493, 1.4999, 6.2455, 3.1591, 3.8280, 5.9148, 0.9242, 1.6506,\n",
      "         3.3092]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.003880977630615\n",
      "Epoch: 1 \tStep: 441 \tTime Elapse: 5584.238963365555 \tLoss: 2.392 \tMean Loss: 2.096 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7444446086883545\n",
      "Parameter containing:\n",
      "tensor([[4.2903, 0.6490, 1.4997, 6.2456, 3.1592, 3.8283, 5.9147, 0.9215, 1.6506,\n",
      "         3.3131]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.971957683563232\n",
      "Epoch: 1 \tStep: 442 \tTime Elapse: 5596.972496509552 \tLoss: 2.153 \tMean Loss: 2.104 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.90700101852417\n",
      "Parameter containing:\n",
      "tensor([[4.2916, 0.6488, 1.4997, 6.2457, 3.1593, 3.8285, 5.9148, 0.9191, 1.6506,\n",
      "         3.3166]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.983627080917358\n",
      "Epoch: 1 \tStep: 443 \tTime Elapse: 5609.880044937134 \tLoss: 2.426 \tMean Loss: 2.115 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9378414154052734\n",
      "Parameter containing:\n",
      "tensor([[4.2925, 0.6486, 1.4992, 6.2458, 3.1594, 3.8282, 5.9156, 0.9172, 1.6506,\n",
      "         3.3186]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.97158408164978\n",
      "Epoch: 1 \tStep: 444 \tTime Elapse: 5622.806661128998 \tLoss: 2.232 \tMean Loss: 2.123 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9130022525787354\n",
      "Parameter containing:\n",
      "tensor([[4.2932, 0.6482, 1.4988, 6.2460, 3.1593, 3.8285, 5.9155, 0.9154, 1.6506,\n",
      "         3.3213]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.688720226287842\n",
      "Epoch: 1 \tStep: 445 \tTime Elapse: 5635.424997806549 \tLoss: 2.4 \tMean Loss: 2.13 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7655973434448242\n",
      "Parameter containing:\n",
      "tensor([[4.2939, 0.6478, 1.4985, 6.2461, 3.1593, 3.8291, 5.9152, 0.9137, 1.6506,\n",
      "         3.3240]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.666925430297852\n",
      "Epoch: 1 \tStep: 446 \tTime Elapse: 5647.8743777275085 \tLoss: 2.441 \tMean Loss: 2.145 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9738473892211914\n",
      "Parameter containing:\n",
      "tensor([[4.2945, 0.6474, 1.4982, 6.2463, 3.1592, 3.8306, 5.9141, 0.9115, 1.6506,\n",
      "         3.3279]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.628327369689941\n",
      "Epoch: 1 \tStep: 447 \tTime Elapse: 5660.493252277374 \tLoss: 2.434 \tMean Loss: 2.157 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9453072547912598\n",
      "Parameter containing:\n",
      "tensor([[4.2951, 0.6470, 1.4980, 6.2464, 3.1591, 3.8330, 5.9122, 0.9092, 1.6506,\n",
      "         3.3329]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.992450475692749\n",
      "Epoch: 1 \tStep: 448 \tTime Elapse: 5673.447957515717 \tLoss: 2.42 \tMean Loss: 2.161 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7304375171661377\n",
      "Parameter containing:\n",
      "tensor([[4.2962, 0.6465, 1.4984, 6.2463, 3.1591, 3.8367, 5.9097, 0.9058, 1.6506,\n",
      "         3.3400]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.155083417892456\n",
      "Epoch: 1 \tStep: 449 \tTime Elapse: 5686.3505437374115 \tLoss: 2.372 \tMean Loss: 2.174 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7313263416290283\n",
      "Parameter containing:\n",
      "tensor([[4.2971, 0.6459, 1.4988, 6.2462, 3.1591, 3.8409, 5.9066, 0.9025, 1.6506,\n",
      "         3.3476]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.000309228897095\n",
      "Epoch: 1 \tStep: 450 \tTime Elapse: 5699.099236726761 \tLoss: 2.431 \tMean Loss: 2.193 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9202139377593994\n",
      "Parameter containing:\n",
      "tensor([[4.2981, 0.6455, 1.4992, 6.2462, 3.1591, 3.8444, 5.9041, 0.8995, 1.6506,\n",
      "         3.3541]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.962971925735474\n",
      "Epoch: 1 \tStep: 451 \tTime Elapse: 5711.999039411545 \tLoss: 2.208 \tMean Loss: 2.2 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.938805341720581\n",
      "Parameter containing:\n",
      "tensor([[4.2986, 0.6447, 1.4992, 6.2462, 3.1588, 3.8493, 5.9002, 0.8959, 1.6506,\n",
      "         3.3624]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.62572455406189\n",
      "Epoch: 1 \tStep: 452 \tTime Elapse: 5724.58034992218 \tLoss: 2.4 \tMean Loss: 2.208 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9375345706939697\n",
      "Parameter containing:\n",
      "tensor([[4.2990, 0.6432, 1.4991, 6.2463, 3.1582, 3.8556, 5.8945, 0.8908, 1.6506,\n",
      "         3.3738]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.593312740325928\n",
      "Epoch: 1 \tStep: 453 \tTime Elapse: 5737.1284329891205 \tLoss: 2.14 \tMean Loss: 2.202 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7436065673828125\n",
      "Parameter containing:\n",
      "tensor([[4.2994, 0.6419, 1.4991, 6.2463, 3.1576, 3.8622, 5.8886, 0.8857, 1.6506,\n",
      "         3.3852]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.612594842910767\n",
      "Epoch: 1 \tStep: 454 \tTime Elapse: 5749.501830816269 \tLoss: 2.421 \tMean Loss: 2.217 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9190340042114258\n",
      "Parameter containing:\n",
      "tensor([[4.2995, 0.6405, 1.4988, 6.2464, 3.1569, 3.8693, 5.8824, 0.8802, 1.6506,\n",
      "         3.3972]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59779167175293\n",
      "Epoch: 1 \tStep: 455 \tTime Elapse: 5762.035477638245 \tLoss: 2.387 \tMean Loss: 2.243 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9367754459381104\n",
      "Parameter containing:\n",
      "tensor([[4.2982, 0.6379, 1.4968, 6.2468, 3.1557, 3.8770, 5.8761, 0.8738, 1.6506,\n",
      "         3.4102]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.621159791946411\n",
      "Epoch: 1 \tStep: 456 \tTime Elapse: 5774.61048078537 \tLoss: 2.094 \tMean Loss: 2.246 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9117374420166016\n",
      "Parameter containing:\n",
      "tensor([[4.2972, 0.6357, 1.4951, 6.2471, 3.1545, 3.8845, 5.8700, 0.8674, 1.6506,\n",
      "         3.4228]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.576998710632324\n",
      "Epoch: 1 \tStep: 457 \tTime Elapse: 5787.116127729416 \tLoss: 2.258 \tMean Loss: 2.246 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7259621620178223\n",
      "Parameter containing:\n",
      "tensor([[4.2950, 0.6328, 1.4922, 6.2477, 3.1529, 3.8920, 5.8633, 0.8608, 1.6506,\n",
      "         3.4358]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.626278162002563\n",
      "Epoch: 1 \tStep: 458 \tTime Elapse: 5799.485693693161 \tLoss: 2.242 \tMean Loss: 2.25 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.920844316482544\n",
      "Parameter containing:\n",
      "tensor([[4.2930, 0.6302, 1.4896, 6.2482, 3.1514, 3.8988, 5.8572, 0.8550, 1.6506,\n",
      "         3.4475]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.575217008590698\n",
      "Epoch: 1 \tStep: 459 \tTime Elapse: 5811.999126672745 \tLoss: 2.418 \tMean Loss: 2.259 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9290015697479248\n",
      "Parameter containing:\n",
      "tensor([[4.2894, 0.6268, 1.4850, 6.2489, 3.1495, 3.9063, 5.8511, 0.8480, 1.6506,\n",
      "         3.4605]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.819698095321655\n",
      "Epoch: 1 \tStep: 460 \tTime Elapse: 5824.765000581741 \tLoss: 2.221 \tMean Loss: 2.269 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9681732654571533\n",
      "Parameter containing:\n",
      "tensor([[4.2883, 0.6248, 1.4828, 6.2493, 3.1482, 3.9116, 5.8461, 0.8431, 1.6506,\n",
      "         3.4705]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  12.237220764160156\n",
      "Epoch: 1 \tStep: 461 \tTime Elapse: 5838.991694688797 \tLoss: 2.047 \tMean Loss: 2.259 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7363831996917725\n",
      "Parameter containing:\n",
      "tensor([[4.2879, 0.6233, 1.4811, 6.2496, 3.1473, 3.9160, 5.8417, 0.8390, 1.6506,\n",
      "         3.4786]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.081156253814697\n",
      "Epoch: 1 \tStep: 462 \tTime Elapse: 5851.826493740082 \tLoss: 2.258 \tMean Loss: 2.266 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7711279392242432\n",
      "Parameter containing:\n",
      "tensor([[4.2875, 0.6218, 1.4794, 6.2498, 3.1464, 3.9209, 5.8369, 0.8346, 1.6506,\n",
      "         3.4872]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.606409311294556\n",
      "Epoch: 1 \tStep: 463 \tTime Elapse: 5864.220431089401 \tLoss: 2.374 \tMean Loss: 2.266 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.768449306488037\n",
      "Parameter containing:\n",
      "tensor([[4.2882, 0.6210, 1.4788, 6.2500, 3.1459, 3.9270, 5.8319, 0.8293, 1.6506,\n",
      "         3.4972]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.366810321807861\n",
      "Epoch: 1 \tStep: 464 \tTime Elapse: 5876.372596979141 \tLoss: 2.279 \tMean Loss: 2.278 \tMean Acc: 0.237\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7668273448944092\n",
      "Parameter containing:\n",
      "tensor([[4.2880, 0.6195, 1.4773, 6.2502, 3.1452, 3.9326, 5.8275, 0.8242, 1.6506,\n",
      "         3.5064]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.350664854049683\n",
      "Epoch: 1 \tStep: 465 \tTime Elapse: 5888.50648021698 \tLoss: 2.228 \tMean Loss: 2.282 \tMean Acc: 0.237\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.5964419841766357\n",
      "Parameter containing:\n",
      "tensor([[4.2892, 0.6187, 1.4761, 6.2503, 3.1449, 3.9342, 5.8255, 0.8214, 1.6506,\n",
      "         3.5099]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.31796407699585\n",
      "Epoch: 1 \tStep: 466 \tTime Elapse: 5900.437841415405 \tLoss: 1.872 \tMean Loss: 2.27 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7631609439849854\n",
      "Parameter containing:\n",
      "tensor([[4.2893, 0.6176, 1.4744, 6.2504, 3.1444, 3.9340, 5.8246, 0.8209, 1.6506,\n",
      "         3.5108]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.762311458587646\n",
      "Epoch: 1 \tStep: 467 \tTime Elapse: 5912.979745388031 \tLoss: 2.27 \tMean Loss: 2.266 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7675299644470215\n",
      "Parameter containing:\n",
      "tensor([[4.2903, 0.6171, 1.4741, 6.2505, 3.1442, 3.9327, 5.8244, 0.8210, 1.6506,\n",
      "         3.5107]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.769093036651611\n",
      "Epoch: 1 \tStep: 468 \tTime Elapse: 5925.533205986023 \tLoss: 2.287 \tMean Loss: 2.272 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7951018810272217\n",
      "Parameter containing:\n",
      "tensor([[4.2943, 0.6185, 1.4769, 6.2505, 3.1450, 3.9304, 5.8251, 0.8207, 1.6506,\n",
      "         3.5094]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.740604639053345\n",
      "Epoch: 1 \tStep: 469 \tTime Elapse: 5938.085393667221 \tLoss: 2.173 \tMean Loss: 2.281 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.5952012538909912\n",
      "Parameter containing:\n",
      "tensor([[4.2976, 0.6192, 1.4788, 6.2505, 3.1456, 3.9286, 5.8256, 0.8197, 1.6506,\n",
      "         3.5088]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.3275785446167\n",
      "Epoch: 1 \tStep: 470 \tTime Elapse: 5950.025101423264 \tLoss: 2.196 \tMean Loss: 2.282 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7464385032653809\n",
      "Parameter containing:\n",
      "tensor([[4.3014, 0.6201, 1.4816, 6.2504, 3.1464, 3.9276, 5.8256, 0.8177, 1.6506,\n",
      "         3.5095]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.347607851028442\n",
      "Epoch: 1 \tStep: 471 \tTime Elapse: 5962.1358053684235 \tLoss: 2.077 \tMean Loss: 2.272 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7898542881011963\n",
      "Parameter containing:\n",
      "tensor([[4.3042, 0.6205, 1.4835, 6.2504, 3.1469, 3.9272, 5.8252, 0.8153, 1.6506,\n",
      "         3.5109]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.602745771408081\n",
      "Epoch: 1 \tStep: 472 \tTime Elapse: 5974.544959783554 \tLoss: 2.203 \tMean Loss: 2.274 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6294090747833252\n",
      "Parameter containing:\n",
      "tensor([[4.3081, 0.6217, 1.4867, 6.2502, 3.1478, 3.9265, 5.8253, 0.8134, 1.6506,\n",
      "         3.5118]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.773388862609863\n",
      "Epoch: 1 \tStep: 473 \tTime Elapse: 5986.965049028397 \tLoss: 2.337 \tMean Loss: 2.271 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.5818665027618408\n",
      "Parameter containing:\n",
      "tensor([[4.3123, 0.6230, 1.4902, 6.2500, 3.1488, 3.9260, 5.8248, 0.8109, 1.6506,\n",
      "         3.5133]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.59890103340149\n",
      "Epoch: 1 \tStep: 474 \tTime Elapse: 5999.163175106049 \tLoss: 2.206 \tMean Loss: 2.27 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7526319026947021\n",
      "Parameter containing:\n",
      "tensor([[4.3162, 0.6240, 1.4939, 6.2499, 3.1497, 3.9252, 5.8247, 0.8085, 1.6506,\n",
      "         3.5145]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.593471050262451\n",
      "Epoch: 1 \tStep: 475 \tTime Elapse: 6011.525891542435 \tLoss: 2.324 \tMean Loss: 2.267 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.771742343902588\n",
      "Parameter containing:\n",
      "tensor([[4.3195, 0.6245, 1.4966, 6.2497, 3.1504, 3.9259, 5.8238, 0.8043, 1.6506,\n",
      "         3.5175]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.587719202041626\n",
      "Epoch: 1 \tStep: 476 \tTime Elapse: 6023.902210712433 \tLoss: 2.257 \tMean Loss: 2.261 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.784472942352295\n",
      "Parameter containing:\n",
      "tensor([[4.3226, 0.6250, 1.4994, 6.2496, 3.1510, 3.9276, 5.8218, 0.7990, 1.6506,\n",
      "         3.5222]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.757447481155396\n",
      "Epoch: 1 \tStep: 477 \tTime Elapse: 6036.461796045303 \tLoss: 2.353 \tMean Loss: 2.258 \tMean Acc: 0.238\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.5956625938415527\n",
      "Parameter containing:\n",
      "tensor([[4.3238, 0.6241, 1.4992, 6.2497, 3.1508, 3.9296, 5.8193, 0.7927, 1.6506,\n",
      "         3.5275]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.731171607971191\n",
      "Epoch: 1 \tStep: 478 \tTime Elapse: 6048.805579423904 \tLoss: 1.793 \tMean Loss: 2.238 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7538094520568848\n",
      "Parameter containing:\n",
      "tensor([[4.3241, 0.6225, 1.4979, 6.2499, 3.1503, 3.9327, 5.8158, 0.7851, 1.6506,\n",
      "         3.5346]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.72125244140625\n",
      "Epoch: 1 \tStep: 479 \tTime Elapse: 6061.297022342682 \tLoss: 2.22 \tMean Loss: 2.232 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7617955207824707\n",
      "Parameter containing:\n",
      "tensor([[4.3243, 0.6211, 1.4968, 6.2501, 3.1499, 3.9359, 5.8122, 0.7780, 1.6506,\n",
      "         3.5415]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.324837684631348\n",
      "Epoch: 1 \tStep: 480 \tTime Elapse: 6073.400639295578 \tLoss: 2.429 \tMean Loss: 2.232 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.792313575744629\n",
      "Parameter containing:\n",
      "tensor([[4.3279, 0.6225, 1.4991, 6.2498, 3.1505, 3.9347, 5.8112, 0.7756, 1.6506,\n",
      "         3.5423]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.353614568710327\n",
      "Epoch: 1 \tStep: 481 \tTime Elapse: 6085.562948703766 \tLoss: 1.849 \tMean Loss: 2.22 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6106746196746826\n",
      "Parameter containing:\n",
      "tensor([[4.3321, 0.6241, 1.5016, 6.2495, 3.1513, 3.9349, 5.8095, 0.7707, 1.6506,\n",
      "         3.5455]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.715834140777588\n",
      "Epoch: 1 \tStep: 482 \tTime Elapse: 6097.906728506088 \tLoss: 2.205 \tMean Loss: 2.214 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7836577892303467\n",
      "Parameter containing:\n",
      "tensor([[4.3371, 0.6264, 1.5055, 6.2489, 3.1524, 3.9345, 5.8082, 0.7670, 1.6506,\n",
      "         3.5477]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.573923826217651\n",
      "Epoch: 1 \tStep: 483 \tTime Elapse: 6110.281115055084 \tLoss: 2.392 \tMean Loss: 2.222 \tMean Acc: 0.239\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.796203851699829\n",
      "Parameter containing:\n",
      "tensor([[4.3428, 0.6294, 1.5100, 6.2482, 3.1536, 3.9327, 5.8064, 0.7643, 1.6506,\n",
      "         3.5485]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.571325540542603\n",
      "Epoch: 1 \tStep: 484 \tTime Elapse: 6122.665495872498 \tLoss: 2.112 \tMean Loss: 2.212 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6283884048461914\n",
      "Parameter containing:\n",
      "tensor([[4.3482, 0.6319, 1.5142, 6.2476, 3.1544, 3.9336, 5.8023, 0.7587, 1.6506,\n",
      "         3.5533]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.518421173095703\n",
      "Epoch: 1 \tStep: 485 \tTime Elapse: 6134.828655004501 \tLoss: 2.127 \tMean Loss: 2.203 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6128315925598145\n",
      "Parameter containing:\n",
      "tensor([[4.3522, 0.6332, 1.5174, 6.2471, 3.1547, 3.9365, 5.7965, 0.7508, 1.6506,\n",
      "         3.5615]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.313449144363403\n",
      "Epoch: 1 \tStep: 486 \tTime Elapse: 6146.77140045166 \tLoss: 2.09 \tMean Loss: 2.203 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7948336601257324\n",
      "Parameter containing:\n",
      "tensor([[4.3550, 0.6335, 1.5192, 6.2469, 3.1545, 3.9381, 5.7918, 0.7437, 1.6506,\n",
      "         3.5678]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.352230548858643\n",
      "Epoch: 1 \tStep: 487 \tTime Elapse: 6158.935161828995 \tLoss: 2.062 \tMean Loss: 2.197 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7959990501403809\n",
      "Parameter containing:\n",
      "tensor([[4.3584, 0.6342, 1.5215, 6.2465, 3.1547, 3.9410, 5.7868, 0.7356, 1.6506,\n",
      "         3.5755]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.315960884094238\n",
      "Epoch: 1 \tStep: 488 \tTime Elapse: 6171.064051151276 \tLoss: 2.302 \tMean Loss: 2.199 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.807889699935913\n",
      "Parameter containing:\n",
      "tensor([[4.3618, 0.6349, 1.5236, 6.2461, 3.1549, 3.9427, 5.7830, 0.7285, 1.6506,\n",
      "         3.5813]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.276618957519531\n",
      "Epoch: 1 \tStep: 489 \tTime Elapse: 6183.165120124817 \tLoss: 1.978 \tMean Loss: 2.184 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6151044368743896\n",
      "Parameter containing:\n",
      "tensor([[4.3657, 0.6362, 1.5258, 6.2456, 3.1555, 3.9431, 5.7810, 0.7227, 1.6506,\n",
      "         3.5849]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.3080313205719\n",
      "Epoch: 1 \tStep: 490 \tTime Elapse: 6195.105129480362 \tLoss: 2.279 \tMean Loss: 2.186 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.787330150604248\n",
      "Parameter containing:\n",
      "tensor([[4.3695, 0.6374, 1.5282, 6.2450, 3.1562, 3.9450, 5.7780, 0.7155, 1.6506,\n",
      "         3.5903]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.601359367370605\n",
      "Epoch: 1 \tStep: 491 \tTime Elapse: 6207.510158777237 \tLoss: 2.332 \tMean Loss: 2.195 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7775437831878662\n",
      "Parameter containing:\n",
      "tensor([[4.3726, 0.6382, 1.5300, 6.2446, 3.1566, 3.9460, 5.7754, 0.7104, 1.6506,\n",
      "         3.5939]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.596790075302124\n",
      "Epoch: 1 \tStep: 492 \tTime Elapse: 6219.901565313339 \tLoss: 2.31 \tMean Loss: 2.197 \tMean Acc: 0.24\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.801478624343872\n",
      "Parameter containing:\n",
      "tensor([[4.3744, 0.6379, 1.5315, 6.2444, 3.1564, 3.9448, 5.7734, 0.7068, 1.6506,\n",
      "         3.5955]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.563615798950195\n",
      "Epoch: 1 \tStep: 493 \tTime Elapse: 6232.28311419487 \tLoss: 2.11 \tMean Loss: 2.188 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6230919361114502\n",
      "Parameter containing:\n",
      "tensor([[4.3757, 0.6366, 1.5322, 6.2444, 3.1561, 3.9435, 5.7716, 0.7032, 1.6506,\n",
      "         3.5963]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.594099283218384\n",
      "Epoch: 1 \tStep: 494 \tTime Elapse: 6244.517285823822 \tLoss: 2.203 \tMean Loss: 2.186 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7843620777130127\n",
      "Parameter containing:\n",
      "tensor([[4.3730, 0.6327, 1.5288, 6.2453, 3.1540, 3.9415, 5.7697, 0.7002, 1.6506,\n",
      "         3.5963]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.317126750946045\n",
      "Epoch: 1 \tStep: 495 \tTime Elapse: 6256.635046720505 \tLoss: 1.948 \tMean Loss: 2.177 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7786803245544434\n",
      "Parameter containing:\n",
      "tensor([[4.3707, 0.6292, 1.5264, 6.2460, 3.1523, 3.9394, 5.7683, 0.6984, 1.6506,\n",
      "         3.5957]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.309713363647461\n",
      "Epoch: 1 \tStep: 496 \tTime Elapse: 6268.740588188171 \tLoss: 2.363 \tMean Loss: 2.193 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6255247592926025\n",
      "Parameter containing:\n",
      "tensor([[4.3687, 0.6255, 1.5234, 6.2467, 3.1508, 3.9379, 5.7670, 0.6951, 1.6506,\n",
      "         3.5960]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.90847134590149\n",
      "Epoch: 1 \tStep: 497 \tTime Elapse: 6281.291355133057 \tLoss: 2.197 \tMean Loss: 2.19 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.647385597229004\n",
      "Parameter containing:\n",
      "tensor([[4.3655, 0.6210, 1.5193, 6.2475, 3.1488, 3.9370, 5.7655, 0.6915, 1.6506,\n",
      "         3.5969]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.776371717453003\n",
      "Epoch: 1 \tStep: 498 \tTime Elapse: 6293.731595754623 \tLoss: 2.188 \tMean Loss: 2.187 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7855329513549805\n",
      "Parameter containing:\n",
      "tensor([[4.3649, 0.6186, 1.5181, 6.2479, 3.1479, 3.9341, 5.7652, 0.6893, 1.6506,\n",
      "         3.5956]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.745024919509888\n",
      "Epoch: 1 \tStep: 499 \tTime Elapse: 6306.278542041779 \tLoss: 2.282 \tMean Loss: 2.191 \tMean Acc: 0.241\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7771086692810059\n",
      "Parameter containing:\n",
      "tensor([[4.3641, 0.6163, 1.5164, 6.2484, 3.1470, 3.9315, 5.7650, 0.6868, 1.6506,\n",
      "         3.5944]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.761425256729126\n",
      "Epoch: 1 \tStep: 500 \tTime Elapse: 6318.833965778351 \tLoss: 2.327 \tMean Loss: 2.195 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.797569990158081\n",
      "Parameter containing:\n",
      "tensor([[4.3625, 0.6138, 1.5139, 6.2489, 3.1459, 3.9280, 5.7653, 0.6855, 1.6506,\n",
      "         3.5919]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.763280391693115\n",
      "Epoch: 1 \tStep: 501 \tTime Elapse: 6331.4113965034485 \tLoss: 2.277 \tMean Loss: 2.202 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7377979755401611\n",
      "Parameter containing:\n",
      "tensor([[4.3614, 0.6115, 1.5119, 6.2493, 3.1450, 3.9254, 5.7646, 0.6834, 1.6506,\n",
      "         3.5908]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.316324472427368\n",
      "Epoch: 1 \tStep: 502 \tTime Elapse: 6343.482207775116 \tLoss: 2.153 \tMean Loss: 2.2 \tMean Acc: 0.242\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7868967056274414\n",
      "Parameter containing:\n",
      "tensor([[4.3588, 0.6082, 1.5081, 6.2497, 3.1435, 3.9208, 5.7656, 0.6816, 1.6506,\n",
      "         3.5877]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.725879669189453\n",
      "Epoch: 1 \tStep: 503 \tTime Elapse: 6356.011749982834 \tLoss: 1.929 \tMean Loss: 2.187 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8040895462036133\n",
      "Parameter containing:\n",
      "tensor([[4.3552, 0.6042, 1.5031, 6.2502, 3.1418, 3.9158, 5.7675, 0.6800, 1.6506,\n",
      "         3.5840]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.717805624008179\n",
      "Epoch: 1 \tStep: 504 \tTime Elapse: 6368.5505340099335 \tLoss: 2.03 \tMean Loss: 2.181 \tMean Acc: 0.243\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.801943063735962\n",
      "Parameter containing:\n",
      "tensor([[4.3523, 0.6004, 1.4983, 6.2506, 3.1404, 3.9097, 5.7703, 0.6786, 1.6506,\n",
      "         3.5790]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.774410486221313\n",
      "Epoch: 1 \tStep: 505 \tTime Elapse: 6381.143363952637 \tLoss: 2.05 \tMean Loss: 2.172 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6175262928009033\n",
      "Parameter containing:\n",
      "tensor([[4.3498, 0.5969, 1.4944, 6.2510, 3.1391, 3.9016, 5.7739, 0.6784, 1.6506,\n",
      "         3.5722]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.775012254714966\n",
      "Epoch: 1 \tStep: 506 \tTime Elapse: 6393.552589893341 \tLoss: 2.043 \tMean Loss: 2.164 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.784862995147705\n",
      "Parameter containing:\n",
      "tensor([[4.3477, 0.5937, 1.4909, 6.2513, 3.1380, 3.8944, 5.7771, 0.6784, 1.6506,\n",
      "         3.5660]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.325321435928345\n",
      "Epoch: 1 \tStep: 507 \tTime Elapse: 6405.679566144943 \tLoss: 2.414 \tMean Loss: 2.167 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.79042387008667\n",
      "Parameter containing:\n",
      "tensor([[4.3456, 0.5909, 1.4879, 6.2516, 3.1370, 3.8867, 5.7811, 0.6801, 1.6506,\n",
      "         3.5584]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.30276608467102\n",
      "Epoch: 1 \tStep: 508 \tTime Elapse: 6417.7896065711975 \tLoss: 2.249 \tMean Loss: 2.182 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.614588737487793\n",
      "Parameter containing:\n",
      "tensor([[4.3432, 0.5878, 1.4842, 6.2518, 3.1360, 3.8818, 5.7832, 0.6801, 1.6506,\n",
      "         3.5543]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.869658708572388\n",
      "Epoch: 1 \tStep: 509 \tTime Elapse: 6430.290532588959 \tLoss: 2.167 \tMean Loss: 2.18 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.605250358581543\n",
      "Parameter containing:\n",
      "tensor([[4.3389, 0.5835, 1.4787, 6.2518, 3.1344, 3.8769, 5.7853, 0.6799, 1.6506,\n",
      "         3.5502]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.737244129180908\n",
      "Epoch: 1 \tStep: 510 \tTime Elapse: 6442.649693965912 \tLoss: 2.102 \tMean Loss: 2.169 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7816309928894043\n",
      "Parameter containing:\n",
      "tensor([[4.3347, 0.5793, 1.4730, 6.2518, 3.1329, 3.8737, 5.7855, 0.6777, 1.6506,\n",
      "         3.5489]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.618237018585205\n",
      "Epoch: 1 \tStep: 511 \tTime Elapse: 6455.068285226822 \tLoss: 2.195 \tMean Loss: 2.181 \tMean Acc: 0.244\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.778296947479248\n",
      "Parameter containing:\n",
      "tensor([[4.3302, 0.5748, 1.4668, 6.2516, 3.1314, 3.8693, 5.7868, 0.6762, 1.6506,\n",
      "         3.5461]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.350630760192871\n",
      "Epoch: 1 \tStep: 512 \tTime Elapse: 6467.213991165161 \tLoss: 1.788 \tMean Loss: 2.167 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8036928176879883\n",
      "Parameter containing:\n",
      "tensor([[4.3264, 0.5715, 1.4618, 6.2516, 3.1304, 3.8630, 5.7882, 0.6764, 1.6506,\n",
      "         3.5409]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.347291707992554\n",
      "Epoch: 1 \tStep: 513 \tTime Elapse: 6479.381661653519 \tLoss: 2.266 \tMean Loss: 2.163 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6168274879455566\n",
      "Parameter containing:\n",
      "tensor([[4.3232, 0.5686, 1.4574, 6.2515, 3.1296, 3.8560, 5.7902, 0.6774, 1.6506,\n",
      "         3.5345]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.296666622161865\n",
      "Epoch: 1 \tStep: 514 \tTime Elapse: 6491.3123099803925 \tLoss: 1.97 \tMean Loss: 2.158 \tMean Acc: 0.246\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7896530628204346\n",
      "Parameter containing:\n",
      "tensor([[4.3203, 0.5660, 1.4534, 6.2515, 3.1289, 3.8499, 5.7919, 0.6783, 1.6506,\n",
      "         3.5290]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.318462610244751\n",
      "Epoch: 1 \tStep: 515 \tTime Elapse: 6503.4369995594025 \tLoss: 2.416 \tMean Loss: 2.167 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7803232669830322\n",
      "Parameter containing:\n",
      "tensor([[4.3177, 0.5637, 1.4499, 6.2515, 3.1283, 3.8449, 5.7929, 0.6785, 1.6506,\n",
      "         3.5249]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.317169904708862\n",
      "Epoch: 1 \tStep: 516 \tTime Elapse: 6515.5515768527985 \tLoss: 2.416 \tMean Loss: 2.178 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.802950382232666\n",
      "Parameter containing:\n",
      "tensor([[4.3156, 0.5618, 1.4469, 6.2515, 3.1278, 3.8404, 5.7940, 0.6785, 1.6506,\n",
      "         3.5214]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.32373309135437\n",
      "Epoch: 1 \tStep: 517 \tTime Elapse: 6527.694992303848 \tLoss: 2.207 \tMean Loss: 2.183 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6161823272705078\n",
      "Parameter containing:\n",
      "tensor([[4.3136, 0.5600, 1.4440, 6.2515, 3.1273, 3.8356, 5.7955, 0.6790, 1.6506,\n",
      "         3.5172]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.29946494102478\n",
      "Epoch: 1 \tStep: 518 \tTime Elapse: 6539.628352165222 \tLoss: 1.964 \tMean Loss: 2.172 \tMean Acc: 0.245\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.785369634628296\n",
      "Parameter containing:\n",
      "tensor([[4.3142, 0.5598, 1.4434, 6.2521, 3.1277, 3.8285, 5.7991, 0.6809, 1.6506,\n",
      "         3.5098]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.322411298751831\n",
      "Epoch: 1 \tStep: 519 \tTime Elapse: 6551.752572774887 \tLoss: 1.846 \tMean Loss: 2.167 \tMean Acc: 0.246\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7945375442504883\n",
      "Parameter containing:\n",
      "tensor([[4.3155, 0.5599, 1.4440, 6.2528, 3.1283, 3.8226, 5.8021, 0.6823, 1.6506,\n",
      "         3.5040]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.412588119506836\n",
      "Epoch: 1 \tStep: 520 \tTime Elapse: 6563.976608991623 \tLoss: 2.367 \tMean Loss: 2.17 \tMean Acc: 0.246\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6879663467407227\n",
      "Parameter containing:\n",
      "tensor([[4.3163, 0.5595, 1.4440, 6.2533, 3.1288, 3.8176, 5.8046, 0.6833, 1.6506,\n",
      "         3.4992]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.979187488555908\n",
      "Epoch: 1 \tStep: 521 \tTime Elapse: 6576.660274028778 \tLoss: 2.222 \tMean Loss: 2.167 \tMean Acc: 0.246\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6708524227142334\n",
      "Parameter containing:\n",
      "tensor([[4.3174, 0.5582, 1.4433, 6.2539, 3.1295, 3.8147, 5.8073, 0.6811, 1.6506,\n",
      "         3.4978]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.808439016342163\n",
      "Epoch: 1 \tStep: 522 \tTime Elapse: 6589.156763553619 \tLoss: 1.911 \tMean Loss: 2.153 \tMean Acc: 0.247\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8520636558532715\n",
      "Parameter containing:\n",
      "tensor([[4.3183, 0.5570, 1.4420, 6.2544, 3.1301, 3.8125, 5.8092, 0.6780, 1.6506,\n",
      "         3.4974]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.42924451828003\n",
      "Epoch: 1 \tStep: 523 \tTime Elapse: 6601.454432725906 \tLoss: 2.045 \tMean Loss: 2.151 \tMean Acc: 0.247\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8543846607208252\n",
      "Parameter containing:\n",
      "tensor([[4.3189, 0.5560, 1.4405, 6.2548, 3.1305, 3.8109, 5.8111, 0.6744, 1.6506,\n",
      "         3.4979]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.435521602630615\n",
      "Epoch: 1 \tStep: 524 \tTime Elapse: 6613.761302232742 \tLoss: 2.187 \tMean Loss: 2.151 \tMean Acc: 0.247\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8605461120605469\n",
      "Parameter containing:\n",
      "tensor([[4.3202, 0.5557, 1.4397, 6.2553, 3.1311, 3.8091, 5.8137, 0.6709, 1.6506,\n",
      "         3.4979]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.797740936279297\n",
      "Epoch: 1 \tStep: 525 \tTime Elapse: 6626.436282634735 \tLoss: 2.279 \tMean Loss: 2.162 \tMean Acc: 0.247\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.688481330871582\n",
      "Parameter containing:\n",
      "tensor([[4.3205, 0.5548, 1.4379, 6.2556, 3.1315, 3.8078, 5.8157, 0.6671, 1.6506,\n",
      "         3.4985]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.653189897537231\n",
      "Epoch: 1 \tStep: 526 \tTime Elapse: 6638.795082807541 \tLoss: 2.22 \tMean Loss: 2.157 \tMean Acc: 0.247\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8687899112701416\n",
      "Parameter containing:\n",
      "tensor([[4.3215, 0.5538, 1.4364, 6.2560, 3.1321, 3.8059, 5.8184, 0.6625, 1.6506,\n",
      "         3.4990]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.681119918823242\n",
      "Epoch: 1 \tStep: 527 \tTime Elapse: 6651.361608982086 \tLoss: 1.651 \tMean Loss: 2.139 \tMean Acc: 0.249\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8610279560089111\n",
      "Parameter containing:\n",
      "tensor([[4.3210, 0.5516, 1.4333, 6.2562, 3.1324, 3.8046, 5.8206, 0.6577, 1.6506,\n",
      "         3.5002]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.660053253173828\n",
      "Epoch: 1 \tStep: 528 \tTime Elapse: 6663.899485111237 \tLoss: 2.059 \tMean Loss: 2.134 \tMean Acc: 0.249\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8477451801300049\n",
      "Parameter containing:\n",
      "tensor([[4.3209, 0.5494, 1.4313, 6.2563, 3.1328, 3.8026, 5.8228, 0.6537, 1.6506,\n",
      "         3.5005]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.441868782043457\n",
      "Epoch: 1 \tStep: 529 \tTime Elapse: 6676.205402374268 \tLoss: 2.272 \tMean Loss: 2.134 \tMean Acc: 0.249\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.665937900543213\n",
      "Parameter containing:\n",
      "tensor([[4.3209, 0.5475, 1.4296, 6.2565, 3.1332, 3.8021, 5.8235, 0.6493, 1.6506,\n",
      "         3.5026]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.413662672042847\n",
      "Epoch: 1 \tStep: 530 \tTime Elapse: 6688.302317380905 \tLoss: 2.401 \tMean Loss: 2.137 \tMean Acc: 0.249\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8595316410064697\n",
      "Parameter containing:\n",
      "tensor([[4.3185, 0.5441, 1.4253, 6.2563, 3.1331, 3.8028, 5.8231, 0.6442, 1.6506,\n",
      "         3.5062]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.846954107284546\n",
      "Epoch: 1 \tStep: 531 \tTime Elapse: 6701.025335550308 \tLoss: 2.006 \tMean Loss: 2.128 \tMean Acc: 0.249\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8429019451141357\n",
      "Parameter containing:\n",
      "tensor([[4.3164, 0.5408, 1.4212, 6.2562, 3.1328, 3.8021, 5.8243, 0.6392, 1.6506,\n",
      "         3.5082]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.858839988708496\n",
      "Epoch: 1 \tStep: 532 \tTime Elapse: 6713.743837594986 \tLoss: 2.13 \tMean Loss: 2.127 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.686291217803955\n",
      "Parameter containing:\n",
      "tensor([[4.3158, 0.5384, 1.4182, 6.2562, 3.1329, 3.7999, 5.8266, 0.6346, 1.6506,\n",
      "         3.5082]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.000524044036865\n",
      "Epoch: 1 \tStep: 533 \tTime Elapse: 6726.447035551071 \tLoss: 1.821 \tMean Loss: 2.123 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6779749393463135\n",
      "Parameter containing:\n",
      "tensor([[4.3149, 0.5358, 1.4154, 6.2562, 3.1330, 3.7976, 5.8291, 0.6310, 1.6506,\n",
      "         3.5079]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.688920736312866\n",
      "Epoch: 1 \tStep: 534 \tTime Elapse: 6738.831263065338 \tLoss: 2.202 \tMean Loss: 2.129 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8485689163208008\n",
      "Parameter containing:\n",
      "tensor([[4.3132, 0.5328, 1.4120, 6.2561, 3.1329, 3.7963, 5.8306, 0.6268, 1.6506,\n",
      "         3.5089]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414957761764526\n",
      "Epoch: 1 \tStep: 535 \tTime Elapse: 6751.112610340118 \tLoss: 2.195 \tMean Loss: 2.134 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8637146949768066\n",
      "Parameter containing:\n",
      "tensor([[4.3121, 0.5304, 1.4093, 6.2560, 3.1329, 3.7959, 5.8310, 0.6226, 1.6506,\n",
      "         3.5111]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.386320352554321\n",
      "Epoch: 1 \tStep: 536 \tTime Elapse: 6763.379590034485 \tLoss: 2.41 \tMean Loss: 2.146 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8821723461151123\n",
      "Parameter containing:\n",
      "tensor([[4.3115, 0.5283, 1.4070, 6.2560, 3.1331, 3.7949, 5.8321, 0.6194, 1.6506,\n",
      "         3.5119]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39555048942566\n",
      "Epoch: 1 \tStep: 537 \tTime Elapse: 6775.673912525177 \tLoss: 2.217 \tMean Loss: 2.139 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.702308177947998\n",
      "Parameter containing:\n",
      "tensor([[4.3094, 0.5254, 1.4036, 6.2558, 3.1329, 3.7932, 5.8328, 0.6170, 1.6506,\n",
      "         3.5120]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.452706336975098\n",
      "Epoch: 1 \tStep: 538 \tTime Elapse: 6787.845699310303 \tLoss: 2.003 \tMean Loss: 2.131 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8545196056365967\n",
      "Parameter containing:\n",
      "tensor([[4.3067, 0.5223, 1.3996, 6.2554, 3.1325, 3.7918, 5.8331, 0.6147, 1.6506,\n",
      "         3.5124]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.47597622871399\n",
      "Epoch: 1 \tStep: 539 \tTime Elapse: 6800.192769765854 \tLoss: 2.204 \tMean Loss: 2.132 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8544163703918457\n",
      "Parameter containing:\n",
      "tensor([[4.3037, 0.5189, 1.3953, 6.2551, 3.1322, 3.7908, 5.8323, 0.6127, 1.6506,\n",
      "         3.5131]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.846968650817871\n",
      "Epoch: 1 \tStep: 540 \tTime Elapse: 6812.910994529724 \tLoss: 2.099 \tMean Loss: 2.132 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8608026504516602\n",
      "Parameter containing:\n",
      "tensor([[4.3005, 0.5154, 1.3907, 6.2546, 3.1318, 3.7903, 5.8313, 0.6106, 1.6506,\n",
      "         3.5143]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.86591124534607\n",
      "Epoch: 1 \tStep: 541 \tTime Elapse: 6825.654313325882 \tLoss: 2.207 \tMean Loss: 2.133 \tMean Acc: 0.25\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6769332885742188\n",
      "Parameter containing:\n",
      "tensor([[4.2972, 0.5120, 1.3861, 6.2542, 3.1314, 3.7892, 5.8303, 0.6088, 1.6506,\n",
      "         3.5149]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.80684232711792\n",
      "Epoch: 1 \tStep: 542 \tTime Elapse: 6838.154728889465 \tLoss: 2.051 \tMean Loss: 2.141 \tMean Acc: 0.251\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8544509410858154\n",
      "Parameter containing:\n",
      "tensor([[4.2947, 0.5089, 1.3819, 6.2538, 3.1313, 3.7893, 5.8283, 0.6058, 1.6506,\n",
      "         3.5173]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.829992055892944\n",
      "Epoch: 1 \tStep: 543 \tTime Elapse: 6850.855855464935 \tLoss: 2.213 \tMean Loss: 2.14 \tMean Acc: 0.251\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8567984104156494\n",
      "Parameter containing:\n",
      "tensor([[4.2936, 0.5067, 1.3793, 6.2537, 3.1316, 3.7892, 5.8267, 0.6028, 1.6506,\n",
      "         3.5194]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.822668075561523\n",
      "Epoch: 1 \tStep: 544 \tTime Elapse: 6863.552280664444 \tLoss: 2.255 \tMean Loss: 2.149 \tMean Acc: 0.251\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.685072898864746\n",
      "Parameter containing:\n",
      "tensor([[4.2957, 0.5064, 1.3794, 6.2542, 3.1330, 3.7874, 5.8264, 0.6001, 1.6506,\n",
      "         3.5194]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.013330698013306\n",
      "Epoch: 1 \tStep: 545 \tTime Elapse: 6876.26726269722 \tLoss: 1.861 \tMean Loss: 2.131 \tMean Acc: 0.252\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.686284065246582\n",
      "Parameter containing:\n",
      "tensor([[4.2979, 0.5060, 1.3798, 6.2547, 3.1346, 3.7836, 5.8266, 0.5984, 1.6506,\n",
      "         3.5174]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.833296060562134\n",
      "Epoch: 1 \tStep: 546 \tTime Elapse: 6888.804579257965 \tLoss: 1.827 \tMean Loss: 2.111 \tMean Acc: 0.253\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8623182773590088\n",
      "Parameter containing:\n",
      "tensor([[4.2995, 0.5053, 1.3800, 6.2550, 3.1358, 3.7803, 5.8269, 0.5976, 1.6506,\n",
      "         3.5150]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.68576717376709\n",
      "Epoch: 1 \tStep: 547 \tTime Elapse: 6901.369123220444 \tLoss: 2.279 \tMean Loss: 2.113 \tMean Acc: 0.252\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8692808151245117\n",
      "Parameter containing:\n",
      "tensor([[4.3009, 0.5045, 1.3800, 6.2554, 3.1368, 3.7774, 5.8281, 0.5959, 1.6506,\n",
      "         3.5136]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.421250820159912\n",
      "Epoch: 1 \tStep: 548 \tTime Elapse: 6913.6766402721405 \tLoss: 1.807 \tMean Loss: 2.108 \tMean Acc: 0.253\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9035348892211914\n",
      "Parameter containing:\n",
      "tensor([[4.3020, 0.5038, 1.3800, 6.2556, 3.1378, 3.7750, 5.8290, 0.5943, 1.6506,\n",
      "         3.5126]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.399425268173218\n",
      "Epoch: 1 \tStep: 549 \tTime Elapse: 6925.996309995651 \tLoss: 2.427 \tMean Loss: 2.128 \tMean Acc: 0.253\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.692962884902954\n",
      "Parameter containing:\n",
      "tensor([[4.3035, 0.5030, 1.3799, 6.2559, 3.1388, 3.7738, 5.8288, 0.5909, 1.6506,\n",
      "         3.5140]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.393245220184326\n",
      "Epoch: 1 \tStep: 550 \tTime Elapse: 6938.099898338318 \tLoss: 1.944 \tMean Loss: 2.114 \tMean Acc: 0.253\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8722660541534424\n",
      "Parameter containing:\n",
      "tensor([[4.3035, 0.5011, 1.3782, 6.2561, 3.1393, 3.7713, 5.8301, 0.5874, 1.6506,\n",
      "         3.5146]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.834122896194458\n",
      "Epoch: 1 \tStep: 551 \tTime Elapse: 6950.823645591736 \tLoss: 1.615 \tMean Loss: 2.093 \tMean Acc: 0.255\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8631370067596436\n",
      "Parameter containing:\n",
      "tensor([[4.3036, 0.4989, 1.3765, 6.2563, 3.1399, 3.7671, 5.8336, 0.5848, 1.6506,\n",
      "         3.5125]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.423773050308228\n",
      "Epoch: 1 \tStep: 552 \tTime Elapse: 6963.127712011337 \tLoss: 1.685 \tMean Loss: 2.086 \tMean Acc: 0.256\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8684568405151367\n",
      "Parameter containing:\n",
      "tensor([[4.3036, 0.4971, 1.3751, 6.2564, 3.1403, 3.7629, 5.8368, 0.5830, 1.6506,\n",
      "         3.5101]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.669180870056152\n",
      "Epoch: 1 \tStep: 553 \tTime Elapse: 6975.681887149811 \tLoss: 2.377 \tMean Loss: 2.097 \tMean Acc: 0.255\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6650774478912354\n",
      "Parameter containing:\n",
      "tensor([[4.3037, 0.4956, 1.3740, 6.2566, 3.1408, 3.7593, 5.8396, 0.5812, 1.6506,\n",
      "         3.5081]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.665719270706177\n",
      "Epoch: 1 \tStep: 554 \tTime Elapse: 6988.029990434647 \tLoss: 2.422 \tMean Loss: 2.105 \tMean Acc: 0.255\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8553450107574463\n",
      "Parameter containing:\n",
      "tensor([[4.3046, 0.4944, 1.3736, 6.2567, 3.1414, 3.7576, 5.8410, 0.5780, 1.6506,\n",
      "         3.5089]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.632070779800415\n",
      "Epoch: 1 \tStep: 555 \tTime Elapse: 7000.534470081329 \tLoss: 2.143 \tMean Loss: 2.1 \tMean Acc: 0.255\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8509604930877686\n",
      "Parameter containing:\n",
      "tensor([[4.3084, 0.4951, 1.3763, 6.2569, 3.1428, 3.7531, 5.8439, 0.5765, 1.6506,\n",
      "         3.5056]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.650375843048096\n",
      "Epoch: 1 \tStep: 556 \tTime Elapse: 7013.052839040756 \tLoss: 2.024 \tMean Loss: 2.094 \tMean Acc: 0.255\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7030880451202393\n",
      "Parameter containing:\n",
      "tensor([[4.3099, 0.4945, 1.3763, 6.2570, 3.1435, 3.7493, 5.8459, 0.5746, 1.6506,\n",
      "         3.5034]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.808108568191528\n",
      "Epoch: 1 \tStep: 557 \tTime Elapse: 7025.580568552017 \tLoss: 1.765 \tMean Loss: 2.097 \tMean Acc: 0.256\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7049543857574463\n",
      "Parameter containing:\n",
      "tensor([[4.3127, 0.4945, 1.3771, 6.2571, 3.1446, 3.7467, 5.8481, 0.5709, 1.6506,\n",
      "         3.5034]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.643778800964355\n",
      "Epoch: 1 \tStep: 558 \tTime Elapse: 7037.946345090866 \tLoss: 2.082 \tMean Loss: 2.098 \tMean Acc: 0.257\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8673434257507324\n",
      "Parameter containing:\n",
      "tensor([[4.3161, 0.4945, 1.3784, 6.2572, 3.1457, 3.7433, 5.8497, 0.5666, 1.6506,\n",
      "         3.5039]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.658541679382324\n",
      "Epoch: 1 \tStep: 559 \tTime Elapse: 7050.488683223724 \tLoss: 1.813 \tMean Loss: 2.083 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8745841979980469\n",
      "Parameter containing:\n",
      "tensor([[4.3177, 0.4936, 1.3780, 6.2573, 3.1463, 3.7409, 5.8509, 0.5628, 1.6506,\n",
      "         3.5049]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638890266418457\n",
      "Epoch: 1 \tStep: 560 \tTime Elapse: 7063.019282579422 \tLoss: 2.238 \tMean Loss: 2.077 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8796563148498535\n",
      "Parameter containing:\n",
      "tensor([[4.3181, 0.4921, 1.3762, 6.2575, 3.1465, 3.7382, 5.8521, 0.5596, 1.6506,\n",
      "         3.5052]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.433467626571655\n",
      "Epoch: 1 \tStep: 561 \tTime Elapse: 7075.349208116531 \tLoss: 2.028 \tMean Loss: 2.078 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.690972089767456\n",
      "Parameter containing:\n",
      "tensor([[4.3182, 0.4907, 1.3744, 6.2577, 3.1466, 3.7375, 5.8519, 0.5553, 1.6506,\n",
      "         3.5083]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.43894076347351\n",
      "Epoch: 1 \tStep: 562 \tTime Elapse: 7087.496527194977 \tLoss: 2.349 \tMean Loss: 2.085 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8656377792358398\n",
      "Parameter containing:\n",
      "tensor([[4.3199, 0.4899, 1.3741, 6.2578, 3.1471, 3.7373, 5.8527, 0.5507, 1.6506,\n",
      "         3.5114]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.843012809753418\n",
      "Epoch: 1 \tStep: 563 \tTime Elapse: 7100.221786975861 \tLoss: 2.254 \tMean Loss: 2.1 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8556170463562012\n",
      "Parameter containing:\n",
      "tensor([[4.3205, 0.4888, 1.3724, 6.2579, 3.1472, 3.7358, 5.8545, 0.5465, 1.6506,\n",
      "         3.5130]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.832380056381226\n",
      "Epoch: 1 \tStep: 564 \tTime Elapse: 7112.9269008636475 \tLoss: 1.893 \tMean Loss: 2.09 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9917314052581787\n",
      "Parameter containing:\n",
      "tensor([[4.3206, 0.4875, 1.3704, 6.2581, 3.1472, 3.7342, 5.8562, 0.5429, 1.6506,\n",
      "         3.5140]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.821993589401245\n",
      "Epoch: 1 \tStep: 565 \tTime Elapse: 7125.7590227127075 \tLoss: 2.198 \tMean Loss: 2.09 \tMean Acc: 0.258\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6866416931152344\n",
      "Parameter containing:\n",
      "tensor([[4.3199, 0.4856, 1.3668, 6.2583, 3.1469, 3.7336, 5.8579, 0.5382, 1.6506,\n",
      "         3.5165]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.674067735671997\n",
      "Epoch: 1 \tStep: 566 \tTime Elapse: 7138.1368062496185 \tLoss: 1.844 \tMean Loss: 2.071 \tMean Acc: 0.259\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8517508506774902\n",
      "Parameter containing:\n",
      "tensor([[4.3180, 0.4825, 1.3619, 6.2587, 3.1463, 3.7357, 5.8572, 0.5320, 1.6506,\n",
      "         3.5228]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.683994054794312\n",
      "Epoch: 1 \tStep: 567 \tTime Elapse: 7150.689077615738 \tLoss: 2.065 \tMean Loss: 2.066 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8541226387023926\n",
      "Parameter containing:\n",
      "tensor([[4.3163, 0.4797, 1.3573, 6.2590, 3.1456, 3.7374, 5.8567, 0.5262, 1.6506,\n",
      "         3.5283]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.848062515258789\n",
      "Epoch: 1 \tStep: 568 \tTime Elapse: 7163.408054113388 \tLoss: 2.205 \tMean Loss: 2.073 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.681302785873413\n",
      "Parameter containing:\n",
      "tensor([[4.3153, 0.4773, 1.3534, 6.2592, 3.1452, 3.7383, 5.8571, 0.5207, 1.6506,\n",
      "         3.5330]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.850705862045288\n",
      "Epoch: 1 \tStep: 569 \tTime Elapse: 7175.956745386124 \tLoss: 1.97 \tMean Loss: 2.065 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6789565086364746\n",
      "Parameter containing:\n",
      "tensor([[4.3137, 0.4747, 1.3490, 6.2595, 3.1446, 3.7394, 5.8564, 0.5161, 1.6506,\n",
      "         3.5371]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.66344690322876\n",
      "Epoch: 1 \tStep: 570 \tTime Elapse: 7188.3161334991455 \tLoss: 2.302 \tMean Loss: 2.071 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8479695320129395\n",
      "Parameter containing:\n",
      "tensor([[4.3123, 0.4723, 1.3447, 6.2597, 3.1441, 3.7403, 5.8566, 0.5112, 1.6506,\n",
      "         3.5410]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.698937177658081\n",
      "Epoch: 1 \tStep: 571 \tTime Elapse: 7200.879788637161 \tLoss: 2.0 \tMean Loss: 2.065 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8629028797149658\n",
      "Parameter containing:\n",
      "tensor([[4.3116, 0.4704, 1.3418, 6.2599, 3.1437, 3.7411, 5.8562, 0.5068, 1.6506,\n",
      "         3.5449]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.666724443435669\n",
      "Epoch: 1 \tStep: 572 \tTime Elapse: 7213.426444768906 \tLoss: 2.313 \tMean Loss: 2.073 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8907322883605957\n",
      "Parameter containing:\n",
      "tensor([[4.3095, 0.4677, 1.3375, 6.2601, 3.1430, 3.7417, 5.8559, 0.5031, 1.6506,\n",
      "         3.5482]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.649178743362427\n",
      "Epoch: 1 \tStep: 573 \tTime Elapse: 7225.9830729961395 \tLoss: 1.932 \tMean Loss: 2.064 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6862983703613281\n",
      "Parameter containing:\n",
      "tensor([[4.3073, 0.4651, 1.3332, 6.2603, 3.1423, 3.7420, 5.8548, 0.5001, 1.6506,\n",
      "         3.5507]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.408662557601929\n",
      "Epoch: 1 \tStep: 574 \tTime Elapse: 7238.095056772232 \tLoss: 2.335 \tMean Loss: 2.067 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8499751091003418\n",
      "Parameter containing:\n",
      "tensor([[4.3051, 0.4627, 1.3291, 6.2605, 3.1416, 3.7424, 5.8536, 0.4966, 1.6506,\n",
      "         3.5539]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414366245269775\n",
      "Epoch: 1 \tStep: 575 \tTime Elapse: 7250.376015901566 \tLoss: 2.232 \tMean Loss: 2.079 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.861076831817627\n",
      "Parameter containing:\n",
      "tensor([[4.3013, 0.4591, 1.3233, 6.2606, 3.1404, 3.7452, 5.8507, 0.4920, 1.6506,\n",
      "         3.5601]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.844167947769165\n",
      "Epoch: 1 \tStep: 576 \tTime Elapse: 7263.098521232605 \tLoss: 2.297 \tMean Loss: 2.095 \tMean Acc: 0.26\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8986151218414307\n",
      "Parameter containing:\n",
      "tensor([[4.2944, 0.4538, 1.3142, 6.2607, 3.1386, 3.7494, 5.8468, 0.4863, 1.6506,\n",
      "         3.5685]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.844882011413574\n",
      "Epoch: 1 \tStep: 577 \tTime Elapse: 7275.858986616135 \tLoss: 1.881 \tMean Loss: 2.081 \tMean Acc: 0.261\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.661982536315918\n",
      "Parameter containing:\n",
      "tensor([[4.2882, 0.4490, 1.3059, 6.2608, 3.1369, 3.7532, 5.8433, 0.4811, 1.6506,\n",
      "         3.5761]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.811342000961304\n",
      "Epoch: 1 \tStep: 578 \tTime Elapse: 7288.3495128154755 \tLoss: 2.184 \tMean Loss: 2.094 \tMean Acc: 0.261\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8405952453613281\n",
      "Parameter containing:\n",
      "tensor([[4.2832, 0.4452, 1.2990, 6.2609, 3.1355, 3.7556, 5.8410, 0.4763, 1.6506,\n",
      "         3.5821]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.855039119720459\n",
      "Epoch: 1 \tStep: 579 \tTime Elapse: 7301.062291145325 \tLoss: 2.023 \tMean Loss: 2.081 \tMean Acc: 0.261\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8564822673797607\n",
      "Parameter containing:\n",
      "tensor([[4.2773, 0.4411, 1.2912, 6.2608, 3.1341, 3.7566, 5.8393, 0.4722, 1.6506,\n",
      "         3.5858]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.82518196105957\n",
      "Epoch: 1 \tStep: 580 \tTime Elapse: 7313.76235127449 \tLoss: 1.819 \tMean Loss: 2.076 \tMean Acc: 0.262\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6841099262237549\n",
      "Parameter containing:\n",
      "tensor([[4.2734, 0.4376, 1.2853, 6.2610, 3.1332, 3.7560, 5.8393, 0.4685, 1.6506,\n",
      "         3.5877]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.575763940811157\n",
      "Epoch: 1 \tStep: 581 \tTime Elapse: 7326.038815736771 \tLoss: 1.834 \tMean Loss: 2.084 \tMean Acc: 0.263\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6846096515655518\n",
      "Parameter containing:\n",
      "tensor([[4.2696, 0.4344, 1.2798, 6.2611, 3.1324, 3.7554, 5.8392, 0.4651, 1.6506,\n",
      "         3.5895]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.403266429901123\n",
      "Epoch: 1 \tStep: 582 \tTime Elapse: 7338.143599748611 \tLoss: 2.18 \tMean Loss: 2.1 \tMean Acc: 0.263\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.840437650680542\n",
      "Parameter containing:\n",
      "tensor([[4.2657, 0.4313, 1.2745, 6.2611, 3.1316, 3.7552, 5.8387, 0.4611, 1.6506,\n",
      "         3.5923]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.422073125839233\n",
      "Epoch: 1 \tStep: 583 \tTime Elapse: 7350.4228048324585 \tLoss: 2.289 \tMean Loss: 2.097 \tMean Acc: 0.263\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8388962745666504\n",
      "Parameter containing:\n",
      "tensor([[4.2645, 0.4298, 1.2719, 6.2615, 3.1314, 3.7539, 5.8387, 0.4577, 1.6506,\n",
      "         3.5934]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.426658153533936\n",
      "Epoch: 1 \tStep: 584 \tTime Elapse: 7362.705139398575 \tLoss: 2.047 \tMean Loss: 2.085 \tMean Acc: 0.263\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9033315181732178\n",
      "Parameter containing:\n",
      "tensor([[4.2648, 0.4295, 1.2709, 6.2621, 3.1318, 3.7496, 5.8403, 0.4559, 1.6506,\n",
      "         3.5904]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.413472652435303\n",
      "Epoch: 1 \tStep: 585 \tTime Elapse: 7375.038678407669 \tLoss: 1.779 \tMean Loss: 2.073 \tMean Acc: 0.264\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6939115524291992\n",
      "Parameter containing:\n",
      "tensor([[4.2654, 0.4290, 1.2705, 6.2628, 3.1322, 3.7451, 5.8419, 0.4542, 1.6506,\n",
      "         3.5872]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.390644788742065\n",
      "Epoch: 1 \tStep: 586 \tTime Elapse: 7387.140254497528 \tLoss: 2.22 \tMean Loss: 2.079 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8400306701660156\n",
      "Parameter containing:\n",
      "tensor([[4.2670, 0.4292, 1.2712, 6.2635, 3.1328, 3.7401, 5.8440, 0.4528, 1.6506,\n",
      "         3.5833]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.394294261932373\n",
      "Epoch: 1 \tStep: 587 \tTime Elapse: 7399.390967845917 \tLoss: 2.212 \tMean Loss: 2.094 \tMean Acc: 0.264\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8619465827941895\n",
      "Parameter containing:\n",
      "tensor([[4.2701, 0.4298, 1.2733, 6.2645, 3.1339, 3.7361, 5.8447, 0.4514, 1.6506,\n",
      "         3.5806]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.420672178268433\n",
      "Epoch: 1 \tStep: 588 \tTime Elapse: 7411.690525531769 \tLoss: 2.302 \tMean Loss: 2.101 \tMean Acc: 0.264\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8880119323730469\n",
      "Parameter containing:\n",
      "tensor([[4.2716, 0.4296, 1.2739, 6.2652, 3.1346, 3.7336, 5.8449, 0.4495, 1.6506,\n",
      "         3.5796]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.392602443695068\n",
      "Epoch: 1 \tStep: 589 \tTime Elapse: 7423.988175153732 \tLoss: 2.088 \tMean Loss: 2.11 \tMean Acc: 0.264\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6861255168914795\n",
      "Parameter containing:\n",
      "tensor([[4.2722, 0.4290, 1.2736, 6.2657, 3.1351, 3.7318, 5.8444, 0.4474, 1.6506,\n",
      "         3.5794]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.45538067817688\n",
      "Epoch: 1 \tStep: 590 \tTime Elapse: 7436.146720647812 \tLoss: 1.99 \tMean Loss: 2.102 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8552851676940918\n",
      "Parameter containing:\n",
      "tensor([[4.2720, 0.4280, 1.2726, 6.2661, 3.1355, 3.7278, 5.8457, 0.4468, 1.6506,\n",
      "         3.5758]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.656445980072021\n",
      "Epoch: 1 \tStep: 591 \tTime Elapse: 7448.675076007843 \tLoss: 1.81 \tMean Loss: 2.095 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8764986991882324\n",
      "Parameter containing:\n",
      "tensor([[4.2726, 0.4272, 1.2725, 6.2665, 3.1361, 3.7245, 5.8463, 0.4454, 1.6506,\n",
      "         3.5737]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.657960653305054\n",
      "Epoch: 1 \tStep: 592 \tTime Elapse: 7461.226610183716 \tLoss: 2.167 \tMean Loss: 2.089 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6914796829223633\n",
      "Parameter containing:\n",
      "tensor([[4.2736, 0.4267, 1.2730, 6.2669, 3.1367, 3.7228, 5.8456, 0.4433, 1.6506,\n",
      "         3.5739]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.79445219039917\n",
      "Epoch: 1 \tStep: 593 \tTime Elapse: 7473.729375123978 \tLoss: 2.36 \tMean Loss: 2.092 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8216962814331055\n",
      "Parameter containing:\n",
      "tensor([[4.2736, 0.4254, 1.2722, 6.2672, 3.1372, 3.7214, 5.8444, 0.4412, 1.6506,\n",
      "         3.5746]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.643152952194214\n",
      "Epoch: 1 \tStep: 594 \tTime Elapse: 7486.211681604385 \tLoss: 2.034 \tMean Loss: 2.097 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8573694229125977\n",
      "Parameter containing:\n",
      "tensor([[4.2758, 0.4252, 1.2738, 6.2677, 3.1380, 3.7196, 5.8442, 0.4395, 1.6506,\n",
      "         3.5747]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.653880596160889\n",
      "Epoch: 1 \tStep: 595 \tTime Elapse: 7498.739587068558 \tLoss: 2.253 \tMean Loss: 2.099 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8592255115509033\n",
      "Parameter containing:\n",
      "tensor([[4.2779, 0.4250, 1.2755, 6.2681, 3.1388, 3.7180, 5.8439, 0.4380, 1.6506,\n",
      "         3.5747]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.642333269119263\n",
      "Epoch: 1 \tStep: 596 \tTime Elapse: 7511.258090734482 \tLoss: 2.416 \tMean Loss: 2.118 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8697516918182373\n",
      "Parameter containing:\n",
      "tensor([[4.2806, 0.4253, 1.2777, 6.2685, 3.1396, 3.7171, 5.8431, 0.4364, 1.6506,\n",
      "         3.5755]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.486937046051025\n",
      "Epoch: 1 \tStep: 597 \tTime Elapse: 7523.631910324097 \tLoss: 2.407 \tMean Loss: 2.129 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6914796829223633\n",
      "Parameter containing:\n",
      "tensor([[4.2829, 0.4255, 1.2796, 6.2689, 3.1404, 3.7153, 5.8428, 0.4351, 1.6506,\n",
      "         3.5752]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.439362287521362\n",
      "Epoch: 1 \tStep: 598 \tTime Elapse: 7535.780216932297 \tLoss: 1.972 \tMean Loss: 2.122 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8661653995513916\n",
      "Parameter containing:\n",
      "tensor([[4.2850, 0.4257, 1.2814, 6.2692, 3.1411, 3.7117, 5.8434, 0.4346, 1.6506,\n",
      "         3.5725]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.858663320541382\n",
      "Epoch: 1 \tStep: 599 \tTime Elapse: 7548.521921157837 \tLoss: 2.017 \tMean Loss: 2.123 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.866816759109497\n",
      "Parameter containing:\n",
      "tensor([[4.2884, 0.4263, 1.2841, 6.2696, 3.1420, 3.7096, 5.8435, 0.4329, 1.6506,\n",
      "         3.5719]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83108639717102\n",
      "Epoch: 1 \tStep: 600 \tTime Elapse: 7561.237104415894 \tLoss: 2.13 \tMean Loss: 2.117 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8730194568634033\n",
      "Parameter containing:\n",
      "tensor([[4.2917, 0.4271, 1.2870, 6.2699, 3.1428, 3.7078, 5.8438, 0.4313, 1.6506,\n",
      "         3.5714]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.429494857788086\n",
      "Epoch: 1 \tStep: 601 \tTime Elapse: 7573.557061910629 \tLoss: 2.385 \tMean Loss: 2.13 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6918697357177734\n",
      "Parameter containing:\n",
      "tensor([[4.2915, 0.4265, 1.2861, 6.2702, 3.1431, 3.7047, 5.8447, 0.4310, 1.6506,\n",
      "         3.5686]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.63590931892395\n",
      "Epoch: 1 \tStep: 602 \tTime Elapse: 7585.902066707611 \tLoss: 2.152 \tMean Loss: 2.125 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8620388507843018\n",
      "Parameter containing:\n",
      "tensor([[4.2897, 0.4246, 1.2837, 6.2705, 3.1430, 3.7020, 5.8454, 0.4308, 1.6506,\n",
      "         3.5667]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.701704025268555\n",
      "Epoch: 1 \tStep: 603 \tTime Elapse: 7598.482541561127 \tLoss: 2.051 \tMean Loss: 2.129 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8570754528045654\n",
      "Parameter containing:\n",
      "tensor([[4.2875, 0.4225, 1.2810, 6.2709, 3.1429, 3.6992, 5.8460, 0.4309, 1.6506,\n",
      "         3.5645]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.638983249664307\n",
      "Epoch: 1 \tStep: 604 \tTime Elapse: 7610.995309591293 \tLoss: 2.25 \tMean Loss: 2.126 \tMean Acc: 0.265\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.682110071182251\n",
      "Parameter containing:\n",
      "tensor([[4.2872, 0.4212, 1.2801, 6.2711, 3.1430, 3.6938, 5.8484, 0.4324, 1.6506,\n",
      "         3.5590]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.820258378982544\n",
      "Epoch: 1 \tStep: 605 \tTime Elapse: 7623.514122724533 \tLoss: 1.918 \tMean Loss: 2.116 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6879372596740723\n",
      "Parameter containing:\n",
      "tensor([[4.2870, 0.4201, 1.2794, 6.2713, 3.1431, 3.6887, 5.8506, 0.4338, 1.6506,\n",
      "         3.5538]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.678207159042358\n",
      "Epoch: 1 \tStep: 606 \tTime Elapse: 7635.8974096775055 \tLoss: 2.181 \tMean Loss: 2.112 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8342869281768799\n",
      "Parameter containing:\n",
      "tensor([[4.2869, 0.4191, 1.2788, 6.2715, 3.1431, 3.6836, 5.8531, 0.4352, 1.6506,\n",
      "         3.5486]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.655991077423096\n",
      "Epoch: 1 \tStep: 607 \tTime Elapse: 7648.404974937439 \tLoss: 1.956 \tMean Loss: 2.114 \tMean Acc: 0.266\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8618106842041016\n",
      "Parameter containing:\n",
      "tensor([[4.2872, 0.4180, 1.2785, 6.2717, 3.1433, 3.6787, 5.8560, 0.4359, 1.6506,\n",
      "         3.5440]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.837287425994873\n",
      "Epoch: 1 \tStep: 608 \tTime Elapse: 7661.121091365814 \tLoss: 2.037 \tMean Loss: 2.109 \tMean Acc: 0.267\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.87453293800354\n",
      "Parameter containing:\n",
      "tensor([[4.2889, 0.4176, 1.2797, 6.2718, 3.1436, 3.6751, 5.8577, 0.4362, 1.6506,\n",
      "         3.5408]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.846097707748413\n",
      "Epoch: 1 \tStep: 609 \tTime Elapse: 7673.858421087265 \tLoss: 2.135 \tMean Loss: 2.113 \tMean Acc: 0.267\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6774251461029053\n",
      "Parameter containing:\n",
      "tensor([[4.2919, 0.4177, 1.2826, 6.2719, 3.1440, 3.6710, 5.8594, 0.4366, 1.6506,\n",
      "         3.5372]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83840012550354\n",
      "Epoch: 1 \tStep: 610 \tTime Elapse: 7686.3927500247955 \tLoss: 2.011 \tMean Loss: 2.119 \tMean Acc: 0.267\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8640074729919434\n",
      "Parameter containing:\n",
      "tensor([[4.2961, 0.4186, 1.2871, 6.2718, 3.1446, 3.6642, 5.8622, 0.4392, 1.6506,\n",
      "         3.5297]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.84990930557251\n",
      "Epoch: 1 \tStep: 611 \tTime Elapse: 7699.123504161835 \tLoss: 2.238 \tMean Loss: 2.133 \tMean Acc: 0.267\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.83842134475708\n",
      "Parameter containing:\n",
      "tensor([[4.2997, 0.4193, 1.2909, 6.2718, 3.1451, 3.6582, 5.8646, 0.4413, 1.6506,\n",
      "         3.5233]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.796987056732178\n",
      "Epoch: 1 \tStep: 612 \tTime Elapse: 7711.776187181473 \tLoss: 2.213 \tMean Loss: 2.134 \tMean Acc: 0.267\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8651208877563477\n",
      "Parameter containing:\n",
      "tensor([[4.3051, 0.4209, 1.2964, 6.2716, 3.1457, 3.6497, 5.8679, 0.4440, 1.6506,\n",
      "         3.5142]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.475251197814941\n",
      "Epoch: 1 \tStep: 613 \tTime Elapse: 7724.134366750717 \tLoss: 1.712 \tMean Loss: 2.115 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.671297311782837\n",
      "Parameter containing:\n",
      "tensor([[4.3102, 0.4225, 1.3016, 6.2715, 3.1463, 3.6436, 5.8698, 0.4454, 1.6506,\n",
      "         3.5082]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.406543254852295\n",
      "Epoch: 1 \tStep: 614 \tTime Elapse: 7736.229341745377 \tLoss: 2.15 \tMean Loss: 2.118 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8432321548461914\n",
      "Parameter containing:\n",
      "tensor([[4.3171, 0.4248, 1.3086, 6.2711, 3.1471, 3.6373, 5.8722, 0.4468, 1.6506,\n",
      "         3.5022]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.40753984451294\n",
      "Epoch: 1 \tStep: 615 \tTime Elapse: 7748.496708154678 \tLoss: 2.013 \tMean Loss: 2.126 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8546037673950195\n",
      "Parameter containing:\n",
      "tensor([[4.3239, 0.4268, 1.3153, 6.2707, 3.1478, 3.6335, 5.8727, 0.4465, 1.6506,\n",
      "         3.5000]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.658857107162476\n",
      "Epoch: 1 \tStep: 616 \tTime Elapse: 7761.027181625366 \tLoss: 1.953 \tMean Loss: 2.117 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6882314682006836\n",
      "Parameter containing:\n",
      "tensor([[4.3319, 0.4290, 1.3228, 6.2701, 3.1485, 3.6308, 5.8734, 0.4454, 1.6506,\n",
      "         3.4987]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.557813167572021\n",
      "Epoch: 1 \tStep: 617 \tTime Elapse: 7773.290136814117 \tLoss: 1.744 \tMean Loss: 2.102 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6765193939208984\n",
      "Parameter containing:\n",
      "tensor([[4.3406, 0.4319, 1.3314, 6.2694, 3.1494, 3.6286, 5.8740, 0.4435, 1.6506,\n",
      "         3.4988]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.394487857818604\n",
      "Epoch: 1 \tStep: 618 \tTime Elapse: 7785.378866195679 \tLoss: 2.127 \tMean Loss: 2.096 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8342654705047607\n",
      "Parameter containing:\n",
      "tensor([[4.3487, 0.4349, 1.3394, 6.2687, 3.1503, 3.6269, 5.8747, 0.4415, 1.6506,\n",
      "         3.4991]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.385574340820312\n",
      "Epoch: 1 \tStep: 619 \tTime Elapse: 7797.61514544487 \tLoss: 2.389 \tMean Loss: 2.106 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.859342336654663\n",
      "Parameter containing:\n",
      "tensor([[4.3563, 0.4377, 1.3468, 6.2680, 3.1511, 3.6253, 5.8752, 0.4398, 1.6506,\n",
      "         3.4993]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.427582740783691\n",
      "Epoch: 1 \tStep: 620 \tTime Elapse: 7809.918968439102 \tLoss: 2.422 \tMean Loss: 2.12 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.876434087753296\n",
      "Parameter containing:\n",
      "tensor([[4.3633, 0.4401, 1.3535, 6.2673, 3.1518, 3.6238, 5.8759, 0.4382, 1.6506,\n",
      "         3.4995]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.467291116714478\n",
      "Epoch: 1 \tStep: 621 \tTime Elapse: 7822.279448032379 \tLoss: 2.213 \tMean Loss: 2.134 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.669597864151001\n",
      "Parameter containing:\n",
      "tensor([[4.3679, 0.4413, 1.3581, 6.2671, 3.1521, 3.6218, 5.8768, 0.4370, 1.6506,\n",
      "         3.4992]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.858198881149292\n",
      "Epoch: 1 \tStep: 622 \tTime Elapse: 7834.824964761734 \tLoss: 2.156 \tMean Loss: 2.133 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8433291912078857\n",
      "Parameter containing:\n",
      "tensor([[4.3713, 0.4421, 1.3611, 6.2670, 3.1521, 3.6192, 5.8781, 0.4359, 1.6506,\n",
      "         3.4980]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.485401630401611\n",
      "Epoch: 1 \tStep: 623 \tTime Elapse: 7847.170427799225 \tLoss: 2.078 \tMean Loss: 2.124 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.857569694519043\n",
      "Parameter containing:\n",
      "tensor([[4.3736, 0.4420, 1.3630, 6.2671, 3.1518, 3.6187, 5.8780, 0.4342, 1.6506,\n",
      "         3.4993]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.460712671279907\n",
      "Epoch: 1 \tStep: 624 \tTime Elapse: 7859.505654811859 \tLoss: 2.362 \tMean Loss: 2.135 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8381173610687256\n",
      "Parameter containing:\n",
      "tensor([[4.3748, 0.4413, 1.3635, 6.2674, 3.1513, 3.6194, 5.8768, 0.4320, 1.6506,\n",
      "         3.5021]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.487557411193848\n",
      "Epoch: 1 \tStep: 625 \tTime Elapse: 7871.848233222961 \tLoss: 2.151 \tMean Loss: 2.131 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6811633110046387\n",
      "Parameter containing:\n",
      "tensor([[4.3762, 0.4411, 1.3647, 6.2676, 3.1509, 3.6189, 5.8754, 0.4304, 1.6506,\n",
      "         3.5039]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.42200517654419\n",
      "Epoch: 1 \tStep: 626 \tTime Elapse: 7883.968696594238 \tLoss: 2.212 \tMean Loss: 2.125 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8606362342834473\n",
      "Parameter containing:\n",
      "tensor([[4.3766, 0.4404, 1.3645, 6.2679, 3.1503, 3.6191, 5.8736, 0.4286, 1.6506,\n",
      "         3.5066]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.443151950836182\n",
      "Epoch: 1 \tStep: 627 \tTime Elapse: 7896.289015054703 \tLoss: 2.18 \tMean Loss: 2.117 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.853196382522583\n",
      "Parameter containing:\n",
      "tensor([[4.3798, 0.4410, 1.3674, 6.2677, 3.1501, 3.6180, 5.8728, 0.4274, 1.6506,\n",
      "         3.5070]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.441329956054688\n",
      "Epoch: 1 \tStep: 628 \tTime Elapse: 7908.600713729858 \tLoss: 2.047 \tMean Loss: 2.119 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6681156158447266\n",
      "Parameter containing:\n",
      "tensor([[4.3844, 0.4423, 1.3719, 6.2672, 3.1501, 3.6173, 5.8723, 0.4259, 1.6506,\n",
      "         3.5079]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.599320888519287\n",
      "Epoch: 1 \tStep: 629 \tTime Elapse: 7920.886281251907 \tLoss: 2.177 \tMean Loss: 2.125 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.70271635055542\n",
      "Parameter containing:\n",
      "tensor([[4.3885, 0.4435, 1.3760, 6.2668, 3.1500, 3.6164, 5.8724, 0.4245, 1.6506,\n",
      "         3.5085]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.436853647232056\n",
      "Epoch: 1 \tStep: 630 \tTime Elapse: 7933.042924404144 \tLoss: 2.001 \tMean Loss: 2.12 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8929376602172852\n",
      "Parameter containing:\n",
      "tensor([[4.3931, 0.4449, 1.3802, 6.2662, 3.1501, 3.6152, 5.8729, 0.4232, 1.6506,\n",
      "         3.5086]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.430352210998535\n",
      "Epoch: 1 \tStep: 631 \tTime Elapse: 7945.383186578751 \tLoss: 2.136 \tMean Loss: 2.112 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8688321113586426\n",
      "Parameter containing:\n",
      "tensor([[4.3971, 0.4461, 1.3836, 6.2658, 3.1501, 3.6138, 5.8736, 0.4220, 1.6506,\n",
      "         3.5084]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.84451937675476\n",
      "Epoch: 1 \tStep: 632 \tTime Elapse: 7958.113743066788 \tLoss: 2.205 \tMean Loss: 2.114 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8945350646972656\n",
      "Parameter containing:\n",
      "tensor([[4.3969, 0.4451, 1.3823, 6.2660, 3.1493, 3.6152, 5.8722, 0.4194, 1.6506,\n",
      "         3.5123]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.462717533111572\n",
      "Epoch: 1 \tStep: 633 \tTime Elapse: 7970.488263607025 \tLoss: 2.049 \tMean Loss: 2.114 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6697444915771484\n",
      "Parameter containing:\n",
      "tensor([[4.3961, 0.4441, 1.3803, 6.2663, 3.1483, 3.6153, 5.8711, 0.4178, 1.6506,\n",
      "         3.5144]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.702474594116211\n",
      "Epoch: 1 \tStep: 634 \tTime Elapse: 7982.878106355667 \tLoss: 2.203 \tMean Loss: 2.112 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8731718063354492\n",
      "Parameter containing:\n",
      "tensor([[4.3941, 0.4422, 1.3773, 6.2668, 3.1472, 3.6155, 5.8694, 0.4165, 1.6506,\n",
      "         3.5166]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.655350923538208\n",
      "Epoch: 1 \tStep: 635 \tTime Elapse: 7995.42352938652 \tLoss: 2.328 \tMean Loss: 2.126 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8450367450714111\n",
      "Parameter containing:\n",
      "tensor([[4.3910, 0.4398, 1.3733, 6.2673, 3.1458, 3.6153, 5.8675, 0.4158, 1.6506,\n",
      "         3.5180]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.655418634414673\n",
      "Epoch: 1 \tStep: 636 \tTime Elapse: 8007.941281795502 \tLoss: 2.215 \tMean Loss: 2.127 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.867915391921997\n",
      "Parameter containing:\n",
      "tensor([[4.3871, 0.4369, 1.3685, 6.2679, 3.1443, 3.6162, 5.8645, 0.4150, 1.6506,\n",
      "         3.5204]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.673044443130493\n",
      "Epoch: 1 \tStep: 637 \tTime Elapse: 8020.49901843071 \tLoss: 2.359 \tMean Loss: 2.141 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6878108978271484\n",
      "Parameter containing:\n",
      "tensor([[4.3825, 0.4337, 1.3629, 6.2685, 3.1428, 3.6172, 5.8617, 0.4140, 1.6506,\n",
      "         3.5228]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.652913570404053\n",
      "Epoch: 1 \tStep: 638 \tTime Elapse: 8032.856670379639 \tLoss: 2.158 \tMean Loss: 2.145 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8568778038024902\n",
      "Parameter containing:\n",
      "tensor([[4.3764, 0.4298, 1.3558, 6.2691, 3.1410, 3.6199, 5.8577, 0.4122, 1.6506,\n",
      "         3.5276]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64739179611206\n",
      "Epoch: 1 \tStep: 639 \tTime Elapse: 8045.3775453567505 \tLoss: 2.229 \tMean Loss: 2.148 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8592033386230469\n",
      "Parameter containing:\n",
      "tensor([[4.3706, 0.4260, 1.3492, 6.2697, 3.1394, 3.6233, 5.8531, 0.4098, 1.6506,\n",
      "         3.5334]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.663250207901001\n",
      "Epoch: 1 \tStep: 640 \tTime Elapse: 8057.916777610779 \tLoss: 2.376 \tMean Loss: 2.16 \tMean Acc: 0.268\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6753630638122559\n",
      "Parameter containing:\n",
      "tensor([[4.3636, 0.4209, 1.3409, 6.2701, 3.1376, 3.6288, 5.8472, 0.4061, 1.6506,\n",
      "         3.5418]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.823176622390747\n",
      "Epoch: 1 \tStep: 641 \tTime Elapse: 8070.431966781616 \tLoss: 2.013 \tMean Loss: 2.152 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6751506328582764\n",
      "Parameter containing:\n",
      "tensor([[4.3580, 0.4166, 1.3339, 6.2705, 3.1362, 3.6326, 5.8430, 0.4027, 1.6506,\n",
      "         3.5482]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.654165744781494\n",
      "Epoch: 1 \tStep: 642 \tTime Elapse: 8082.778645992279 \tLoss: 1.771 \tMean Loss: 2.138 \tMean Acc: 0.269\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.871150255203247\n",
      "Parameter containing:\n",
      "tensor([[4.3525, 0.4123, 1.3273, 6.2708, 3.1349, 3.6351, 5.8400, 0.4000, 1.6506,\n",
      "         3.5530]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.623251676559448\n",
      "Epoch: 1 \tStep: 643 \tTime Elapse: 8095.289578676224 \tLoss: 2.017 \tMean Loss: 2.148 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.850600004196167\n",
      "Parameter containing:\n",
      "tensor([[4.3469, 0.4080, 1.3206, 6.2710, 3.1337, 3.6376, 5.8373, 0.3975, 1.6506,\n",
      "         3.5573]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.398228168487549\n",
      "Epoch: 1 \tStep: 644 \tTime Elapse: 8107.55558013916 \tLoss: 2.202 \tMean Loss: 2.15 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8767130374908447\n",
      "Parameter containing:\n",
      "tensor([[4.3407, 0.4032, 1.3133, 6.2710, 3.1326, 3.6412, 5.8326, 0.3948, 1.6506,\n",
      "         3.5633]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.388964414596558\n",
      "Epoch: 1 \tStep: 645 \tTime Elapse: 8119.838025569916 \tLoss: 2.232 \tMean Loss: 2.157 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6759047508239746\n",
      "Parameter containing:\n",
      "tensor([[4.3366, 0.3995, 1.3078, 6.2713, 3.1318, 3.6441, 5.8288, 0.3919, 1.6506,\n",
      "         3.5684]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.453008651733398\n",
      "Epoch: 1 \tStep: 646 \tTime Elapse: 8131.984669685364 \tLoss: 2.092 \tMean Loss: 2.161 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8776557445526123\n",
      "Parameter containing:\n",
      "tensor([[4.3327, 0.3959, 1.3028, 6.2714, 3.1312, 3.6454, 5.8259, 0.3899, 1.6506,\n",
      "         3.5719]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.672949075698853\n",
      "Epoch: 1 \tStep: 647 \tTime Elapse: 8144.552130937576 \tLoss: 2.004 \tMean Loss: 2.17 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.862114429473877\n",
      "Parameter containing:\n",
      "tensor([[4.3288, 0.3925, 1.2982, 6.2716, 3.1307, 3.6457, 5.8235, 0.3884, 1.6506,\n",
      "         3.5741]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.648611783981323\n",
      "Epoch: 1 \tStep: 648 \tTime Elapse: 8157.079767465591 \tLoss: 2.222 \tMean Loss: 2.173 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.877516269683838\n",
      "Parameter containing:\n",
      "tensor([[4.3256, 0.3895, 1.2942, 6.2717, 3.1305, 3.6470, 5.8204, 0.3863, 1.6506,\n",
      "         3.5776]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.673531770706177\n",
      "Epoch: 1 \tStep: 649 \tTime Elapse: 8169.647414445877 \tLoss: 2.139 \tMean Loss: 2.165 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6661932468414307\n",
      "Parameter containing:\n",
      "tensor([[4.3224, 0.3865, 1.2902, 6.2718, 3.1303, 3.6476, 5.8179, 0.3846, 1.6506,\n",
      "         3.5801]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.692556619644165\n",
      "Epoch: 1 \tStep: 650 \tTime Elapse: 8182.02424454689 \tLoss: 1.974 \tMean Loss: 2.15 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.853414535522461\n",
      "Parameter containing:\n",
      "tensor([[4.3215, 0.3846, 1.2889, 6.2723, 3.1306, 3.6484, 5.8150, 0.3822, 1.6506,\n",
      "         3.5833]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.678842306137085\n",
      "Epoch: 1 \tStep: 651 \tTime Elapse: 8194.573153495789 \tLoss: 2.104 \tMean Loss: 2.146 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9692785739898682\n",
      "Parameter containing:\n",
      "tensor([[4.3207, 0.3828, 1.2877, 6.2728, 3.1310, 3.6489, 5.8124, 0.3801, 1.6506,\n",
      "         3.5860]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.674275636672974\n",
      "Epoch: 1 \tStep: 652 \tTime Elapse: 8207.233696460724 \tLoss: 2.207 \tMean Loss: 2.148 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6502974033355713\n",
      "Parameter containing:\n",
      "tensor([[4.3200, 0.3812, 1.2867, 6.2732, 3.1313, 3.6491, 5.8102, 0.3782, 1.6506,\n",
      "         3.5882]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.573106288909912\n",
      "Epoch: 1 \tStep: 653 \tTime Elapse: 8219.474604606628 \tLoss: 2.197 \tMean Loss: 2.152 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.650442123413086\n",
      "Parameter containing:\n",
      "tensor([[4.3211, 0.3804, 1.2875, 6.2740, 3.1319, 3.6501, 5.8074, 0.3759, 1.6506,\n",
      "         3.5913]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.400163412094116\n",
      "Epoch: 1 \tStep: 654 \tTime Elapse: 8231.543345451355 \tLoss: 2.345 \tMean Loss: 2.151 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8367667198181152\n",
      "Parameter containing:\n",
      "tensor([[4.3218, 0.3796, 1.2880, 6.2746, 3.1325, 3.6509, 5.8050, 0.3738, 1.6506,\n",
      "         3.5940]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.411957263946533\n",
      "Epoch: 1 \tStep: 655 \tTime Elapse: 8243.809211969376 \tLoss: 1.95 \tMean Loss: 2.145 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8373043537139893\n",
      "Parameter containing:\n",
      "tensor([[4.3223, 0.3787, 1.2882, 6.2752, 3.1330, 3.6516, 5.8030, 0.3718, 1.6506,\n",
      "         3.5965]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.67258882522583\n",
      "Epoch: 1 \tStep: 656 \tTime Elapse: 8256.336059093475 \tLoss: 2.184 \tMean Loss: 2.144 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8439369201660156\n",
      "Parameter containing:\n",
      "tensor([[4.3243, 0.3782, 1.2903, 6.2759, 3.1339, 3.6500, 5.8028, 0.3704, 1.6506,\n",
      "         3.5967]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.667011499404907\n",
      "Epoch: 1 \tStep: 657 \tTime Elapse: 8268.86351442337 \tLoss: 1.846 \tMean Loss: 2.133 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6370842456817627\n",
      "Parameter containing:\n",
      "tensor([[4.3263, 0.3778, 1.2923, 6.2767, 3.1347, 3.6483, 5.8030, 0.3692, 1.6506,\n",
      "         3.5967]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.705983400344849\n",
      "Epoch: 1 \tStep: 658 \tTime Elapse: 8281.224628210068 \tLoss: 2.196 \tMean Loss: 2.138 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8600361347198486\n",
      "Parameter containing:\n",
      "tensor([[4.3303, 0.3785, 1.2961, 6.2776, 3.1357, 3.6463, 5.8040, 0.3676, 1.6506,\n",
      "         3.5964]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.406650304794312\n",
      "Epoch: 1 \tStep: 659 \tTime Elapse: 8293.507995843887 \tLoss: 2.263 \tMean Loss: 2.141 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8615391254425049\n",
      "Parameter containing:\n",
      "tensor([[4.3340, 0.3793, 1.2997, 6.2785, 3.1365, 3.6446, 5.8048, 0.3662, 1.6506,\n",
      "         3.5962]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.454055547714233\n",
      "Epoch: 1 \tStep: 660 \tTime Elapse: 8305.840752840042 \tLoss: 2.419 \tMean Loss: 2.154 \tMean Acc: 0.27\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.861304759979248\n",
      "Parameter containing:\n",
      "tensor([[4.3384, 0.3800, 1.3038, 6.2794, 3.1374, 3.6437, 5.8044, 0.3640, 1.6506,\n",
      "         3.5977]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.709612131118774\n",
      "Epoch: 1 \tStep: 661 \tTime Elapse: 8318.428465604782 \tLoss: 1.969 \tMean Loss: 2.149 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6574456691741943\n",
      "Parameter containing:\n",
      "tensor([[4.3417, 0.3804, 1.3069, 6.2802, 3.1383, 3.6423, 5.8039, 0.3618, 1.6506,\n",
      "         3.5986]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.678051948547363\n",
      "Epoch: 1 \tStep: 662 \tTime Elapse: 8330.781819581985 \tLoss: 2.062 \tMean Loss: 2.144 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8301301002502441\n",
      "Parameter containing:\n",
      "tensor([[4.3441, 0.3805, 1.3092, 6.2809, 3.1390, 3.6418, 5.8024, 0.3591, 1.6506,\n",
      "         3.6007]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.671834707260132\n",
      "Epoch: 1 \tStep: 663 \tTime Elapse: 8343.300397872925 \tLoss: 2.218 \tMean Loss: 2.15 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.845069169998169\n",
      "Parameter containing:\n",
      "tensor([[4.3466, 0.3806, 1.3113, 6.2815, 3.1397, 3.6388, 5.8027, 0.3580, 1.6506,\n",
      "         3.5994]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.677751302719116\n",
      "Epoch: 1 \tStep: 664 \tTime Elapse: 8355.839786052704 \tLoss: 2.041 \tMean Loss: 2.144 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6695992946624756\n",
      "Parameter containing:\n",
      "tensor([[4.3490, 0.3808, 1.3134, 6.2820, 3.1404, 3.6360, 5.8031, 0.3571, 1.6506,\n",
      "         3.5981]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.625503301620483\n",
      "Epoch: 1 \tStep: 665 \tTime Elapse: 8368.15219283104 \tLoss: 2.423 \tMean Loss: 2.148 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6744418144226074\n",
      "Parameter containing:\n",
      "tensor([[4.3501, 0.3801, 1.3147, 6.2825, 3.1410, 3.6314, 5.8041, 0.3574, 1.6506,\n",
      "         3.5949]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.444372415542603\n",
      "Epoch: 1 \tStep: 666 \tTime Elapse: 8380.288558244705 \tLoss: 1.946 \tMean Loss: 2.139 \tMean Acc: 0.271\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8607063293457031\n",
      "Parameter containing:\n",
      "tensor([[4.3493, 0.3783, 1.3141, 6.2829, 3.1415, 3.6265, 5.8053, 0.3577, 1.6506,\n",
      "         3.5916]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.786058902740479\n",
      "Epoch: 1 \tStep: 667 \tTime Elapse: 8392.951903104782 \tLoss: 1.799 \tMean Loss: 2.12 \tMean Acc: 0.272\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8638780117034912\n",
      "Parameter containing:\n",
      "tensor([[4.3491, 0.3768, 1.3142, 6.2833, 3.1419, 3.6204, 5.8082, 0.3585, 1.6506,\n",
      "         3.5866]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.817324161529541\n",
      "Epoch: 1 \tStep: 668 \tTime Elapse: 8405.650073766708 \tLoss: 1.875 \tMean Loss: 2.11 \tMean Acc: 0.273\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8872265815734863\n",
      "Parameter containing:\n",
      "tensor([[4.3474, 0.3745, 1.3129, 6.2836, 3.1424, 3.6133, 5.8110, 0.3603, 1.6506,\n",
      "         3.5805]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.461440086364746\n",
      "Epoch: 1 \tStep: 669 \tTime Elapse: 8418.0157122612 \tLoss: 2.248 \tMean Loss: 2.111 \tMean Acc: 0.273\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6697518825531006\n",
      "Parameter containing:\n",
      "tensor([[4.3448, 0.3716, 1.3106, 6.2839, 3.1428, 3.6087, 5.8120, 0.3608, 1.6506,\n",
      "         3.5777]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.441202640533447\n",
      "Epoch: 1 \tStep: 670 \tTime Elapse: 8430.145769357681 \tLoss: 2.288 \tMean Loss: 2.108 \tMean Acc: 0.273\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8632874488830566\n",
      "Parameter containing:\n",
      "tensor([[4.3425, 0.3691, 1.3086, 6.2842, 3.1431, 3.6049, 5.8128, 0.3610, 1.6506,\n",
      "         3.5755]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85203504562378\n",
      "Epoch: 1 \tStep: 671 \tTime Elapse: 8442.878011226654 \tLoss: 2.424 \tMean Loss: 2.122 \tMean Acc: 0.272\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8719701766967773\n",
      "Parameter containing:\n",
      "tensor([[4.3403, 0.3666, 1.3064, 6.2845, 3.1434, 3.6016, 5.8132, 0.3606, 1.6506,\n",
      "         3.5741]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85034728050232\n",
      "Epoch: 1 \tStep: 672 \tTime Elapse: 8455.617412567139 \tLoss: 2.085 \tMean Loss: 2.132 \tMean Acc: 0.273\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8688089847564697\n",
      "Parameter containing:\n",
      "tensor([[4.3366, 0.3636, 1.3027, 6.2848, 3.1436, 3.5992, 5.8125, 0.3598, 1.6506,\n",
      "         3.5738]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.378750562667847\n",
      "Epoch: 1 \tStep: 673 \tTime Elapse: 8467.881831169128 \tLoss: 2.081 \tMean Loss: 2.135 \tMean Acc: 0.273\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6923243999481201\n",
      "Parameter containing:\n",
      "tensor([[4.3344, 0.3608, 1.3000, 6.2850, 3.1437, 3.5962, 5.8125, 0.3584, 1.6506,\n",
      "         3.5732]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.394190788269043\n",
      "Epoch: 1 \tStep: 674 \tTime Elapse: 8479.985874176025 \tLoss: 1.71 \tMean Loss: 2.118 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8570988178253174\n",
      "Parameter containing:\n",
      "tensor([[4.3326, 0.3582, 1.2977, 6.2852, 3.1437, 3.5956, 5.8102, 0.3560, 1.6506,\n",
      "         3.5757]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.402556419372559\n",
      "Epoch: 1 \tStep: 675 \tTime Elapse: 8492.264529705048 \tLoss: 2.279 \tMean Loss: 2.12 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.883239507675171\n",
      "Parameter containing:\n",
      "tensor([[4.3311, 0.3557, 1.2957, 6.2854, 3.1437, 3.5970, 5.8056, 0.3526, 1.6506,\n",
      "         3.5807]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.416385889053345\n",
      "Epoch: 1 \tStep: 676 \tTime Elapse: 8504.581506967545 \tLoss: 2.062 \tMean Loss: 2.119 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.68361234664917\n",
      "Parameter containing:\n",
      "tensor([[4.3284, 0.3527, 1.2932, 6.2856, 3.1437, 3.5968, 5.8020, 0.3508, 1.6506,\n",
      "         3.5834]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.576318502426147\n",
      "Epoch: 1 \tStep: 677 \tTime Elapse: 8516.859054088593 \tLoss: 2.082 \tMean Loss: 2.121 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6850395202636719\n",
      "Parameter containing:\n",
      "tensor([[4.3259, 0.3500, 1.2909, 6.2858, 3.1436, 3.5966, 5.7989, 0.3491, 1.6506,\n",
      "         3.5858]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64062762260437\n",
      "Epoch: 1 \tStep: 678 \tTime Elapse: 8529.201980829239 \tLoss: 2.186 \tMean Loss: 2.12 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8232624530792236\n",
      "Parameter containing:\n",
      "tensor([[4.3249, 0.3481, 1.2898, 6.2859, 3.1435, 3.5973, 5.7940, 0.3467, 1.6506,\n",
      "         3.5896]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.667763233184814\n",
      "Epoch: 1 \tStep: 679 \tTime Elapse: 8541.709679841995 \tLoss: 2.204 \tMean Loss: 2.122 \tMean Acc: 0.274\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8497498035430908\n",
      "Parameter containing:\n",
      "tensor([[4.3237, 0.3461, 1.2884, 6.2860, 3.1435, 3.5976, 5.7900, 0.3446, 1.6506,\n",
      "         3.5927]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64493179321289\n",
      "Epoch: 1 \tStep: 680 \tTime Elapse: 8554.221394062042 \tLoss: 1.722 \tMean Loss: 2.114 \tMean Acc: 0.275\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8746163845062256\n",
      "Parameter containing:\n",
      "tensor([[4.3248, 0.3450, 1.2895, 6.2860, 3.1433, 3.5983, 5.7857, 0.3423, 1.6506,\n",
      "         3.5962]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.470418214797974\n",
      "Epoch: 1 \tStep: 681 \tTime Elapse: 8566.584119319916 \tLoss: 2.078 \tMean Loss: 2.113 \tMean Acc: 0.275\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6847403049468994\n",
      "Parameter containing:\n",
      "tensor([[4.3276, 0.3448, 1.2924, 6.2860, 3.1430, 3.5967, 5.7841, 0.3405, 1.6506,\n",
      "         3.5967]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.448203325271606\n",
      "Epoch: 1 \tStep: 682 \tTime Elapse: 8578.73439002037 \tLoss: 1.853 \tMean Loss: 2.101 \tMean Acc: 0.275\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8576436042785645\n",
      "Parameter containing:\n",
      "tensor([[4.3290, 0.3441, 1.2936, 6.2860, 3.1428, 3.5953, 5.7822, 0.3385, 1.6506,\n",
      "         3.5975]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.424765825271606\n",
      "Epoch: 1 \tStep: 683 \tTime Elapse: 8591.033390522003 \tLoss: 1.826 \tMean Loss: 2.089 \tMean Acc: 0.276\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.878859519958496\n",
      "Parameter containing:\n",
      "tensor([[4.3336, 0.3449, 1.2976, 6.2859, 3.1425, 3.5922, 5.7833, 0.3364, 1.6506,\n",
      "         3.5964]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.443875551223755\n",
      "Epoch: 1 \tStep: 684 \tTime Elapse: 8603.373333454132 \tLoss: 1.959 \tMean Loss: 2.076 \tMean Acc: 0.276\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8624179363250732\n",
      "Parameter containing:\n",
      "tensor([[4.3369, 0.3453, 1.3002, 6.2858, 3.1422, 3.5892, 5.7849, 0.3344, 1.6506,\n",
      "         3.5952]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.443905353546143\n",
      "Epoch: 1 \tStep: 685 \tTime Elapse: 8615.696692943573 \tLoss: 2.084 \tMean Loss: 2.08 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6692278385162354\n",
      "Parameter containing:\n",
      "tensor([[4.3404, 0.3462, 1.3032, 6.2857, 3.1420, 3.5847, 5.7869, 0.3331, 1.6506,\n",
      "         3.5922]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.454154253005981\n",
      "Epoch: 1 \tStep: 686 \tTime Elapse: 8627.837842702866 \tLoss: 2.251 \tMean Loss: 2.083 \tMean Acc: 0.276\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8701868057250977\n",
      "Parameter containing:\n",
      "tensor([[4.3433, 0.3471, 1.3056, 6.2857, 3.1417, 3.5806, 5.7889, 0.3319, 1.6506,\n",
      "         3.5893]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.675342082977295\n",
      "Epoch: 1 \tStep: 687 \tTime Elapse: 8640.400110006332 \tLoss: 2.189 \tMean Loss: 2.094 \tMean Acc: 0.276\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8418970108032227\n",
      "Parameter containing:\n",
      "tensor([[4.3475, 0.3483, 1.3094, 6.2856, 3.1415, 3.5752, 5.7924, 0.3311, 1.6506,\n",
      "         3.5853]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.702017307281494\n",
      "Epoch: 1 \tStep: 688 \tTime Elapse: 8652.961726665497 \tLoss: 1.886 \tMean Loss: 2.084 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6727259159088135\n",
      "Parameter containing:\n",
      "tensor([[4.3513, 0.3495, 1.3129, 6.2856, 3.1413, 3.5690, 5.7967, 0.3308, 1.6506,\n",
      "         3.5800]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.848686695098877\n",
      "Epoch: 1 \tStep: 689 \tTime Elapse: 8665.50050163269 \tLoss: 2.227 \tMean Loss: 2.083 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6839079856872559\n",
      "Parameter containing:\n",
      "tensor([[4.3547, 0.3506, 1.3159, 6.2855, 3.1410, 3.5635, 5.8005, 0.3306, 1.6506,\n",
      "         3.5753]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.667081356048584\n",
      "Epoch: 1 \tStep: 690 \tTime Elapse: 8677.868668794632 \tLoss: 2.416 \tMean Loss: 2.082 \tMean Acc: 0.276\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8546953201293945\n",
      "Parameter containing:\n",
      "tensor([[4.3602, 0.3525, 1.3209, 6.2855, 3.1408, 3.5585, 5.8044, 0.3298, 1.6506,\n",
      "         3.5711]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.679041147232056\n",
      "Epoch: 1 \tStep: 691 \tTime Elapse: 8690.419044017792 \tLoss: 2.018 \tMean Loss: 2.084 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8495798110961914\n",
      "Parameter containing:\n",
      "tensor([[4.3649, 0.3537, 1.3250, 6.2855, 3.1406, 3.5552, 5.8069, 0.3278, 1.6506,\n",
      "         3.5696]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.464953899383545\n",
      "Epoch: 1 \tStep: 692 \tTime Elapse: 8702.75082707405 \tLoss: 2.09 \tMean Loss: 2.085 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8926734924316406\n",
      "Parameter containing:\n",
      "tensor([[4.3675, 0.3537, 1.3269, 6.2854, 3.1405, 3.5507, 5.8099, 0.3272, 1.6506,\n",
      "         3.5663]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.699638605117798\n",
      "Epoch: 1 \tStep: 693 \tTime Elapse: 8715.359999418259 \tLoss: 2.06 \tMean Loss: 2.08 \tMean Acc: 0.277\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6861398220062256\n",
      "Parameter containing:\n",
      "tensor([[4.3691, 0.3533, 1.3276, 6.2854, 3.1404, 3.5462, 5.8126, 0.3265, 1.6506,\n",
      "         3.5631]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.671257495880127\n",
      "Epoch: 1 \tStep: 694 \tTime Elapse: 8727.735943078995 \tLoss: 1.746 \tMean Loss: 2.07 \tMean Acc: 0.278\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.849524974822998\n",
      "Parameter containing:\n",
      "tensor([[4.3705, 0.3525, 1.3280, 6.2853, 3.1403, 3.5447, 5.8132, 0.3243, 1.6506,\n",
      "         3.5639]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.658901691436768\n",
      "Epoch: 1 \tStep: 695 \tTime Elapse: 8740.261267662048 \tLoss: 2.137 \tMean Loss: 2.06 \tMean Acc: 0.278\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8740460872650146\n",
      "Parameter containing:\n",
      "tensor([[4.3718, 0.3518, 1.3284, 6.2853, 3.1403, 3.5435, 5.8137, 0.3222, 1.6506,\n",
      "         3.5647]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414121627807617\n",
      "Epoch: 1 \tStep: 696 \tTime Elapse: 8752.566427230835 \tLoss: 2.195 \tMean Loss: 2.069 \tMean Acc: 0.278\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8736541271209717\n",
      "Parameter containing:\n",
      "tensor([[4.3739, 0.3512, 1.3294, 6.2852, 3.1402, 3.5434, 5.8143, 0.3195, 1.6506,\n",
      "         3.5667]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.384421348571777\n",
      "Epoch: 1 \tStep: 697 \tTime Elapse: 8764.840877056122 \tLoss: 1.958 \tMean Loss: 2.074 \tMean Acc: 0.278\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6832878589630127\n",
      "Parameter containing:\n",
      "tensor([[4.3761, 0.3502, 1.3305, 6.2852, 3.1402, 3.5422, 5.8158, 0.3172, 1.6506,\n",
      "         3.5676]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.398913145065308\n",
      "Epoch: 1 \tStep: 698 \tTime Elapse: 8776.940455913544 \tLoss: 1.819 \tMean Loss: 2.072 \tMean Acc: 0.279\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8766071796417236\n",
      "Parameter containing:\n",
      "tensor([[4.3769, 0.3488, 1.3303, 6.2852, 3.1402, 3.5435, 5.8146, 0.3135, 1.6506,\n",
      "         3.5720]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.857576847076416\n",
      "Epoch: 1 \tStep: 699 \tTime Elapse: 8789.691673278809 \tLoss: 1.995 \tMean Loss: 2.064 \tMean Acc: 0.279\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.879511833190918\n",
      "Parameter containing:\n",
      "tensor([[4.3735, 0.3455, 1.3266, 6.2850, 3.1404, 3.5442, 5.8107, 0.3110, 1.6506,\n",
      "         3.5758]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.822048664093018\n",
      "Epoch: 1 \tStep: 700 \tTime Elapse: 8802.410540342331 \tLoss: 1.942 \tMean Loss: 2.052 \tMean Acc: 0.28\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6995158195495605\n",
      "Parameter containing:\n",
      "tensor([[4.3684, 0.3419, 1.3211, 6.2848, 3.1406, 3.5446, 5.8072, 0.3090, 1.6506,\n",
      "         3.5788]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.95086145401001\n",
      "Epoch: 1 \tStep: 701 \tTime Elapse: 8815.07741856575 \tLoss: 2.011 \tMean Loss: 2.038 \tMean Acc: 0.28\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6738970279693604\n",
      "Parameter containing:\n",
      "tensor([[4.3634, 0.3385, 1.3157, 6.2846, 3.1408, 3.5457, 5.8034, 0.3067, 1.6506,\n",
      "         3.5825]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.432531595230103\n",
      "Epoch: 1 \tStep: 702 \tTime Elapse: 8827.201374053955 \tLoss: 2.155 \tMean Loss: 2.041 \tMean Acc: 0.28\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.844597578048706\n",
      "Parameter containing:\n",
      "tensor([[4.3567, 0.3344, 1.3087, 6.2844, 3.1411, 3.5453, 5.8006, 0.3051, 1.6506,\n",
      "         3.5844]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.392247438430786\n",
      "Epoch: 1 \tStep: 703 \tTime Elapse: 8839.454998493195 \tLoss: 1.887 \tMean Loss: 2.034 \tMean Acc: 0.281\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8475978374481201\n",
      "Parameter containing:\n",
      "tensor([[4.3508, 0.3303, 1.3025, 6.2842, 3.1413, 3.5459, 5.7971, 0.3030, 1.6506,\n",
      "         3.5873]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.365330457687378\n",
      "Epoch: 1 \tStep: 704 \tTime Elapse: 8851.68547964096 \tLoss: 1.844 \tMean Loss: 2.039 \tMean Acc: 0.281\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8877358436584473\n",
      "Parameter containing:\n",
      "tensor([[4.3463, 0.3268, 1.2978, 6.2840, 3.1415, 3.5443, 5.7955, 0.3015, 1.6506,\n",
      "         3.5877]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.368521690368652\n",
      "Epoch: 1 \tStep: 705 \tTime Elapse: 8863.95823431015 \tLoss: 1.83 \tMean Loss: 2.024 \tMean Acc: 0.282\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7353527545928955\n",
      "Parameter containing:\n",
      "tensor([[4.3421, 0.3231, 1.2930, 6.2839, 3.1417, 3.5428, 5.7943, 0.2994, 1.6506,\n",
      "         3.5887]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.654414653778076\n",
      "Epoch: 1 \tStep: 706 \tTime Elapse: 8876.364893913269 \tLoss: 1.892 \tMean Loss: 2.018 \tMean Acc: 0.283\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8609635829925537\n",
      "Parameter containing:\n",
      "tensor([[4.3397, 0.3202, 1.2898, 6.2837, 3.1418, 3.5403, 5.7935, 0.2977, 1.6506,\n",
      "         3.5884]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.415725708007812\n",
      "Epoch: 1 \tStep: 707 \tTime Elapse: 8888.658237934113 \tLoss: 2.117 \tMean Loss: 2.019 \tMean Acc: 0.283\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8658878803253174\n",
      "Parameter containing:\n",
      "tensor([[4.3366, 0.3171, 1.2859, 6.2836, 3.1420, 3.5375, 5.7933, 0.2961, 1.6506,\n",
      "         3.5874]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.408499479293823\n",
      "Epoch: 1 \tStep: 708 \tTime Elapse: 8900.949922084808 \tLoss: 1.747 \tMean Loss: 2.005 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8713300228118896\n",
      "Parameter containing:\n",
      "tensor([[4.3364, 0.3158, 1.2854, 6.2835, 3.1421, 3.5323, 5.7940, 0.2956, 1.6506,\n",
      "         3.5835]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39909553527832\n",
      "Epoch: 1 \tStep: 709 \tTime Elapse: 8913.237332344055 \tLoss: 2.179 \tMean Loss: 2.004 \tMean Acc: 0.283\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.655022382736206\n",
      "Parameter containing:\n",
      "tensor([[4.3381, 0.3154, 1.2869, 6.2833, 3.1422, 3.5272, 5.7952, 0.2950, 1.6506,\n",
      "         3.5798]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414273500442505\n",
      "Epoch: 1 \tStep: 710 \tTime Elapse: 8925.324589014053 \tLoss: 2.349 \tMean Loss: 2.025 \tMean Acc: 0.283\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8808856010437012\n",
      "Parameter containing:\n",
      "tensor([[4.3396, 0.3150, 1.2879, 6.2832, 3.1422, 3.5223, 5.7968, 0.2945, 1.6506,\n",
      "         3.5761]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.38626742362976\n",
      "Epoch: 1 \tStep: 711 \tTime Elapse: 8937.609011888504 \tLoss: 1.959 \tMean Loss: 2.021 \tMean Acc: 0.283\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9594907760620117\n",
      "Parameter containing:\n",
      "tensor([[4.3416, 0.3148, 1.2895, 6.2831, 3.1423, 3.5175, 5.7988, 0.2939, 1.6506,\n",
      "         3.5725]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.395965337753296\n",
      "Epoch: 1 \tStep: 712 \tTime Elapse: 8949.981772899628 \tLoss: 1.991 \tMean Loss: 2.025 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6805574893951416\n",
      "Parameter containing:\n",
      "tensor([[4.3437, 0.3148, 1.2913, 6.2830, 3.1423, 3.5130, 5.8008, 0.2933, 1.6506,\n",
      "         3.5691]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.572404384613037\n",
      "Epoch: 1 \tStep: 713 \tTime Elapse: 8962.25170993805 \tLoss: 2.193 \tMean Loss: 2.038 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6723182201385498\n",
      "Parameter containing:\n",
      "tensor([[4.3453, 0.3141, 1.2924, 6.2829, 3.1424, 3.5083, 5.8034, 0.2932, 1.6506,\n",
      "         3.5652]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414240837097168\n",
      "Epoch: 1 \tStep: 714 \tTime Elapse: 8974.355791568756 \tLoss: 2.037 \tMean Loss: 2.04 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8673973083496094\n",
      "Parameter containing:\n",
      "tensor([[4.3441, 0.3125, 1.2906, 6.2828, 3.1424, 3.5031, 5.8066, 0.2938, 1.6506,\n",
      "         3.5600]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.70432424545288\n",
      "Epoch: 1 \tStep: 715 \tTime Elapse: 8986.944778442383 \tLoss: 1.887 \tMean Loss: 2.034 \tMean Acc: 0.285\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8775265216827393\n",
      "Parameter containing:\n",
      "tensor([[4.3435, 0.3112, 1.2895, 6.2828, 3.1424, 3.4988, 5.8091, 0.2943, 1.6506,\n",
      "         3.5558]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.67096734046936\n",
      "Epoch: 1 \tStep: 716 \tTime Elapse: 8999.510349035263 \tLoss: 2.407 \tMean Loss: 2.039 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9102566242218018\n",
      "Parameter containing:\n",
      "tensor([[4.3433, 0.3104, 1.2888, 6.2828, 3.1424, 3.4946, 5.8123, 0.2941, 1.6506,\n",
      "         3.5520]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.493550777435303\n",
      "Epoch: 1 \tStep: 717 \tTime Elapse: 9011.930820465088 \tLoss: 2.291 \tMean Loss: 2.042 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6776068210601807\n",
      "Parameter containing:\n",
      "tensor([[4.3429, 0.3093, 1.2879, 6.2827, 3.1424, 3.4904, 5.8151, 0.2940, 1.6506,\n",
      "         3.5484]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.857510089874268\n",
      "Epoch: 1 \tStep: 718 \tTime Elapse: 9024.484305143356 \tLoss: 1.984 \tMean Loss: 2.045 \tMean Acc: 0.284\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8509047031402588\n",
      "Parameter containing:\n",
      "tensor([[4.3418, 0.3080, 1.2862, 6.2827, 3.1424, 3.4865, 5.8178, 0.2938, 1.6506,\n",
      "         3.5450]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.860100984573364\n",
      "Epoch: 1 \tStep: 719 \tTime Elapse: 9037.211961746216 \tLoss: 1.725 \tMean Loss: 2.029 \tMean Acc: 0.285\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.869103193283081\n",
      "Parameter containing:\n",
      "tensor([[4.3402, 0.3064, 1.2841, 6.2827, 3.1424, 3.4829, 5.8202, 0.2936, 1.6506,\n",
      "         3.5422]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.860738039016724\n",
      "Epoch: 1 \tStep: 720 \tTime Elapse: 9049.964364051819 \tLoss: 1.484 \tMean Loss: 1.998 \tMean Acc: 0.286\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.86183500289917\n",
      "Parameter containing:\n",
      "tensor([[4.3387, 0.3047, 1.2822, 6.2827, 3.1423, 3.4790, 5.8218, 0.2938, 1.6506,\n",
      "         3.5391]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.843922138214111\n",
      "Epoch: 1 \tStep: 721 \tTime Elapse: 9062.686738014221 \tLoss: 2.225 \tMean Loss: 2.005 \tMean Acc: 0.286\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7138755321502686\n",
      "Parameter containing:\n",
      "tensor([[4.3374, 0.3030, 1.2807, 6.2827, 3.1423, 3.4749, 5.8237, 0.2941, 1.6506,\n",
      "         3.5356]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.869704961776733\n",
      "Epoch: 1 \tStep: 722 \tTime Elapse: 9075.287423610687 \tLoss: 1.988 \tMean Loss: 2.001 \tMean Acc: 0.286\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.869734525680542\n",
      "Parameter containing:\n",
      "tensor([[4.3352, 0.3009, 1.2783, 6.2827, 3.1423, 3.4703, 5.8260, 0.2946, 1.6506,\n",
      "         3.5317]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.826818704605103\n",
      "Epoch: 1 \tStep: 723 \tTime Elapse: 9088.000705003738 \tLoss: 1.833 \tMean Loss: 1.994 \tMean Acc: 0.287\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8878848552703857\n",
      "Parameter containing:\n",
      "tensor([[4.3343, 0.2991, 1.2773, 6.2827, 3.1422, 3.4655, 5.8294, 0.2947, 1.6506,\n",
      "         3.5280]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85857105255127\n",
      "Epoch: 1 \tStep: 724 \tTime Elapse: 9100.764494895935 \tLoss: 1.681 \tMean Loss: 1.991 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.700894832611084\n",
      "Parameter containing:\n",
      "tensor([[4.3338, 0.2975, 1.2767, 6.2827, 3.1422, 3.4607, 5.8330, 0.2949, 1.6506,\n",
      "         3.5239]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.96666145324707\n",
      "Epoch: 1 \tStep: 725 \tTime Elapse: 9113.448927402496 \tLoss: 2.203 \tMean Loss: 1.994 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6804542541503906\n",
      "Parameter containing:\n",
      "tensor([[4.3335, 0.2962, 1.2764, 6.2827, 3.1422, 3.4558, 5.8365, 0.2953, 1.6506,\n",
      "         3.5196]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.424177408218384\n",
      "Epoch: 1 \tStep: 726 \tTime Elapse: 9125.571078062057 \tLoss: 2.193 \tMean Loss: 1.994 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.852278232574463\n",
      "Parameter containing:\n",
      "tensor([[4.3320, 0.2941, 1.2745, 6.2827, 3.1421, 3.4540, 5.8384, 0.2942, 1.6506,\n",
      "         3.5195]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.418325185775757\n",
      "Epoch: 1 \tStep: 727 \tTime Elapse: 9137.858500003815 \tLoss: 1.854 \tMean Loss: 1.99 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8587074279785156\n",
      "Parameter containing:\n",
      "tensor([[4.3308, 0.2922, 1.2731, 6.2827, 3.1421, 3.4543, 5.8392, 0.2920, 1.6506,\n",
      "         3.5223]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.673229932785034\n",
      "Epoch: 1 \tStep: 728 \tTime Elapse: 9150.408553123474 \tLoss: 2.303 \tMean Loss: 2.006 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8892853260040283\n",
      "Parameter containing:\n",
      "tensor([[4.3286, 0.2899, 1.2708, 6.2827, 3.1420, 3.4540, 5.8384, 0.2903, 1.6506,\n",
      "         3.5248]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.683331966400146\n",
      "Epoch: 1 \tStep: 729 \tTime Elapse: 9162.998119592667 \tLoss: 2.281 \tMean Loss: 2.016 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6922643184661865\n",
      "Parameter containing:\n",
      "tensor([[4.3258, 0.2875, 1.2676, 6.2827, 3.1420, 3.4556, 5.8368, 0.2879, 1.6506,\n",
      "         3.5295]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.420210361480713\n",
      "Epoch: 1 \tStep: 730 \tTime Elapse: 9175.127839326859 \tLoss: 2.13 \tMean Loss: 2.022 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.864847183227539\n",
      "Parameter containing:\n",
      "tensor([[4.3229, 0.2852, 1.2644, 6.2827, 3.1420, 3.4569, 5.8354, 0.2857, 1.6506,\n",
      "         3.5335]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.384815216064453\n",
      "Epoch: 1 \tStep: 731 \tTime Elapse: 9187.393992900848 \tLoss: 1.963 \tMean Loss: 2.02 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8703413009643555\n",
      "Parameter containing:\n",
      "tensor([[4.3222, 0.2839, 1.2632, 6.2827, 3.1419, 3.4586, 5.8344, 0.2830, 1.6506,\n",
      "         3.5383]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.393625259399414\n",
      "Epoch: 1 \tStep: 732 \tTime Elapse: 9199.674951791763 \tLoss: 2.229 \tMean Loss: 2.023 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8827786445617676\n",
      "Parameter containing:\n",
      "tensor([[4.3219, 0.2828, 1.2622, 6.2828, 3.1419, 3.4602, 5.8338, 0.2804, 1.6506,\n",
      "         3.5429]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.816218137741089\n",
      "Epoch: 1 \tStep: 733 \tTime Elapse: 9212.390476226807 \tLoss: 2.194 \tMean Loss: 2.033 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.682246446609497\n",
      "Parameter containing:\n",
      "tensor([[4.3216, 0.2817, 1.2612, 6.2828, 3.1419, 3.4619, 5.8332, 0.2780, 1.6506,\n",
      "         3.5472]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.835125923156738\n",
      "Epoch: 1 \tStep: 734 \tTime Elapse: 9224.925198078156 \tLoss: 2.203 \tMean Loss: 2.045 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8773248195648193\n",
      "Parameter containing:\n",
      "tensor([[4.3216, 0.2807, 1.2606, 6.2828, 3.1419, 3.4632, 5.8330, 0.2755, 1.6506,\n",
      "         3.5511]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.834065675735474\n",
      "Epoch: 1 \tStep: 735 \tTime Elapse: 9237.653172254562 \tLoss: 1.519 \tMean Loss: 2.035 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8551931381225586\n",
      "Parameter containing:\n",
      "tensor([[4.3221, 0.2798, 1.2607, 6.2828, 3.1418, 3.4636, 5.8330, 0.2733, 1.6506,\n",
      "         3.5539]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.85118293762207\n",
      "Epoch: 1 \tStep: 736 \tTime Elapse: 9250.376984357834 \tLoss: 2.003 \tMean Loss: 2.038 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6704521179199219\n",
      "Parameter containing:\n",
      "tensor([[4.3223, 0.2789, 1.2605, 6.2828, 3.1418, 3.4641, 5.8329, 0.2714, 1.6506,\n",
      "         3.5565]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.639810800552368\n",
      "Epoch: 1 \tStep: 737 \tTime Elapse: 9262.704561948776 \tLoss: 2.42 \tMean Loss: 2.049 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6880064010620117\n",
      "Parameter containing:\n",
      "tensor([[4.3224, 0.2781, 1.2603, 6.2828, 3.1418, 3.4646, 5.8325, 0.2697, 1.6506,\n",
      "         3.5590]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.45584750175476\n",
      "Epoch: 1 \tStep: 738 \tTime Elapse: 9274.865388393402 \tLoss: 2.43 \tMean Loss: 2.071 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.872628927230835\n",
      "Parameter containing:\n",
      "tensor([[4.3230, 0.2775, 1.2606, 6.2827, 3.1418, 3.4660, 5.8314, 0.2677, 1.6506,\n",
      "         3.5625]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.469719648361206\n",
      "Epoch: 1 \tStep: 739 \tTime Elapse: 9287.224694490433 \tLoss: 2.377 \tMean Loss: 2.078 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8609790802001953\n",
      "Parameter containing:\n",
      "tensor([[4.3254, 0.2776, 1.2624, 6.2827, 3.1418, 3.4682, 5.8308, 0.2650, 1.6506,\n",
      "         3.5672]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.435281038284302\n",
      "Epoch: 1 \tStep: 740 \tTime Elapse: 9299.538125276566 \tLoss: 2.046 \tMean Loss: 2.068 \tMean Acc: 0.288\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8783831596374512\n",
      "Parameter containing:\n",
      "tensor([[4.3271, 0.2775, 1.2637, 6.2827, 3.1418, 3.4685, 5.8309, 0.2631, 1.6506,\n",
      "         3.5698]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.441239833831787\n",
      "Epoch: 1 \tStep: 741 \tTime Elapse: 9311.874887943268 \tLoss: 1.61 \tMean Loss: 2.056 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.68617844581604\n",
      "Parameter containing:\n",
      "tensor([[4.3284, 0.2772, 1.2645, 6.2827, 3.1418, 3.4685, 5.8309, 0.2613, 1.6506,\n",
      "         3.5721]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.434823989868164\n",
      "Epoch: 1 \tStep: 742 \tTime Elapse: 9324.013115882874 \tLoss: 2.201 \tMean Loss: 2.063 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8578829765319824\n",
      "Parameter containing:\n",
      "tensor([[4.3294, 0.2769, 1.2651, 6.2827, 3.1417, 3.4687, 5.8309, 0.2596, 1.6506,\n",
      "         3.5744]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.42579960823059\n",
      "Epoch: 1 \tStep: 743 \tTime Elapse: 9336.31371641159 \tLoss: 2.193 \tMean Loss: 2.063 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8720333576202393\n",
      "Parameter containing:\n",
      "tensor([[4.3309, 0.2767, 1.2662, 6.2827, 3.1417, 3.4700, 5.8298, 0.2576, 1.6506,\n",
      "         3.5779]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.864978313446045\n",
      "Epoch: 1 \tStep: 744 \tTime Elapse: 9349.068021297455 \tLoss: 2.367 \tMean Loss: 2.074 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8784410953521729\n",
      "Parameter containing:\n",
      "tensor([[4.3336, 0.2767, 1.2684, 6.2827, 3.1417, 3.4698, 5.8298, 0.2562, 1.6506,\n",
      "         3.5796]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.403509855270386\n",
      "Epoch: 1 \tStep: 745 \tTime Elapse: 9361.366848230362 \tLoss: 1.839 \tMean Loss: 2.073 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6952521800994873\n",
      "Parameter containing:\n",
      "tensor([[4.3359, 0.2765, 1.2702, 6.2827, 3.1417, 3.4691, 5.8303, 0.2549, 1.6506,\n",
      "         3.5805]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39055061340332\n",
      "Epoch: 1 \tStep: 746 \tTime Elapse: 9373.469916820526 \tLoss: 2.029 \tMean Loss: 2.06 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.873885154724121\n",
      "Parameter containing:\n",
      "tensor([[4.3379, 0.2762, 1.2719, 6.2827, 3.1417, 3.4685, 5.8307, 0.2537, 1.6506,\n",
      "         3.5813]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.634567499160767\n",
      "Epoch: 1 \tStep: 747 \tTime Elapse: 9385.995210647583 \tLoss: 2.412 \tMean Loss: 2.064 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8806421756744385\n",
      "Parameter containing:\n",
      "tensor([[4.3401, 0.2763, 1.2737, 6.2827, 3.1417, 3.4677, 5.8297, 0.2527, 1.6506,\n",
      "         3.5818]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.490396499633789\n",
      "Epoch: 1 \tStep: 748 \tTime Elapse: 9398.383290529251 \tLoss: 2.087 \tMean Loss: 2.067 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7101922035217285\n",
      "Parameter containing:\n",
      "tensor([[4.3416, 0.2762, 1.2751, 6.2827, 3.1417, 3.4669, 5.8292, 0.2518, 1.6506,\n",
      "         3.5820]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.915271043777466\n",
      "Epoch: 1 \tStep: 749 \tTime Elapse: 9411.025840997696 \tLoss: 2.203 \tMean Loss: 2.083 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6787145137786865\n",
      "Parameter containing:\n",
      "tensor([[4.3436, 0.2764, 1.2769, 6.2827, 3.1417, 3.4660, 5.8289, 0.2509, 1.6506,\n",
      "         3.5820]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.833553552627563\n",
      "Epoch: 1 \tStep: 750 \tTime Elapse: 9423.555990695953 \tLoss: 2.156 \tMean Loss: 2.106 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8503820896148682\n",
      "Parameter containing:\n",
      "tensor([[4.3457, 0.2767, 1.2787, 6.2827, 3.1417, 3.4657, 5.8283, 0.2498, 1.6506,\n",
      "         3.5827]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.50942850112915\n",
      "Epoch: 1 \tStep: 751 \tTime Elapse: 9435.932718992233 \tLoss: 2.402 \tMean Loss: 2.112 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8653273582458496\n",
      "Parameter containing:\n",
      "tensor([[4.3495, 0.2776, 1.2820, 6.2826, 3.1417, 3.4657, 5.8274, 0.2483, 1.6506,\n",
      "         3.5837]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.448110818862915\n",
      "Epoch: 1 \tStep: 752 \tTime Elapse: 9448.263065814972 \tLoss: 1.814 \tMean Loss: 2.106 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.880218505859375\n",
      "Parameter containing:\n",
      "tensor([[4.3529, 0.2783, 1.2848, 6.2826, 3.1417, 3.4654, 5.8265, 0.2470, 1.6506,\n",
      "         3.5843]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.457161664962769\n",
      "Epoch: 1 \tStep: 753 \tTime Elapse: 9460.617534399033 \tLoss: 2.238 \tMean Loss: 2.119 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.675710916519165\n",
      "Parameter containing:\n",
      "tensor([[4.3561, 0.2790, 1.2875, 6.2826, 3.1418, 3.4651, 5.8258, 0.2457, 1.6506,\n",
      "         3.5849]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.485387086868286\n",
      "Epoch: 1 \tStep: 754 \tTime Elapse: 9472.796516895294 \tLoss: 2.193 \tMean Loss: 2.136 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8314998149871826\n",
      "Parameter containing:\n",
      "tensor([[4.3586, 0.2792, 1.2896, 6.2826, 3.1418, 3.4630, 5.8270, 0.2451, 1.6506,\n",
      "         3.5831]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.521064281463623\n",
      "Epoch: 1 \tStep: 755 \tTime Elapse: 9485.166689157486 \tLoss: 1.905 \tMean Loss: 2.126 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8773446083068848\n",
      "Parameter containing:\n",
      "tensor([[4.3625, 0.2799, 1.2933, 6.2826, 3.1418, 3.4615, 5.8289, 0.2434, 1.6506,\n",
      "         3.5827]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.454347372055054\n",
      "Epoch: 1 \tStep: 756 \tTime Elapse: 9497.515884160995 \tLoss: 1.888 \tMean Loss: 2.116 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8574602603912354\n",
      "Parameter containing:\n",
      "tensor([[4.3659, 0.2805, 1.2964, 6.2826, 3.1418, 3.4602, 5.8305, 0.2418, 1.6506,\n",
      "         3.5824]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.47545576095581\n",
      "Epoch: 1 \tStep: 757 \tTime Elapse: 9509.865591049194 \tLoss: 2.414 \tMean Loss: 2.135 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6733460426330566\n",
      "Parameter containing:\n",
      "tensor([[4.3693, 0.2811, 1.2994, 6.2826, 3.1418, 3.4589, 5.8324, 0.2407, 1.6506,\n",
      "         3.5816]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.707339525222778\n",
      "Epoch: 1 \tStep: 758 \tTime Elapse: 9522.263833761215 \tLoss: 2.341 \tMean Loss: 2.136 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8755829334259033\n",
      "Parameter containing:\n",
      "tensor([[4.3724, 0.2818, 1.3020, 6.2826, 3.1418, 3.4579, 5.8342, 0.2394, 1.6506,\n",
      "         3.5813]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.46170449256897\n",
      "Epoch: 1 \tStep: 759 \tTime Elapse: 9534.6176674366 \tLoss: 2.165 \tMean Loss: 2.132 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8914976119995117\n",
      "Parameter containing:\n",
      "tensor([[4.3733, 0.2814, 1.3021, 6.2826, 3.1418, 3.4575, 5.8339, 0.2384, 1.6506,\n",
      "         3.5813]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.439311027526855\n",
      "Epoch: 1 \tStep: 760 \tTime Elapse: 9546.965844869614 \tLoss: 2.157 \tMean Loss: 2.133 \tMean Acc: 0.289\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6985490322113037\n",
      "Parameter containing:\n",
      "tensor([[4.3766, 0.2818, 1.3047, 6.2826, 3.1418, 3.4563, 5.8351, 0.2373, 1.6506,\n",
      "         3.5805]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.987428188323975\n",
      "Epoch: 1 \tStep: 761 \tTime Elapse: 9559.668753147125 \tLoss: 2.061 \tMean Loss: 2.136 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7009999752044678\n",
      "Parameter containing:\n",
      "tensor([[4.3815, 0.2825, 1.3086, 6.2825, 3.1419, 3.4558, 5.8360, 0.2357, 1.6506,\n",
      "         3.5806]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.8406240940094\n",
      "Epoch: 1 \tStep: 762 \tTime Elapse: 9572.227555274963 \tLoss: 1.882 \tMean Loss: 2.125 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.853062629699707\n",
      "Parameter containing:\n",
      "tensor([[4.3875, 0.2840, 1.3132, 6.2825, 3.1419, 3.4561, 5.8360, 0.2337, 1.6506,\n",
      "         3.5817]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.872305393218994\n",
      "Epoch: 1 \tStep: 763 \tTime Elapse: 9584.96979689598 \tLoss: 2.292 \tMean Loss: 2.128 \tMean Acc: 0.29\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9137074947357178\n",
      "Parameter containing:\n",
      "tensor([[4.3949, 0.2863, 1.3195, 6.2825, 3.1419, 3.4548, 5.8380, 0.2319, 1.6506,\n",
      "         3.5809]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.41377329826355\n",
      "Epoch: 1 \tStep: 764 \tTime Elapse: 9597.31451177597 \tLoss: 1.913 \tMean Loss: 2.119 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8712515830993652\n",
      "Parameter containing:\n",
      "tensor([[4.4021, 0.2886, 1.3252, 6.2824, 3.1420, 3.4525, 5.8416, 0.2301, 1.6506,\n",
      "         3.5789]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.681597471237183\n",
      "Epoch: 1 \tStep: 765 \tTime Elapse: 9609.884124994278 \tLoss: 2.056 \tMean Loss: 2.136 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7073190212249756\n",
      "Parameter containing:\n",
      "tensor([[4.4088, 0.2908, 1.3307, 6.2824, 3.1420, 3.4496, 5.8454, 0.2288, 1.6506,\n",
      "         3.5758]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.634604454040527\n",
      "Epoch: 1 \tStep: 766 \tTime Elapse: 9622.243151903152 \tLoss: 2.2 \tMean Loss: 2.143 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8675997257232666\n",
      "Parameter containing:\n",
      "tensor([[4.4152, 0.2926, 1.3360, 6.2823, 3.1421, 3.4475, 5.8487, 0.2273, 1.6506,\n",
      "         3.5739]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.38476848602295\n",
      "Epoch: 1 \tStep: 767 \tTime Elapse: 9634.512178897858 \tLoss: 2.269 \tMean Loss: 2.138 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8818459510803223\n",
      "Parameter containing:\n",
      "tensor([[4.4188, 0.2930, 1.3386, 6.2823, 3.1421, 3.4481, 5.8500, 0.2250, 1.6506,\n",
      "         3.5751]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.392091512680054\n",
      "Epoch: 1 \tStep: 768 \tTime Elapse: 9646.802996873856 \tLoss: 1.931 \tMean Loss: 2.121 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8580741882324219\n",
      "Parameter containing:\n",
      "tensor([[4.4227, 0.2939, 1.3417, 6.2823, 3.1421, 3.4453, 5.8529, 0.2239, 1.6506,\n",
      "         3.5719]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.414050102233887\n",
      "Epoch: 1 \tStep: 769 \tTime Elapse: 9659.09255695343 \tLoss: 1.853 \tMean Loss: 2.104 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6931471824645996\n",
      "Parameter containing:\n",
      "tensor([[4.4303, 0.2963, 1.3481, 6.2822, 3.1421, 3.4444, 5.8555, 0.2220, 1.6506,\n",
      "         3.5710]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.70238447189331\n",
      "Epoch: 1 \tStep: 770 \tTime Elapse: 9671.505494594574 \tLoss: 2.094 \tMean Loss: 2.105 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8813729286193848\n",
      "Parameter containing:\n",
      "tensor([[4.4363, 0.2979, 1.3527, 6.2822, 3.1422, 3.4458, 5.8570, 0.2193, 1.6506,\n",
      "         3.5731]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.832689762115479\n",
      "Epoch: 1 \tStep: 771 \tTime Elapse: 9684.236128807068 \tLoss: 2.143 \tMean Loss: 2.123 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8726348876953125\n",
      "Parameter containing:\n",
      "tensor([[4.4429, 0.2995, 1.3581, 6.2821, 3.1422, 3.4483, 5.8580, 0.2161, 1.6506,\n",
      "         3.5765]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.82188367843628\n",
      "Epoch: 1 \tStep: 772 \tTime Elapse: 9696.94792675972 \tLoss: 2.31 \tMean Loss: 2.127 \tMean Acc: 0.291\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6789119243621826\n",
      "Parameter containing:\n",
      "tensor([[4.4476, 0.3002, 1.3617, 6.2821, 3.1422, 3.4507, 5.8598, 0.2128, 1.6506,\n",
      "         3.5801]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.998645782470703\n",
      "Epoch: 1 \tStep: 773 \tTime Elapse: 9709.643155574799 \tLoss: 1.866 \tMean Loss: 2.116 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6817576885223389\n",
      "Parameter containing:\n",
      "tensor([[4.4506, 0.3004, 1.3636, 6.2821, 3.1422, 3.4522, 5.8618, 0.2100, 1.6506,\n",
      "         3.5823]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.83240818977356\n",
      "Epoch: 1 \tStep: 774 \tTime Elapse: 9722.174518108368 \tLoss: 2.101 \tMean Loss: 2.107 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8840229511260986\n",
      "Parameter containing:\n",
      "tensor([[4.4543, 0.3011, 1.3663, 6.2821, 3.1422, 3.4532, 5.8644, 0.2075, 1.6506,\n",
      "         3.5840]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.840805292129517\n",
      "Epoch: 1 \tStep: 775 \tTime Elapse: 9734.916442155838 \tLoss: 2.268 \tMean Loss: 2.121 \tMean Acc: 0.292\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8715715408325195\n",
      "Parameter containing:\n",
      "tensor([[4.4525, 0.2990, 1.3635, 6.2821, 3.1421, 3.4574, 5.8629, 0.2042, 1.6506,\n",
      "         3.5896]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.812350273132324\n",
      "Epoch: 1 \tStep: 776 \tTime Elapse: 9747.617534399033 \tLoss: 1.855 \tMean Loss: 2.116 \tMean Acc: 0.293\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8832919597625732\n",
      "Parameter containing:\n",
      "tensor([[4.4529, 0.2978, 1.3626, 6.2821, 3.1420, 3.4610, 5.8630, 0.2007, 1.6506,\n",
      "         3.5947]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.828498363494873\n",
      "Epoch: 1 \tStep: 777 \tTime Elapse: 9760.346185922623 \tLoss: 2.032 \tMean Loss: 2.103 \tMean Acc: 0.293\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7049765586853027\n",
      "Parameter containing:\n",
      "tensor([[4.4492, 0.2949, 1.3582, 6.2822, 3.1418, 3.4678, 5.8593, 0.1967, 1.6506,\n",
      "         3.6027]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.4384765625\n",
      "Epoch: 1 \tStep: 778 \tTime Elapse: 9772.506989717484 \tLoss: 2.053 \tMean Loss: 2.102 \tMean Acc: 0.294\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8405604362487793\n",
      "Parameter containing:\n",
      "tensor([[4.4435, 0.2912, 1.3519, 6.2823, 3.1417, 3.4753, 5.8549, 0.1925, 1.6506,\n",
      "         3.6117]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39680290222168\n",
      "Epoch: 1 \tStep: 779 \tTime Elapse: 9784.761565208435 \tLoss: 2.036 \tMean Loss: 2.096 \tMean Acc: 0.294\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8961937427520752\n",
      "Parameter containing:\n",
      "tensor([[4.4374, 0.2875, 1.3455, 6.2823, 3.1415, 3.4813, 5.8508, 0.1890, 1.6506,\n",
      "         3.6192]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.429314851760864\n",
      "Epoch: 1 \tStep: 780 \tTime Elapse: 9797.104413747787 \tLoss: 2.28 \tMean Loss: 2.1 \tMean Acc: 0.294\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8592684268951416\n",
      "Parameter containing:\n",
      "tensor([[4.4314, 0.2835, 1.3390, 6.2824, 3.1413, 3.4870, 5.8472, 0.1855, 1.6506,\n",
      "         3.6266]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.365369081497192\n",
      "Epoch: 1 \tStep: 781 \tTime Elapse: 9809.345916986465 \tLoss: 1.827 \tMean Loss: 2.081 \tMean Acc: 0.294\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6866569519042969\n",
      "Parameter containing:\n",
      "tensor([[4.4250, 0.2795, 1.3320, 6.2824, 3.1411, 3.4920, 5.8446, 0.1821, 1.6506,\n",
      "         3.6332]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.424800634384155\n",
      "Epoch: 1 \tStep: 782 \tTime Elapse: 9821.474935531616 \tLoss: 2.035 \tMean Loss: 2.089 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8606128692626953\n",
      "Parameter containing:\n",
      "tensor([[4.4186, 0.2757, 1.3249, 6.2825, 3.1410, 3.4964, 5.8423, 0.1790, 1.6506,\n",
      "         3.6391]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.42574143409729\n",
      "Epoch: 1 \tStep: 783 \tTime Elapse: 9833.778022050858 \tLoss: 2.219 \tMean Loss: 2.088 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8664312362670898\n",
      "Parameter containing:\n",
      "tensor([[4.4129, 0.2723, 1.3187, 6.2825, 3.1409, 3.5004, 5.8402, 0.1761, 1.6506,\n",
      "         3.6446]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.406596422195435\n",
      "Epoch: 1 \tStep: 784 \tTime Elapse: 9846.068202972412 \tLoss: 1.943 \tMean Loss: 2.08 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6769158840179443\n",
      "Parameter containing:\n",
      "tensor([[4.4077, 0.2692, 1.3130, 6.2825, 3.1407, 3.5037, 5.8386, 0.1736, 1.6506,\n",
      "         3.6491]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.525319337844849\n",
      "Epoch: 1 \tStep: 785 \tTime Elapse: 9858.28778386116 \tLoss: 2.195 \tMean Loss: 2.089 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6907639503479004\n",
      "Parameter containing:\n",
      "tensor([[4.4036, 0.2668, 1.3086, 6.2826, 3.1406, 3.5068, 5.8367, 0.1708, 1.6506,\n",
      "         3.6540]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.385221719741821\n",
      "Epoch: 1 \tStep: 786 \tTime Elapse: 9870.382176160812 \tLoss: 2.284 \tMean Loss: 2.103 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8577380180358887\n",
      "Parameter containing:\n",
      "tensor([[4.4005, 0.2649, 1.3054, 6.2826, 3.1406, 3.5096, 5.8352, 0.1681, 1.6506,\n",
      "         3.6585]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.432601690292358\n",
      "Epoch: 1 \tStep: 787 \tTime Elapse: 9882.689277172089 \tLoss: 1.975 \tMean Loss: 2.088 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8565680980682373\n",
      "Parameter containing:\n",
      "tensor([[4.3984, 0.2635, 1.3031, 6.2827, 3.1405, 3.5123, 5.8337, 0.1655, 1.6506,\n",
      "         3.6627]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39863657951355\n",
      "Epoch: 1 \tStep: 788 \tTime Elapse: 9894.961567401886 \tLoss: 2.17 \tMean Loss: 2.082 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8923437595367432\n",
      "Parameter containing:\n",
      "tensor([[4.3967, 0.2623, 1.3013, 6.2828, 3.1405, 3.5147, 5.8322, 0.1632, 1.6506,\n",
      "         3.6666]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.84427809715271\n",
      "Epoch: 1 \tStep: 789 \tTime Elapse: 9907.714858531952 \tLoss: 2.18 \tMean Loss: 2.083 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6851119995117188\n",
      "Parameter containing:\n",
      "tensor([[4.3986, 0.2622, 1.3030, 6.2829, 3.1405, 3.5156, 5.8323, 0.1605, 1.6506,\n",
      "         3.6695]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.816807746887207\n",
      "Epoch: 1 \tStep: 790 \tTime Elapse: 9920.235644340515 \tLoss: 1.884 \tMean Loss: 2.074 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.873218297958374\n",
      "Parameter containing:\n",
      "tensor([[4.4011, 0.2623, 1.3055, 6.2831, 3.1405, 3.5164, 5.8326, 0.1581, 1.6506,\n",
      "         3.6723]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.803956747055054\n",
      "Epoch: 1 \tStep: 791 \tTime Elapse: 9932.92968416214 \tLoss: 2.222 \tMean Loss: 2.079 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8625481128692627\n",
      "Parameter containing:\n",
      "tensor([[4.4053, 0.2631, 1.3097, 6.2833, 3.1406, 3.5186, 5.8321, 0.1551, 1.6506,\n",
      "         3.6768]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.413556098937988\n",
      "Epoch: 1 \tStep: 792 \tTime Elapse: 9945.22294640541 \tLoss: 2.061 \tMean Loss: 2.085 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9126479625701904\n",
      "Parameter containing:\n",
      "tensor([[4.4098, 0.2637, 1.3146, 6.2835, 3.1407, 3.5214, 5.8302, 0.1524, 1.6506,\n",
      "         3.6821]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.41893219947815\n",
      "Epoch: 1 \tStep: 793 \tTime Elapse: 9957.57130599022 \tLoss: 2.334 \tMean Loss: 2.086 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.680443525314331\n",
      "Parameter containing:\n",
      "tensor([[4.4165, 0.2654, 1.3214, 6.2837, 3.1408, 3.5248, 5.8272, 0.1493, 1.6506,\n",
      "         3.6885]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.39819622039795\n",
      "Epoch: 1 \tStep: 794 \tTime Elapse: 9969.669694900513 \tLoss: 2.241 \tMean Loss: 2.097 \tMean Acc: 0.295\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8628954887390137\n",
      "Parameter containing:\n",
      "tensor([[4.4226, 0.2670, 1.3281, 6.2840, 3.1409, 3.5281, 5.8240, 0.1465, 1.6506,\n",
      "         3.6945]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.40296220779419\n",
      "Epoch: 1 \tStep: 795 \tTime Elapse: 9981.952213525772 \tLoss: 1.696 \tMean Loss: 2.085 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8831658363342285\n",
      "Parameter containing:\n",
      "tensor([[4.4285, 0.2688, 1.3351, 6.2842, 3.1410, 3.5291, 5.8205, 0.1444, 1.6506,\n",
      "         3.6980]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.429551362991333\n",
      "Epoch: 1 \tStep: 796 \tTime Elapse: 9994.282045602798 \tLoss: 1.891 \tMean Loss: 2.075 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.66978120803833\n",
      "Parameter containing:\n",
      "tensor([[4.4329, 0.2699, 1.3406, 6.2843, 3.1411, 3.5304, 5.8165, 0.1425, 1.6506,\n",
      "         3.7016]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.587099552154541\n",
      "Epoch: 1 \tStep: 797 \tTime Elapse: 10006.557626247406 \tLoss: 2.31 \tMean Loss: 2.076 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.6838247776031494\n",
      "Parameter containing:\n",
      "tensor([[4.4379, 0.2710, 1.3465, 6.2845, 3.1412, 3.5334, 5.8115, 0.1401, 1.6506,\n",
      "         3.7070]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.79618525505066\n",
      "Epoch: 1 \tStep: 798 \tTime Elapse: 10019.055663585663 \tLoss: 2.347 \tMean Loss: 2.09 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.8579413890838623\n",
      "Parameter containing:\n",
      "tensor([[4.4437, 0.2724, 1.3532, 6.2847, 3.1413, 3.5353, 5.8082, 0.1380, 1.6506,\n",
      "         3.7110]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.87705659866333\n",
      "Epoch: 1 \tStep: 799 \tTime Elapse: 10031.807655572891 \tLoss: 1.993 \tMean Loss: 2.095 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.9479639530181885\n",
      "Parameter containing:\n",
      "tensor([[4.4482, 0.2734, 1.3586, 6.2848, 3.1414, 3.5369, 5.8053, 0.1360, 1.6506,\n",
      "         3.7148]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.64582109451294\n",
      "Epoch: 1 \tStep: 800 \tTime Elapse: 10044.419606208801 \tLoss: 2.009 \tMean Loss: 2.092 \tMean Acc: 0.297\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.804495096206665\n",
      "Parameter containing:\n",
      "tensor([[4.4523, 0.2741, 1.3632, 6.2850, 3.1415, 3.5389, 5.8026, 0.1339, 1.6506,\n",
      "         3.7188]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.605341672897339\n",
      "Epoch: 1 \tStep: 801 \tTime Elapse: 10056.84634590149 \tLoss: 2.078 \tMean Loss: 2.09 \tMean Acc: 0.297\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.7931113243103027\n",
      "Parameter containing:\n",
      "tensor([[4.4558, 0.2747, 1.3671, 6.2851, 3.1415, 3.5409, 5.8000, 0.1321, 1.6506,\n",
      "         3.7225]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  10.604257822036743\n",
      "Epoch: 1 \tStep: 802 \tTime Elapse: 10069.261543989182 \tLoss: 2.426 \tMean Loss: 2.094 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.839228868484497\n",
      "Parameter containing:\n",
      "tensor([[4.4589, 0.2754, 1.3704, 6.2852, 3.1416, 3.5427, 5.7987, 0.1301, 1.6506,\n",
      "         3.7259]], device='cuda:0', requires_grad=True)\n",
      "Backpropagation time:  11.015308856964111\n",
      "Epoch: 1 \tStep: 803 \tTime Elapse: 10082.133130788803 \tLoss: 2.308 \tMean Loss: 2.108 \tMean Acc: 0.296\n",
      "torch.Size([900, 8]) torch.Size([900, 8])\n",
      "torch.Size([900, 2])\n",
      "Finished 1 quanv layer\n",
      "torch.Size([4, 15, 15, 2])\n",
      "Forward time:  1.847895860671997\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \n\u001b[1;32m     25\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(model\u001b[38;5;241m.\u001b[39mconv_block[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkernel_circuits\u001b[38;5;241m.\u001b[39mweights)\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "logging_steps = 1\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "metric = MulticlassAccuracy()\n",
    "losses = np.array([])\n",
    "accs = np.array([])\n",
    "global_step = 0\n",
    "for epoch in range(1):\n",
    "    start_global = time.time()\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = F.pad(images,(1,1,1,1)).unsqueeze(1).cuda()\n",
    "        # print(images.size(), images.unsqueeze(1).size())\n",
    "        optimizer.zero_grad()  # Reset gradients\n",
    "        start = time.time() # Start forward\n",
    "        outputs = model(images).cpu()  # Forward pass\n",
    "        print(\"Forward time: \", time.time()-start)\n",
    "        # print(outputs, labels)\n",
    "        loss = criterion(outputs, labels)  \n",
    "\n",
    "        start = time.time()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(model.conv_block[0].kernel_circuits.weights)\n",
    "        print(\"Backpropagation time: \", time.time()-start)\n",
    "\n",
    "        # output\n",
    "        acc = multiclass_accuracy(outputs, labels)\n",
    "        \n",
    "        metric.update(outputs, labels)\n",
    "        losses = np.append(losses, loss.item())\n",
    "        global_step += 1\n",
    "        if global_step % logging_steps == 0:\n",
    "            print(\"Epoch:\", epoch+1, \n",
    "                \"\\tStep:\", global_step, \n",
    "                  \"\\tTime Elapse:\",time.time()-start_global,\n",
    "                # \"\\tAcc:\", round(float(acc), 3), \n",
    "                \"\\tLoss:\", round(loss.item(),3),\n",
    "                \"\\tMean Loss:\", round(float(losses[-30:].mean()), 3),\n",
    "                \"\\tMean Acc:\", round(float(metric.compute()), 3)\n",
    "                )\n",
    "        # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(losses, 'model_loss.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'QuanvolutionLayerTest.__init__.<locals>.circuit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./quanv-99-f.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m d \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./quanv-99-f.pt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m d\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/serialization.py:850\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _open_zipfile_writer(f) \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m--> 850\u001b[0m         \u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpickle_protocol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_disable_byteorder_record\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pnl_g/lib/python3.11/site-packages/torch/serialization.py:1088\u001b[0m, in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m   1086\u001b[0m pickler \u001b[38;5;241m=\u001b[39m pickle_module\u001b[38;5;241m.\u001b[39mPickler(data_buf, protocol\u001b[38;5;241m=\u001b[39mpickle_protocol)\n\u001b[1;32m   1087\u001b[0m pickler\u001b[38;5;241m.\u001b[39mpersistent_id \u001b[38;5;241m=\u001b[39m persistent_id\n\u001b[0;32m-> 1088\u001b[0m \u001b[43mpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1089\u001b[0m data_value \u001b[38;5;241m=\u001b[39m data_buf\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[1;32m   1090\u001b[0m zip_file\u001b[38;5;241m.\u001b[39mwrite_record(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_value, \u001b[38;5;28mlen\u001b[39m(data_value))\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'QuanvolutionLayerTest.__init__.<locals>.circuit'"
     ]
    }
   ],
   "source": [
    "torch.save(model, './quanv-99-f.pt')\n",
    "d = torch.load('./quanv-99-f.pt', weights_only=False)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.29928541, 2.26646066, 2.31143808, 2.28566694, 2.30074406,\n",
       "        2.23117399, 2.29665089, 2.28838134, 2.29740858, 2.3180263 ,\n",
       "        2.27688241, 2.2809937 , 2.27192926, 2.26544619, 2.26576376,\n",
       "        2.29138565, 2.28762531, 2.30460477, 2.30582309, 2.29767585,\n",
       "        2.30524755, 2.29540229, 2.27753139, 2.31416941, 2.32026243,\n",
       "        2.33729196, 2.30120635, 2.27086878, 2.29895782, 2.32046843,\n",
       "        2.31096268, 2.26653194, 2.29952621, 2.30972648, 2.31481028,\n",
       "        2.29856586, 2.32582045, 2.30594182, 2.28059483, 2.29702687,\n",
       "        2.27705717, 2.25737238, 2.2603631 , 2.33293843, 2.29739237,\n",
       "        2.28674936, 2.34554625, 2.32904792, 2.29863691, 2.33484936,\n",
       "        2.29960442, 2.30133915, 2.26774311, 2.35196757, 2.30750084,\n",
       "        2.32060337, 2.23556137, 2.32819748, 2.33270621, 2.32574701,\n",
       "        2.31356645, 2.30300641, 2.29785919, 2.31536317, 2.32911825,\n",
       "        2.32489777, 2.17661834, 2.29007792, 2.31942916, 2.33761501,\n",
       "        2.23471022, 2.31688023, 2.31395173, 2.29353666, 2.33455873,\n",
       "        2.34328842, 2.32607985, 2.28250217, 2.28484273, 2.29241681,\n",
       "        2.30839443, 2.33964252, 2.31782103, 2.28797412, 2.28762054,\n",
       "        2.3142314 , 2.21876669, 2.26386261, 2.31808424, 2.30275965,\n",
       "        2.24958205], requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3412,  0.0390, -0.1892,  0.1028, -0.6929, -0.3718, -0.9820, -0.4704,\n",
      "         -0.4137, -1.5197, -0.1858,  1.6441,  0.2530],\n",
      "        [ 0.1813, -0.9602, -0.0967, -1.1668, -1.0073,  0.6101, -0.0489, -1.5478,\n",
      "          0.0143, -0.5811, -1.0953,  0.2186, -1.3174]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2370,  0.5141,  0.3099,  0.8612,  0.1464, -1.5052,  1.1392,  0.0544,\n",
      "         -0.5161, -1.1758,  1.1639,  0.6922, -2.2416],\n",
      "        [ 0.0764,  0.6981,  1.4979,  0.7481, -0.3796,  0.4404,  1.9963,  0.9300,\n",
      "          0.7086, -1.2239,  0.2791, -1.5128,  0.4267]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "13 13\n",
      "CUR BATCH: 0\n",
      "CUR BATCH: 1\n",
      "CUR BATCH: 2\n",
      "CUR BATCH: 3\n",
      "3 3\n",
      "CUR BATCH: 0\n",
      "CUR BATCH: 1\n",
      "CUR BATCH: 2\n",
      "CUR BATCH: 3\n",
      "tensor([[-1.1553e-19,  5.5524e-05,  2.1918e-04, -9.8588e-04, -3.8794e-05,\n",
      "         -3.3907e-20, -4.8771e-04, -6.1539e-04, -4.5283e-04, -1.3964e-05,\n",
      "          1.3151e-19, -7.8229e-04,  2.9520e-04],\n",
      "        [ 5.6295e-04, -9.6974e-03, -2.0485e-06,  1.8727e-03,  3.0563e-03,\n",
      "         -7.0266e-19, -2.0485e-06,  1.1338e-03, -4.9295e-19, -4.8671e-03,\n",
      "          5.0884e-19,  1.7698e-03, -7.1310e-19]], device='cuda:0')\n",
      "Parameter containing:\n",
      "tensor([[ 0.2370,  0.5141,  0.3099,  0.8612,  0.1464, -1.5052,  1.1392,  0.0544,\n",
      "         -0.5161, -1.1758,  1.1639,  0.6922, -2.2416],\n",
      "        [ 0.0764,  0.6981,  1.4979,  0.7481, -0.3796,  0.4404,  1.9963,  0.9300,\n",
      "          0.7086, -1.2239,  0.2791, -1.5128,  0.4267]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model.conv_block._modules['0'].q_params)\n",
    "print(model.conv_block._modules['5'].q_params)\n",
    "optimizer.zero_grad()\n",
    "outputs = model(images[:4]).cpu()  # Forward pass\n",
    "\n",
    "\n",
    "loss = criterion(outputs, labels[:4])  \n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "print(model.conv_block._modules['0'].q_params.grad)\n",
    "print(model.conv_block._modules['5'].q_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       device='cuda:0')\n",
      "tensor(2.3332, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv_block._modules['5'].kernel_circuits.weights.grad)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pennylane' (<_frozen_importlib_external.NamespaceLoader object at 0x7efdb3f1de90>)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "qml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "o8wHpxJTaA1s"
   },
   "outputs": [],
   "source": [
    "def quanv(image):\n",
    "    \"\"\"Convolves the input image with many applications of the same quantum circuit.\"\"\"\n",
    "    out = np.zeros((14, 14,4))\n",
    "\n",
    "    # Loop over the coordinates of the top-left pixel of 2X2 squares\n",
    "    for i in range(4):\n",
    "      cir = circuit1\n",
    "      for j in range(0, 28, 2):\n",
    "          for k in range(0, 28, 2):\n",
    "              # Process a squared 2x2 region of the image with a quantum circuit\n",
    "              # print(j, k )\n",
    "              q_results = cir(\n",
    "                  [\n",
    "                      image[0,j, k],\n",
    "                      image[0,j, k + 1],\n",
    "                      image[0,j + 1, k],\n",
    "                      image[0,j + 1, k + 1]\n",
    "                  ]\n",
    "              )\n",
    "              # Assign expectation values to different channels of the output pixel (j/2, k/2)\n",
    "              # print(q_results)\n",
    "                  # out[j // 2, k // 2, c] = q_results[c]\n",
    "              for c in range(4):\n",
    "                # print(out[i, j // 2, k // 2], q_results[c])\n",
    "                out[j // 2, k // 2,c] += q_results[c].float().numpy()\n",
    "              # out[j // 2, k // 2, i] /= 4\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cZggmpEaA1t"
   },
   "source": [
    "# Quantum pre-processing of the dataset\n",
    "\n",
    "Since we are not going to train the quantum convolution layer, it is\n",
    "more efficient to apply it as a \\\"pre-processing\\\" layer to all the\n",
    "images of our dataset. Later an entirely classical model will be\n",
    "directly trained and tested on the pre-processed dataset, avoiding\n",
    "unnecessary repetitions of quantum computations.\n",
    "\n",
    "The pre-processed images will be saved in the folder `SAVE_PATH`. Once\n",
    "saved, they can be directly loaded by setting `PREPROCESS = False`,\n",
    "otherwise the quantum convolution is evaluated at each run of the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"16\"  # Replace 4 with your desired number of threads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaRybkXJaA1t",
    "outputId": "65a8734c-e048-4095-bbbf-f3225d6a3732"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantum pre-processing of train images:\n",
      "1/50"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paultran27/miniconda3/envs/pnl/lib/python3.11/site-packages/pennylane/math/utils.py:228: UserWarning: Contains tensors of types {'autograd', 'torch'}; dispatch will prioritize TensorFlow, PyTorch, and Jax over Autograd. Consider replacing Autograd with vanilla NumPy.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/50\n",
      "Quantum pre-processing of test images:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m q_test_images \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mQuantum pre-processing of test images:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, img \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest_images\u001b[49m):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, n_test), end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m     q_test_images\u001b[38;5;241m.\u001b[39mappend(quanv(img))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_images' is not defined"
     ]
    }
   ],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, (img, _) in enumerate(train_loader):\n",
    "        # print(img.size())\n",
    "        if idx >=5: break\n",
    "        print(\"\\r{}/{}\".format(idx + 1, n_train), end = '')\n",
    "        q_train_images.append(quanv(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"\\r{}/{}\".format(idx + 1, n_test), end = '')\n",
    "        q_test_images.append(quanv(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # # Save pre-processed images\n",
    "    # np.save(SAVE_PATH + \"q_train_images.npy\", q_train_images)\n",
    "    # np.save(SAVE_PATH + \"q_test_images.npy\", q_test_images)\n",
    "\n",
    "\n",
    "# # Load pre-processed images\n",
    "# q_train_images = np.load(SAVE_PATH + \"q_train_images.npy\")\n",
    "# q_test_images = np.load(SAVE_PATH + \"q_test_images.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_8dPOWNLaA1t"
   },
   "source": [
    "Let us visualize the effect of the quantum convolution layer on a batch\n",
    "of samples:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gY8_SQD-aA1t",
    "outputId": "4412bcc4-e21e-44e1-fe11-0ea1cc475c37"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(10, 10))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    # axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "My4UOwV4aA1t"
   },
   "source": [
    "Below each input image, the $4$ output channels generated by the quantum\n",
    "convolution are visualized in gray scale.\n",
    "\n",
    "One can clearly notice the downsampling of the resolution and some local\n",
    "distortion introduced by the quantum kernel. On the other hand the\n",
    "global shape of the image is preserved, as expected for a convolution\n",
    "layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Iwnmo__naA1t"
   },
   "source": [
    "# Hybrid quantum-classical model\n",
    "\n",
    "After the application of the quantum convolution layer we feed the\n",
    "resulting features into a classical neural network that will be trained\n",
    "to classify the $10$ different digits of the MNIST dataset.\n",
    "\n",
    "We use a very simple model: just a fully connected layer with 10 output\n",
    "nodes with a final *softmax* activation function.\n",
    "\n",
    "The model is compiled with a *stochastic-gradient-descent* optimizer,\n",
    "and a *cross-entropy* loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z01nBYO-JuYy",
    "outputId": "02d3def3-dfac-4685-d80c-f9fdb84a2a71"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_images\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "O8x_WUKRaA1t"
   },
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "def ClassicModel():\n",
    "    \"\"\"Initializes and returns a custom Keras CNN model ready to be trained on MNIST.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        # First Convolutional layer\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def QuanvModel():\n",
    "    \"\"\"Initializes and returns a custom Keras CNN model ready to be trained on MNIST.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        # First Convolutional layer\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(14, 14, 4)),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNsWe0LCaA1t"
   },
   "source": [
    "# Training\n",
    "\n",
    "We first initialize an instance of the model, then we train and validate\n",
    "it with the dataset that has been already pre-processed by a quantum\n",
    "convolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rCG20prHaA1t",
    "outputId": "074e2282-a05c-4e2c-eaf9-7108bee608a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 3s - 1s/step - accuracy: 0.0000e+00 - loss: 2.8372 - val_accuracy: 0.0000e+00 - val_loss: 2.7045\n",
      "Epoch 2/30\n",
      "2/2 - 0s - 30ms/step - accuracy: 0.8000 - loss: 1.2979 - val_accuracy: 0.0000e+00 - val_loss: 3.3358\n",
      "Epoch 3/30\n",
      "2/2 - 0s - 24ms/step - accuracy: 0.6000 - loss: 0.9884 - val_accuracy: 0.0000e+00 - val_loss: 3.7362\n",
      "Epoch 4/30\n",
      "2/2 - 0s - 27ms/step - accuracy: 0.6000 - loss: 0.8411 - val_accuracy: 0.0000e+00 - val_loss: 3.6965\n",
      "Epoch 5/30\n",
      "2/2 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.5623 - val_accuracy: 0.0000e+00 - val_loss: 3.4626\n",
      "Epoch 6/30\n",
      "2/2 - 0s - 24ms/step - accuracy: 1.0000 - loss: 0.3246 - val_accuracy: 0.0000e+00 - val_loss: 3.2518\n",
      "Epoch 7/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.1819 - val_accuracy: 0.2000 - val_loss: 3.1162\n",
      "Epoch 8/30\n",
      "2/2 - 0s - 34ms/step - accuracy: 1.0000 - loss: 0.0998 - val_accuracy: 0.4000 - val_loss: 3.0552\n",
      "Epoch 9/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0574 - val_accuracy: 0.4000 - val_loss: 3.0533\n",
      "Epoch 10/30\n",
      "2/2 - 0s - 23ms/step - accuracy: 1.0000 - loss: 0.0342 - val_accuracy: 0.4000 - val_loss: 3.0877\n",
      "Epoch 11/30\n",
      "2/2 - 0s - 124ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.4000 - val_loss: 3.1399\n",
      "Epoch 12/30\n",
      "2/2 - 0s - 64ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.4000 - val_loss: 3.2002\n",
      "Epoch 13/30\n",
      "2/2 - 0s - 30ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.4000 - val_loss: 3.2622\n",
      "Epoch 14/30\n",
      "2/2 - 0s - 67ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.4000 - val_loss: 3.3211\n",
      "Epoch 15/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.4000 - val_loss: 3.3716\n",
      "Epoch 16/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.4000 - val_loss: 3.4180\n",
      "Epoch 17/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.4000 - val_loss: 3.4608\n",
      "Epoch 18/30\n",
      "2/2 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.4000 - val_loss: 3.4989\n",
      "Epoch 19/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 0.4000 - val_loss: 3.5327\n",
      "Epoch 20/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.4000 - val_loss: 3.5370\n",
      "Epoch 21/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0031 - val_accuracy: 0.4000 - val_loss: 3.5452\n",
      "Epoch 22/30\n",
      "2/2 - 0s - 28ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.6000 - val_loss: 3.5639\n",
      "Epoch 23/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0025 - val_accuracy: 0.6000 - val_loss: 3.5867\n",
      "Epoch 24/30\n",
      "2/2 - 0s - 36ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.6000 - val_loss: 3.6065\n",
      "Epoch 25/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.6000 - val_loss: 3.6218\n",
      "Epoch 26/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0020 - val_accuracy: 0.6000 - val_loss: 3.6352\n",
      "Epoch 27/30\n",
      "2/2 - 0s - 40ms/step - accuracy: 1.0000 - loss: 0.0018 - val_accuracy: 0.6000 - val_loss: 3.6512\n",
      "Epoch 28/30\n",
      "2/2 - 0s - 35ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6000 - val_loss: 3.6659\n",
      "Epoch 29/30\n",
      "2/2 - 0s - 57ms/step - accuracy: 1.0000 - loss: 0.0017 - val_accuracy: 0.6000 - val_loss: 3.6793\n",
      "Epoch 30/30\n",
      "2/2 - 0s - 30ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.6000 - val_loss: 3.6917\n"
     ]
    }
   ],
   "source": [
    "q_model = QuanvModel()\n",
    "\n",
    "q_history = q_model.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFVunUOYaA1t"
   },
   "source": [
    "In order to compare the results achievable with and without the quantum\n",
    "convolution layer, we initialize also a \\\"classical\\\" instance of the\n",
    "model that will be directly trained and validated with the raw MNIST\n",
    "images (i.e., without quantum pre-processing).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dtpqzry8aA1t",
    "outputId": "b5c7823b-5d99-4c73-a1a7-4de0f88e281a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2/2 - 5s - 2s/step - accuracy: 0.0000e+00 - loss: 2.3735 - val_accuracy: 0.4000 - val_loss: 2.1891\n",
      "Epoch 2/30\n",
      "2/2 - 0s - 23ms/step - accuracy: 1.0000 - loss: 1.8873 - val_accuracy: 0.4000 - val_loss: 2.1258\n",
      "Epoch 3/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 1.5827 - val_accuracy: 0.4000 - val_loss: 2.0856\n",
      "Epoch 4/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 1.2649 - val_accuracy: 0.4000 - val_loss: 2.0636\n",
      "Epoch 5/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.9371 - val_accuracy: 0.4000 - val_loss: 2.0659\n",
      "Epoch 6/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.6406 - val_accuracy: 0.4000 - val_loss: 2.0890\n",
      "Epoch 7/30\n",
      "2/2 - 0s - 37ms/step - accuracy: 1.0000 - loss: 0.4030 - val_accuracy: 0.4000 - val_loss: 2.1315\n",
      "Epoch 8/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.2404 - val_accuracy: 0.4000 - val_loss: 2.1862\n",
      "Epoch 9/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.1377 - val_accuracy: 0.4000 - val_loss: 2.2471\n",
      "Epoch 10/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0782 - val_accuracy: 0.4000 - val_loss: 2.3200\n",
      "Epoch 11/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0448 - val_accuracy: 0.4000 - val_loss: 2.3899\n",
      "Epoch 12/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0267 - val_accuracy: 0.4000 - val_loss: 2.4500\n",
      "Epoch 13/30\n",
      "2/2 - 0s - 23ms/step - accuracy: 1.0000 - loss: 0.0165 - val_accuracy: 0.4000 - val_loss: 2.5093\n",
      "Epoch 14/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.4000 - val_loss: 2.5706\n",
      "Epoch 15/30\n",
      "2/2 - 0s - 31ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.4000 - val_loss: 2.6314\n",
      "Epoch 16/30\n",
      "2/2 - 0s - 60ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.4000 - val_loss: 2.6875\n",
      "Epoch 17/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.4000 - val_loss: 2.7379\n",
      "Epoch 18/30\n",
      "2/2 - 0s - 32ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.4000 - val_loss: 2.7828\n",
      "Epoch 19/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 0.0023 - val_accuracy: 0.4000 - val_loss: 2.8222\n",
      "Epoch 20/30\n",
      "2/2 - 0s - 27ms/step - accuracy: 1.0000 - loss: 0.0019 - val_accuracy: 0.4000 - val_loss: 2.8577\n",
      "Epoch 21/30\n",
      "2/2 - 0s - 29ms/step - accuracy: 1.0000 - loss: 0.0016 - val_accuracy: 0.4000 - val_loss: 2.8892\n",
      "Epoch 22/30\n",
      "2/2 - 0s - 30ms/step - accuracy: 1.0000 - loss: 0.0014 - val_accuracy: 0.6000 - val_loss: 2.9169\n",
      "Epoch 23/30\n",
      "2/2 - 0s - 27ms/step - accuracy: 1.0000 - loss: 0.0012 - val_accuracy: 0.6000 - val_loss: 2.9413\n",
      "Epoch 24/30\n",
      "2/2 - 0s - 34ms/step - accuracy: 1.0000 - loss: 0.0011 - val_accuracy: 0.6000 - val_loss: 2.9627\n",
      "Epoch 25/30\n",
      "2/2 - 0s - 65ms/step - accuracy: 1.0000 - loss: 9.8962e-04 - val_accuracy: 0.6000 - val_loss: 2.9814\n",
      "Epoch 26/30\n",
      "2/2 - 0s - 30ms/step - accuracy: 1.0000 - loss: 9.1211e-04 - val_accuracy: 0.6000 - val_loss: 2.9979\n",
      "Epoch 27/30\n",
      "2/2 - 0s - 22ms/step - accuracy: 1.0000 - loss: 8.4997e-04 - val_accuracy: 0.6000 - val_loss: 3.0123\n",
      "Epoch 28/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 7.9933e-04 - val_accuracy: 0.6000 - val_loss: 3.0250\n",
      "Epoch 29/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 7.5733e-04 - val_accuracy: 0.6000 - val_loss: 3.0363\n",
      "Epoch 30/30\n",
      "2/2 - 0s - 21ms/step - accuracy: 1.0000 - loss: 7.2216e-04 - val_accuracy: 0.6000 - val_loss: 3.0462\n"
     ]
    }
   ],
   "source": [
    "c_model = ClassicModel()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images,\n",
    "    train_labels,\n",
    "    validation_data=(test_images, test_labels),\n",
    "    batch_size=4,\n",
    "    epochs=n_epochs,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpT3ghaIaA1t"
   },
   "source": [
    "# Results\n",
    "\n",
    "We can finally plot the test accuracy and the test loss with respect to\n",
    "the number of training epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 906
    },
    "id": "jHRpWQ_laA1t",
    "outputId": "ce45dc3d-fc3e-4874-b6dc-d07886ac0805"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plt.style.use(\"seaborn\")\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(6, 9))\n",
    "\n",
    "ax1.plot(q_history.history[\"val_accuracy\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax1.plot(c_history.history[\"val_accuracy\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax1.set_ylabel(\"Accuracy\")\n",
    "ax1.set_ylim([0, 1])\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.plot(q_history.history[\"val_loss\"], \"-ob\", label=\"With quantum layer\")\n",
    "ax2.plot(c_history.history[\"val_loss\"], \"-og\", label=\"Without quantum layer\")\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_ylim(top=2.5)\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xrc2evb2aA1t"
   },
   "source": [
    "# References\n",
    "\n",
    "1.  Maxwell Henderson, Samriddhi Shakya, Shashindra Pradhan, Tristan\n",
    "    Cook. \\\"Quanvolutional Neural Networks: Powering Image Recognition\n",
    "    with Quantum Circuits.\\\"\n",
    "    [arXiv:1904.04767](https://arxiv.org/abs/1904.04767), 2019.\n",
    "\n",
    "# About the author\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
